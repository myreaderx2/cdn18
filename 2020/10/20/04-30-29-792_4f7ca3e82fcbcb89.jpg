


<!DOCTYPE html>
<html lang="en" class="no-js">

<head>

        <title>Add a picture for suspense: neural correlates of the interaction between language and visual information in the perception of fear | Social Cognitive and Affective Neuroscience | Oxford Academic</title>

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.4/jquery.min.js" type="text/javascript"></script>
<script>window.jQuery || document.write('<script src="//oup.silverchair-cdn.com/UI/app/vendor/jquery-2.2.4.js" type="text/javascript">\x3C/script>')</script>
<script src="//oup.silverchair-cdn.com/Themes/Silver/app/vendor/v-637370535343405606/jquery-migrate-1.4.1.min.js" type="text/javascript"></script>



    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

    
    <meta charset="utf-8" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <!-- Turn off telephone number detection. -->
    <meta name="format-detection" content="telephone=no" />

<!-- Bookmark Icons -->
  <link rel="apple-touch-icon" sizes="180x180" href="//oup.silverchair-cdn.com/UI/app/img/v-637370535184959337/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="//oup.silverchair-cdn.com/UI/app/img/v-637370535184959337/favicon-32x32.png" sizes="32x32">
  <link rel="icon" type="image/png" href="//oup.silverchair-cdn.com/UI/app/img/v-637370535184959337/favicon-16x16.png" sizes="16x16">
  <link rel="mask-icon" href="//oup.silverchair-cdn.com/UI/app/img/v-637370535185271781/safari-pinned-tab.svg" color="#5bbad5">
  <link rel="shortcut icon" href="//oup.silverchair-cdn.com/UI/app/img/v-637370535184959337/favicon.ico">
  <link rel="manifest" href="//oup.silverchair-cdn.com/UI/app/img/v-637370535185118770/manifest.json">
  <meta name="msapplication-config" content="//oup.silverchair-cdn.com/UI/app/img/v-637370535184959337/browserconfig.xml">
  <meta name="theme-color" content="#002f65">


    




<link rel="stylesheet" type="text/css" href="//oup.silverchair-cdn.com/UI/app/fonts/icons.css" />

<link rel="stylesheet" type="text/css" href="//oup.silverchair-cdn.com/UI/app/css/v-637378577423488319/style.min.css" />

        <link rel="stylesheet" type="text/css" href="//oup.silverchair-cdn.com/UI/app/vendor/oupCookiePolicy/css/v-637370535187303002/jquery.fancybox-1.3.4_1.css" />
        <link rel="stylesheet" type="text/css" href="//oup.silverchair-cdn.com/UI/app/vendor/jscrollpane/v-637370535187303002/jscrollpane.css" />
        <link rel="stylesheet" type="text/css" href="//oup.silverchair-cdn.com/UI/app/vendor/jquery.tablesorter/v-637370535187146786/theme.default.css" />

    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Merriweather:300,400,400italic,700,700italic|Source+Sans+Pro:400,400italic,700,700italic" />


        <link href=//oup.silverchair-cdn.com/data/SiteBuilderAssetsOriginals/Live/CSS/journals/global.css rel="stylesheet" type="text/css" />
                <link href=//oup.silverchair-cdn.com/data/SiteBuilderAssets/Live/CSS/scan/Site-619161545.css rel="stylesheet" type="text/css" />



    <script> var dataLayer = [{"event_type":"full-text","supplier_tag":"SC_Journals","object_type":"Article","siteid":"scan","authzrequired":"false","doi":"10.1093/scan/nsq050"}]; </script>
        <script>
        (function (w, d, s, l, i) {
          w[l] = w[l] || []; w[l].push({
            'gtm.start':
              new Date().getTime(), event: 'gtm.js'
          }); var f = d.getElementsByTagName(s)[0],
            j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
            'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
        })(window, document, 'script', 'dataLayer', 'GTM-W6DD7HV');
        </script>

    

        <script type="text/javascript">
            var App = App || {};
            App.LoginUserInfo = {
                isInstLoggedIn: 0,
                isIndividualLoggedIn: 0
            };

            App.CurrentSubdomain = 'scan';
            App.SiteURL = 'academic.oup.com/scan';
        </script>
    
    
    <link href="https://cdn.jsdelivr.net/chartist.js/latest/chartist.min.css" rel="stylesheet" type="text/css" />
    <script type="application/ld+json">
        {"@context":"http://schema.org","@id":"https://academic.oup.com/scan/article/6/4/404/1647696","@type":"ScholarlyArticle","name":"Add a picture for suspense: neural correlates of the interaction between language and visual information in the perception of fear","datePublished":"2010-06-08","isPartOf":{"@id":"https://academic.oup.com/scan/scan/issue/6/4","@type":"PublicationIssue","issueNumber":"4","datePublished":"2011-09-01","isPartOf":{"@id":"https://academic.oup.com/scan/scan","@type":"Periodical","name":"Social Cognitive and Affective Neuroscience","issn":["1749-5024"]}},"url":"http://dx.doi.org/10.1093/scan/nsq050","keywords":["language","emotion","film theory","fMRI","scenes","temporal pole"],"inLanguage":"en","copyrightHolder":"Oxford University Press","copyrightYear":"2020","publisher":"Oxford University Press","sameAs":"https://academic.oup.com/scan/article/6/4/404/1647696","author":[{"name":"Willems, Roel M.","affiliation":"Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, PO Box 9101, 6500 HB Nijmegen, The Netherlands, Helen Wills Neuroscience Institute, University of California Berkeley, 132 Barker Hall, Berkeley, CA 94720-3190, USA, PhD Arts, Academy of the Arts, Humanities Faculty, Leiden University, Rapenburg 38, 2311 EX Leiden, The Netherlands, IVOK, Leuven University, Schapenstraat 34, 3000 Leuven, Belgium, and Max Planck Institute for Psycholinguistics, Wundtlaan 1, 6525 XD Nijmegen, The Netherlands","@type":"Person"},{"name":"Clevis, Krien","affiliation":"Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, PO Box 9101, 6500 HB Nijmegen, The Netherlands, Helen Wills Neuroscience Institute, University of California Berkeley, 132 Barker Hall, Berkeley, CA 94720-3190, USA, PhD Arts, Academy of the Arts, Humanities Faculty, Leiden University, Rapenburg 38, 2311 EX Leiden, The Netherlands, IVOK, Leuven University, Schapenstraat 34, 3000 Leuven, Belgium, and Max Planck Institute for Psycholinguistics, Wundtlaan 1, 6525 XD Nijmegen, The Netherlands","@type":"Person"},{"name":"Hagoort, Peter","affiliation":"Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, PO Box 9101, 6500 HB Nijmegen, The Netherlands, Helen Wills Neuroscience Institute, University of California Berkeley, 132 Barker Hall, Berkeley, CA 94720-3190, USA, PhD Arts, Academy of the Arts, Humanities Faculty, Leiden University, Rapenburg 38, 2311 EX Leiden, The Netherlands, IVOK, Leuven University, Schapenstraat 34, 3000 Leuven, Belgium, and Max Planck Institute for Psycholinguistics, Wundtlaan 1, 6525 XD Nijmegen, The Netherlands","@type":"Person"}],"description":"Abstract.  We investigated how visual and linguistic information interact in the perception of emotion. We borrowed a phenomenon from film theory which states t","pageStart":"404","pageEnd":"416","thumbnailURL":"https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/Issue/6/4/0/m_scan6_4.cover.gif?Expires=1665444426&Signature=e7hSvVXUgPQrcKphyUloq4i~vkrKHvCZAG4A-3sdIDj3GQPGTo2AoMJa1I4fZaIyTOLZCnih8gTZXgyN3TFvNSBb3RvodxyjBQjOjW96m3ggEPreB-wVGsCqfX0VR1mbHJh1CFqiKpNu7lxKEUL2ShgqPmKG6Lpy~Lh36rgusV8F9neUCMnLdVl5GYJg1G41eZCo0DKd3Pi0lQfmfzYQi6LlqjSydhS4qNWg6Zd0p-6gIsZYDBieKYSOHkWXpflCIK6CNvQMrC~xais2o0vpzk5~J1oXLr2lTGjRXhqPopZIj16dFUD93A7ews7C~dX-REGGkTll1hJ8gIljE6moLw__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA","headline":"Add a picture for suspense: neural correlates of the interaction between language and visual information in the perception of fear","image":"https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/Issue/6/4/0/m_scan6_4.cover.gif?Expires=1665444426&Signature=e7hSvVXUgPQrcKphyUloq4i~vkrKHvCZAG4A-3sdIDj3GQPGTo2AoMJa1I4fZaIyTOLZCnih8gTZXgyN3TFvNSBb3RvodxyjBQjOjW96m3ggEPreB-wVGsCqfX0VR1mbHJh1CFqiKpNu7lxKEUL2ShgqPmKG6Lpy~Lh36rgusV8F9neUCMnLdVl5GYJg1G41eZCo0DKd3Pi0lQfmfzYQi6LlqjSydhS4qNWg6Zd0p-6gIsZYDBieKYSOHkWXpflCIK6CNvQMrC~xais2o0vpzk5~J1oXLr2lTGjRXhqPopZIj16dFUD93A7ews7C~dX-REGGkTll1hJ8gIljE6moLw__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA"}
    </script>
    <meta property="og:site_name" content="OUP Academic" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Add a picture for suspense: neural correlates of the interaction between language and visual information in the perception of fear" />
    <meta property="og:description" content="Abstract.  We investigated how visual and linguistic information interact in the perception of emotion. We borrowed a phenomenon from film theory which states t" />
    <meta property="og:url" content="https://academic.oup.com/scan/article/6/4/404/1647696" />
    <meta property="og:image" content="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/Issue/6/4/0/m_scan6_4.cover.gif?Expires=1665444426&amp;Signature=e7hSvVXUgPQrcKphyUloq4i~vkrKHvCZAG4A-3sdIDj3GQPGTo2AoMJa1I4fZaIyTOLZCnih8gTZXgyN3TFvNSBb3RvodxyjBQjOjW96m3ggEPreB-wVGsCqfX0VR1mbHJh1CFqiKpNu7lxKEUL2ShgqPmKG6Lpy~Lh36rgusV8F9neUCMnLdVl5GYJg1G41eZCo0DKd3Pi0lQfmfzYQi6LlqjSydhS4qNWg6Zd0p-6gIsZYDBieKYSOHkWXpflCIK6CNvQMrC~xais2o0vpzk5~J1oXLr2lTGjRXhqPopZIj16dFUD93A7ews7C~dX-REGGkTll1hJ8gIljE6moLw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" />
    <meta property="og:updated_time" content="2010-06-08" />
<meta name="citation_author" content="Willems, Roel M." /><meta name="citation_author_institution" content="Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, PO Box 9101, 6500 HB Nijmegen, The Netherlands, 2Helen Wills Neuroscience Institute, University of California Berkeley, 132 Barker Hall, Berkeley, CA 94720-3190, USA, 3PhD Arts, Academy of the Arts, Humanities Faculty, Leiden University, Rapenburg 38, 2311 EX Leiden, The Netherlands, 4IVOK, Leuven University, Schapenstraat 34, 3000 Leuven, Belgium, and 5Max Planck Institute for Psycholinguistics, Wundtlaan 1, 6525 XD Nijmegen, The Netherlands" /><meta name="citation_author" content="Clevis, Krien" /><meta name="citation_author_institution" content="Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, PO Box 9101, 6500 HB Nijmegen, The Netherlands, 2Helen Wills Neuroscience Institute, University of California Berkeley, 132 Barker Hall, Berkeley, CA 94720-3190, USA, 3PhD Arts, Academy of the Arts, Humanities Faculty, Leiden University, Rapenburg 38, 2311 EX Leiden, The Netherlands, 4IVOK, Leuven University, Schapenstraat 34, 3000 Leuven, Belgium, and 5Max Planck Institute for Psycholinguistics, Wundtlaan 1, 6525 XD Nijmegen, The Netherlands" /><meta name="citation_author" content="Hagoort, Peter" /><meta name="citation_author_institution" content="Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, PO Box 9101, 6500 HB Nijmegen, The Netherlands, 2Helen Wills Neuroscience Institute, University of California Berkeley, 132 Barker Hall, Berkeley, CA 94720-3190, USA, 3PhD Arts, Academy of the Arts, Humanities Faculty, Leiden University, Rapenburg 38, 2311 EX Leiden, The Netherlands, 4IVOK, Leuven University, Schapenstraat 34, 3000 Leuven, Belgium, and 5Max Planck Institute for Psycholinguistics, Wundtlaan 1, 6525 XD Nijmegen, The Netherlands" /><meta name="citation_title" content="Add a picture for suspense: neural correlates of the interaction between language and visual information in the perception of fear" /><meta name="citation_firstpage" content="404" /><meta name="citation_lastpage" content="416" /><meta name="citation_doi" content="10.1093/scan/nsq050" /><meta name="citation_journal_title" content="Social Cognitive and Affective Neuroscience" /><meta name="citation_journal_abbrev" content="Soc Cogn Affect Neurosci" /><meta name="citation_volume" content="6" /><meta name="citation_issue" content="4" /><meta name="citation_publication_date" content="2011/09/01" /><meta name="citation_issn" content="1749-5016" /><meta name="citation_publisher" content="Oxford Academic" /><meta name="citation_reference" content="citation_title=Fear, faces, and the human amygdala; Current Opinion in Neurobiology;  citation_year=2008;  citation_volume=18;  citation_issue=2;  citation_pages=166-72; " /><meta name="citation_reference" content="citation_publisher=Linguistic Data Consortium, University of Pennsylvania, Philadelphia, PA; The CELEX Lexical Database;  citation_year=1993; " /><meta name="citation_reference" content="citation_title=Grounded cognition; Annual Review of Psychology;  citation_year=2008;  citation_volume=59;  citation_pages=617-45; " /><meta name="citation_reference" content="citation_title=FMRI study of emotional speech comprehension; Cerebral Cortex;  citation_year=2007;  citation_volume=17;  citation_issue=2;  citation_pages=339-52; " /><meta name="citation_reference" content="citation_title=The neural substrate for concrete, abstract, and emotional word lexica: a positron emission tomography study; Journal of Cognitive Neuroscience;  citation_year=1997;  citation_volume=9;  citation_issue=4;  citation_pages=441-61; " /><meta name="citation_reference" content="citation_title=Processing words with emotional connotation: An fMR1 study of time course and laterality in rostral frontal and retrosplenial cortices; Journal of Cognitive Neuroscience;  citation_year=2004;  citation_volume=16;  citation_issue=2;  citation_pages=167-77; " /><meta name="citation_reference" content="citation_title=How do you feel–now? The anterior insula and human awareness; Nature reviews. Neuroscience;  citation_year=2009;  citation_volume=10;  citation_issue=1;  citation_pages=59-70; " /><meta name="citation_reference" content="citation_title=Optimal experimental design for event-related fMRI; Human Brain Mapping;  citation_year=1999;  citation_volume=8;  citation_issue=2–3;  citation_pages=109-14; " /><meta name="citation_reference" content="citation_title=Towards the neurobiology of emotional body language; Nature Reviews. Neuroscience;  citation_year=2006;  citation_volume=7;  citation_issue=3;  citation_pages=242-9; " /><meta name="citation_reference" content="citation_title=The extended language network: A meta-analysis of neuroimaging studies on text comprehension; Human Brain Mapping;  citation_year=2008;  citation_volume=29;  citation_issue=5;  citation_pages=581-93; " /><meta name="citation_reference" content="citation_title=Detecting activations in PET and fMRI: levels of inference and power; NeuroImage;  citation_year=1996;  citation_volume=4;  citation_issue=3 Pt 1;  citation_pages=223-35; " /><meta name="citation_reference" content="citation_title=Statistical parametric maps in functional imaging: a general linear approach; Human Brain Mapping;  citation_year=1995;  citation_volume=2;  citation_pages=189-210; " /><meta name="citation_reference" content="citation_title=Multisubject fMRI studies and conjunction analyses; Neuroimage;  citation_year=1999;  citation_volume=10;  citation_issue=4;  citation_pages=385-396; " /><meta name="citation_reference" content="citation_title=Cognitive and behavioral profile in a case of right anterior temporal lobe neurodegeneration; Cortex;  citation_year=2004;  citation_volume=40;  citation_issue=4–5;  citation_pages=631-44; " /><meta name="citation_reference" content="citation_publisher=University of California Press, Berkeley, CA; Hitchcock on Hitchcock: Selected Writings and Interviews;  citation_year=1995; " /><meta name="citation_reference" content="citation_title=On Broca, brain, and binding: a new framework; Trends in Cognitive Sciences;  citation_year=2005;  citation_volume=9;  citation_issue=9;  citation_pages=416-23; " /><meta name="citation_reference" content="citation_title=Semantic unification; citation_publisher=MIT press, Cambridge, MA; The Cognitive Neurosciences IV;  citation_year=2009; " /><meta name="citation_reference" content="citation_title=Integration of word meaning and world knowledge in language comprehension; Science;  citation_year=2004;  citation_volume=304;  citation_issue=5669;  citation_pages=438-41; " /><meta name="citation_reference" content="citation_title=Amygdala activation during reading of emotional adjectives–an advantage for pleasant content; Social Cognitive and Affective Neuroscience;  citation_year=2009;  citation_volume=4;  citation_issue=1;  citation_pages=35-49; " /><meta name="citation_reference" content="citation_title=Neurophysiological correlates of comprehending emotional meaning in context; Journal of Cogntive Neuroscience;  citation_year=2009;  citation_volume=21;  citation_issue=11;  citation_pages=2245-62; " /><meta name="citation_reference" content="citation_title=Linguistic threat activates the human amygdala; Proceedings of the National Academy of Sciences of the United States of America;  citation_year=1999;  citation_volume=96;  citation_issue=18;  citation_pages=10456-10459; " /><meta name="citation_reference" content="citation_title=Contextual modulation of amygdala responsivity to surprised faces; Journal of Cognitive Neuroscience;  citation_year=2004;  citation_volume=16;  citation_issue=10;  citation_pages=1730-45; " /><meta name="citation_reference" content="citation_title=Functional grouping and cortical-subcortical interactions in emotion: a meta-analysis of neuroimaging studies; Neuroimage;  citation_year=2008;  citation_volume=42;  citation_issue=2;  citation_pages=998-1031; " /><meta name="citation_reference" content="citation_title=Incidental effects of emotional valence in single word processing: an fMRI study; Neuroimage;  citation_year=2005;  citation_volume=28;  citation_issue=4;  citation_pages=1022-32; " /><meta name="citation_reference" content="citation_title=Impact of signal-to-noise on functional MRI of the human amygdala; Neuroreport;  citation_year=2001;  citation_volume=12;  citation_issue=16;  citation_pages=3461-64; " /><meta name="citation_reference" content="citation_title=Putting feelings into words - Affect labeling disrupts amygdala activity in response to affective stimuli; Psychological Science;  citation_year=2007;  citation_volume=18;  citation_issue=5;  citation_pages=421-8; " /><meta name="citation_reference" content="citation_title=Paralimbic (mesocortical) areas; citation_publisher=Oxford University Press, New York; Principles of Behavioral and Cognitive Neurology;  citation_year=2000;  citation_pages=49-54; " /><meta name="citation_reference" content="citation_title=Characterizing the hemodynamic response: effects of presentation rate, sampling procedure, and the possibility of ordering brain activity based on relative timing; NeuroImage;  citation_year=2000;  citation_volume=11;  citation_issue=6 Pt 1;  citation_pages=735-59; " /><meta name="citation_reference" content="citation_title=The Kuleshov Effect: the influence of contextual framing on emotional attributions; Social Cognitive and Affective Neuroscience;  citation_year=2006;  citation_volume=1;  citation_issue=2;  citation_pages=95-106; " /><meta name="citation_reference" content="citation_title=The assessment and analysis of handedness: the Edinburgh inventory; Neuropsychologia;  citation_year=1971;  citation_volume=9;  citation_issue=1;  citation_pages=97-113; " /><meta name="citation_reference" content="citation_title=The Enigmatic temporal pole: a review of findings on social and emotional processing; Brain;  citation_year=2007;  citation_volume=130;  citation_issue=Pt 7;  citation_pages=1718-31; " /><meta name="citation_reference" content="citation_title=On-line integration of semantic information from speech and gesture: insights from event-related brain potentials; Journal of Cognitive Neuroscience;  citation_year=2007;  citation_volume=19;  citation_issue=4;  citation_pages=605-16; " /><meta name="citation_reference" content="citation_title=Neuroimaging studies of attention and the processing of emotion-laden stimuli; Progress in Brain Research;  citation_year=2004;  citation_volume=144;  citation_pages=171-82; " /><meta name="citation_reference" content="citation_title=Functional neuroanatomy of emotion: a meta-analysis of emotion activation studies in PET and fMRI; Neuroimage;  citation_year=2002;  citation_volume=16;  citation_issue=2;  citation_pages=331-48; " /><meta name="citation_reference" content="citation_publisher=Amsterdam University Press, Amsterdam; Lessen van Hitchcock;  citation_year=2004; " /><meta name="citation_reference" content="citation_title=Combining spatial extent and peak intensity to test for activations in functional imaging; Neuroimage;  citation_year=1997;  citation_volume=5;  citation_issue=2;  citation_pages=83-96; " /><meta name="citation_reference" content="citation_title=Brain mechanisms linking language and action; Nature Reviews Neuroscience;  citation_year=2005;  citation_volume=6;  citation_issue=7;  citation_pages=576-82; " /><meta name="citation_reference" content="citation_text=Paper presented at the Annual Meeting of the Organization for Human Brain Mapping, San Francisco; Neural Networks of Emotional Discourse Comprehension;  citation_year=2009; " /><meta name="citation_reference" content="citation_title=A common role of insula in feelings, empathy and uncertainty; Trends in Cognitive Science;  citation_year=2009;  citation_volume=13;  citation_issue=8;  citation_pages=334-40; " /><meta name="citation_reference" content="citation_title=Retrieval and unification of syntactic structure in sentence comprehension: an fMRI study using word-category ambiguity; Cerebral Cortex;  citation_year=2009;  citation_volume=19;  citation_issue=7;  citation_pages=1493-503; " /><meta name="citation_reference" content="citation_title=Brain mechanisms for detecting perceptual, semantic, and emotional deviance; Neuroimage;  citation_year=2000;  citation_volume=12;  citation_issue=4;  citation_pages=425-33; " /><meta name="citation_reference" content="citation_title=Differential amygdala activation during emotional decision and recognition memory tasks using unpleasant words: an fMRI study; Neuropsychologia;  citation_year=2001;  citation_volume=39;  citation_issue=6;  citation_pages=556-73; " /><meta name="citation_reference" content="citation_title=The lasting effect of words on feelings: words may facilitate exposure effects to threatening images; Emotion;  citation_year=2008;  citation_volume=8;  citation_issue=3;  citation_pages=307-17; " /><meta name="citation_reference" content="citation_title=Unification of speaker and meaning in language comprehension: an fMRI Study; Journal of Cognitive Neuroscience;  citation_year=2009;  citation_volume=21;  citation_issue=11;  citation_pages=2085-99; " /><meta name="citation_reference" content="citation_title=Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain; Neuroimage;  citation_year=2002;  citation_volume=15;  citation_issue=1;  citation_pages=273-289; " /><meta name="citation_reference" content="citation_title=Both of us disgusted in My insula: the common neural basis of seeing and feeling disgust; Neuron;  citation_year=2003;  citation_volume=40;  citation_issue=3;  citation_pages=655-64; " /><meta name="citation_reference" content="citation_title=Neural evidence for the interplay between language, gesture, and action: a review; Brain Language;  citation_year=2007;  citation_volume=101;  citation_issue=3;  citation_pages=278-89; " /><meta name="citation_reference" content="citation_title=Body-specific representations of action verbs: neural evidence from right- and left-handers; Psychological Science;  citation_year=2010;  citation_volume=21;  citation_issue=1;  citation_pages=67-74; " /><meta name="citation_reference" content="citation_title=Early decreases in alpha and gamma band power distinguish linguistic from visual information during sentence comprehension; Brain Research;  citation_year=2008;  citation_volume=1219;  citation_pages=78-90; " /><meta name="citation_reference" content="citation_title=When language meets action: the neural integration of gesture and speech; Cerebral Cortex;  citation_year=2007;  citation_volume=17;  citation_issue=10;  citation_pages=2322-33; " /><meta name="citation_reference" content="citation_title=Seeing and hearing meaning: ERP and fMRI evidence of word versus picture integration into a sentence context; Journal of Cognitive Neuroscience;  citation_year=2008;  citation_volume=20;  citation_issue=7;  citation_pages=1235-49; " /><meta name="citation_reference" content="citation_title=Differential roles for left inferior frontal and superior temporal cortex in multimodal integration of action and language; Neuroimage;  citation_year=2009;  citation_volume=47;  citation_issue=4;  citation_pages=1992-2004; " /><meta name="citation_reference" content="citation_title=Neural dissociations between action verb understanding and motor imagery; Journal of Cognitive Neuroscience;  citation_year=2010;  citation_volume=22;  citation_issue=10;  citation_pages=2387-400; " /><meta name="citation_fulltext_world_readable" content="" /><meta name="citation_pdf_url" content="https://academic.oup.com/scan/article-pdf/6/4/404/27106151/nsq050.pdf" /><meta name="description" content="Abstract.  We investigated how visual and linguistic information interact in the perception of emotion. We borrowed a phenomenon from film theory which states t" /><meta name="citation_xml_url" content="https://academic.oup.com/scan/article-xml/6/4/404/1647696" />



    <link rel="canonical" href="https://academic.oup.com/scan/article/6/4/404/1647696" />






    
    


<script async="async" src="https://www.googletagservices.com/tag/js/gpt.js"></script>
<script>
    var googletag = googletag || {};
    googletag.cmd = googletag.cmd || [];
</script>
    
        <script type='text/javascript'>
            var gptAdSlots = [];
            googletag.cmd.push(function() {
                    
                    var mapping_ad1 = googletag.sizeMapping()
                        .addSize([1024, 0], [[970, 90], [728, 90]])
                        .addSize([768, 0], [728, 90])
                        .addSize([0, 0], [320, 50])
                        .build();
                    gptAdSlots["ad1"] = googletag.defineSlot('/116097782/scan_Behind_Ad1',
                            [[970, 90], [728, 90], [320, 50]], 'adBlockHeader')
                        .defineSizeMapping(mapping_ad1)
                        .addService(googletag.pubads());
                    

                    
                    var mapping_ad2 = googletag.sizeMapping()
                        .addSize([768, 0], [[300, 250], [300, 600], [160, 600]])
                        .build();
                    gptAdSlots["ad2"] = googletag.defineSlot('/116097782/scan_Behind_Ad2',
                            [[300, 250], [160, 600], [300, 600]], 'adBlockMainBodyTop')
                        .defineSizeMapping(mapping_ad2)
                        .addService(googletag.pubads());
                    

                    
                    var mapping_ad3 = googletag.sizeMapping()
                        .addSize([768, 0], [[300, 250], [300, 600], [160, 600]])
                        .build();
                    gptAdSlots["ad3"] = googletag.defineSlot('/116097782/scan_Behind_Ad3',
                        [[300, 250], [160, 600], [300, 600]], 'adBlockMainBodyBottom')
                        .defineSizeMapping(mapping_ad3)
                        .addService(googletag.pubads());
                    

                    
                var mapping_ad4 = googletag.sizeMapping()
                        .addSize([0,0], [728, 90])
                        .addSize([768, 0], [728, 90])
                        .build();
                    gptAdSlots["ad4"] = googletag.defineSlot('/116097782/scan_Behind_Ad4',
                        [728, 90], 'adBlockFooter')
                        .defineSizeMapping(mapping_ad4)
                        .addService(googletag.pubads());
                    

                googletag.pubads().addEventListener('slotRenderEnded', function (event) {
;                    if (!event.isEmpty) {
                        $('.js-' + event.slot.getSlotElementId()).each(function () {
                            if ($(this).find('iframe').length) {
                                $(this).removeClass('hide');
                            }
                        });
                    }
                });

                googletag.pubads().setTargeting("jnlspage", "article");
                googletag.pubads().setTargeting("jnlsurl", "scan/article/6/4/404/1647696");
                googletag.pubads().enableSingleRequest();
                googletag.pubads().collapseEmptyDivs();
            });
        </script>
    


    


    



    


    


    


    <script>
        var oupcookiepolicy_siteid = "journals";        // the website id
        var oupcookiepolicy_messagetype = 'implied';                        // type of alert message e.g, implied / explicit
        var oupcookiepolicy_preferredlanguage = "en";      // preferred language of the website
        var oupcookiepolicy_impliedmessageclass = 'cookiepolicyimplied';    // the css class for implied alert message
        var oupcookiepolicy_documentroot = '/';	  			                // the document root the cookie is set to
    </script>
    <noscript>We use cookies to enhance your experience on our website.By continuing to use our website, you are agreeing to our use of cookies. You can change your cookie settings at any time. <a href="https://global.oup.com/cookiepolicy/"> Find out more</a></noscript>
    <script type="text/javascript">
        var NTPT_PGEXTRA= 'event_type=full-text&supplier_tag=SC_Journals&object_type=Article&siteid=scan&authzrequired=false&doi=10.1093/scan/nsq050';
    </script>




    <script src="https://scholar.google.com/scholar_js/casa.js" async></script>


</head>

<body data-sitename="socialcognitiveandaffectiveneuroscience" class="off-canvas pg_Article pg_article  " theme-scan data-sitestyletemplate="Journal" >
    
        <noscript>
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W6DD7HV"
                    height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <a href="#skipNav" class="skipnav">Skip to Main Content</a>
<input id="hdnSiteID" name="hdnSiteID" type="hidden" value="5242" /><input id="hdnAdDelaySeconds" name="hdnAdDelaySeconds" type="hidden" value="5000" /><input id="hdnAdConfigurationTop" name="hdnAdConfigurationTop" type="hidden" value="scrolldelay" /><input id="hdnAdConfigurationRightRail" name="hdnAdConfigurationRightRail" type="hidden" value="sticky" />
    






<div class="master-container js-master-container">
    <section class="master-header row js-master-header vt-site-page-header">
    <div class="widget widget-SitePageHeader widget-instance-SitePageHeader">
        
    <div class="ad-banner js-ad-banner-header">
    <div class="widget widget-AdBlock widget-instance-HeaderAd">
        

<div class="adBlockHeader-wrap js-adBlockHeader hide">
    
    <div id="adBlockHeader"
         style=" ">
        <script>
            googletag.cmd.push(function () { googletag.display('adBlockHeader'); });
        </script>
    </div>
        <div class="advertisement-text">Advertisement</div>
</div> 
    </div>

    </div>

    <div class="oup-header">
        <div class="center-inner-row">
            <div class="oup-header-logo">
                <a href="/">
                    <img src="//oup.silverchair-cdn.com/UI/app/svg/umbrella/oxford-academic-logo.svg" alt="Oxford University Press" class="oup-header-image" />
                </a>
            </div>

            <ul class="oup-header-menu account-menu">

                
                <li class="oup-header-menu-item mobile">
                    <a href="javascript:;" class="mobile-dropdown-toggle mobile-search-toggle">
                        <i class="icon-menu_search"><span class="screenreader-text">Search Menu</span></i>
                    </a>
                </li>

                
                <li class="oup-header-menu-item mobile">
                    <a href="javascript:;" class="mobile-dropdown-toggle mobile-account-toggle">
                        <i class="icon-menu_account"><span class="screenreader-text">Account Menu</span></i>
                    </a>
                </li>

                
                <li class="oup-header-menu-item mobile">
                    <a href="javascript:;" class="mobile-dropdown-toggle mobile-nav-toggle">
                        <i class="icon-menu_hamburger"><span class="screenreader-text">Menu</span></i>
                    </a>
                </li>

                
                <li class="oup-header-menu-item desktop">
                    <a href="" class="dropdown-toggle signin js-header-account-info-user-fullname" id="header-account-info-user-fullname-desktop">
                        
Sign In                        <i class="icon-general-arrow-filled-down arrow-icon"></i>
                    </a>
                    <div class="dropdown-panel dropdown-panel-signin dropdown-panel-form">
                        <div class="spinner"></div>
                    </div>
                </li>

                
                    <li class="oup-header-menu-item desktop"><a href="/my-account/register?siteId=5242&amp;returnUrl=%2fscan%2farticle%2f6%2f4%2f404%2f1647696" class="register">Register</a></li>
                
            </ul>
        </div>
    </div>
<div class="dropdown-panel-wrap">

    
    <div class="dropdown-panel mobile-search-dropdown">
        <div class="mobile-search-inner-wrap">
                <div class="navbar-search">
                    <div id="MobileMicrositeSearch" class="mobile-microsite-search">
                        <label for="mobile-navbar-search-filter" class="screenreader-text">Navbar Search Filter</label>
                        <select class="navbar-search-filter" id="mobile-navbar-search-filter">
                                                            <optgroup label="Search within this journal">
<option class="header-search-bar-filters-item" value="Issue">This issue</option><option class="header-search-bar-filters-item" value="">All  Social Cognitive and Affective Neuroscience</option>
                                </optgroup>
                                <optgroup label="Search beyond this journal">
<option class="header-search-bar-filters-item" value="Journals">All  Journals</option>                                </optgroup>
                        </select>





                        <label for="MobileMicrositeSearchTerm" class="screenreader-text">Mobile Microsite Search Term</label>
                        <input class="mobile-search-input mobile-microsite-search-term" type="text" maxlength="255" placeholder="Search" id="MobileMicrositeSearchTerm">

                        <a href="javascript:;" id="MobileMicrositeSearchIcon" class="mobile-microsite-search-icon mobile-search-submit icon-menu_search"><span class="screenreader-text">Search</span></a>

                    </div>
                </div>        </div>
    </div>
    
    <div class="dropdown-panel mobile-account-dropdown">
        <ul class="site-menu site-menu-lvl-0">
            <li class="site-menu-item site-menu-lvl-0">
                <a href="" class="nav-link mobile-account-signin dummy-link js-header-account-info-user-fullname" id="header-account-info-user-fullname-mobile">
                    
Sign In                    <i class="mobile-nav-arrow icon-general_arrow-down"></i>
                </a>
                <ul class="site-menu site-menu-lvl-1 individual-menu">
                    <li class="dropdown-signin-form">
                        <div class="spinner"></div>
                    </li>
                </ul>
            </li>
                            <li class="site-menu-item">
                    <a href="/my-account/register?siteId=5242&amp;returnUrl=%2fscan%2farticle%2f6%2f4%2f404%2f1647696" class="register nav-link">Register</a>
                </li>
        </ul>
    </div>
    
    <div class="dropdown-panel mobile-nav-dropdown">


    <i class="desktop-nav-arrow icon-general-arrow-filled-down arrow-icon"></i><i class="mobile-nav-arrow icon-general_arrow-down"></i>
    <ul class="site-menu site-menu-lvl-0">
            <li class="site-menu-item site-menu-lvl-0" id="site-menu-item-1442900">
                <a href="/scan/issue" class="nav-link ">Issues</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-0" id="site-menu-item-1442901">
                <a href="/scan/advance-articles" class="nav-link ">Advance articles</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-0" id="site-menu-item-1442898">
                <a href="/scan/#" class="nav-link dummy-link">Submit</a>
                    <i class="desktop-nav-arrow icon-general-arrow-filled-down arrow-icon"></i><i class="mobile-nav-arrow icon-general_arrow-down"></i>
    <ul class="site-menu site-menu-lvl-1">
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442902">
                <a href="/scan/pages/General_Instructions" class="nav-link ">Author Guidelines</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442903">
                <a href="https://mc.manuscriptcentral.com/scan" class="nav-link ">Submission Site</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442904">
                <a href="/scan/pages/General_Instructions" class="nav-link ">Open Access</a>
                
            </li>
    </ul>

            </li>
            <li class="site-menu-item site-menu-lvl-0" id="site-menu-item-1442905">
                <a href="/my-account/email-alerts" class="nav-link ">Alerts</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-0" id="site-menu-item-1442899">
                <a href="/scan/#" class="nav-link dummy-link">About</a>
                    <i class="desktop-nav-arrow icon-general-arrow-filled-down arrow-icon"></i><i class="mobile-nav-arrow icon-general_arrow-down"></i>
    <ul class="site-menu site-menu-lvl-1">
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442906">
                <a href="/scan/pages/About" class="nav-link ">About SCAN</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442907">
                <a href="/scan/pages/Editorial_Board" class="nav-link ">Editorial Board</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442908">
                <a href="http://www.oupmediainfo.com/" class="nav-link ">Advertising and Corporate Services</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442909">
                <a href="http://science-and-mathematics-careernetwork.oxfordjournals.org" class="nav-link ">Journals Career Network</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442910">
                <a href="https://academic.oup.com/journals/pages/access_purchase/rights_and_permissions/self_archiving_policy_c" class="nav-link ">Self-Archiving Policy</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442911">
                <a href="/scan/pages/Terms_and_Conditions" class="nav-link ">Terms and Conditions</a>
                
            </li>
    </ul>

            </li>
    </ul>
    </div>

</div>


    <div class="journal-header journal-bg">
        <div class="center-inner-row">
                            <a href="/scan" class="journal-logo-container">
                    <img id="logo-SocialCognitiveandAffectiveNeuroscience" class="journal-logo" src="//oup.silverchair-cdn.com/data/SiteBuilderAssets/Live/Images/scan/scan_title-2085137642.svg" alt="Social Cognitive and Affective Neuroscience" />
                </a>

            <div class="society-logo-block">
            </div> 
        </div>
    </div>
<div class="navbar">
    <div class="center-inner-row">
        <nav class="navbar-menu">


    <i class="desktop-nav-arrow icon-general-arrow-filled-down arrow-icon"></i><i class="mobile-nav-arrow icon-general_arrow-down"></i>
    <ul class="site-menu site-menu-lvl-0">
            <li class="site-menu-item site-menu-lvl-0" id="site-menu-item-1442900">
                <a href="/scan/issue" class="nav-link ">Issues</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-0" id="site-menu-item-1442901">
                <a href="/scan/advance-articles" class="nav-link ">Advance articles</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-0" id="site-menu-item-1442898">
                <a href="/scan/#" class="nav-link dummy-link">Submit</a>
                    <i class="desktop-nav-arrow icon-general-arrow-filled-down arrow-icon"></i><i class="mobile-nav-arrow icon-general_arrow-down"></i>
    <ul class="site-menu site-menu-lvl-1">
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442902">
                <a href="/scan/pages/General_Instructions" class="nav-link ">Author Guidelines</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442903">
                <a href="https://mc.manuscriptcentral.com/scan" class="nav-link ">Submission Site</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442904">
                <a href="/scan/pages/General_Instructions" class="nav-link ">Open Access</a>
                
            </li>
    </ul>

            </li>
            <li class="site-menu-item site-menu-lvl-0" id="site-menu-item-1442905">
                <a href="/my-account/email-alerts" class="nav-link ">Alerts</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-0" id="site-menu-item-1442899">
                <a href="/scan/#" class="nav-link dummy-link">About</a>
                    <i class="desktop-nav-arrow icon-general-arrow-filled-down arrow-icon"></i><i class="mobile-nav-arrow icon-general_arrow-down"></i>
    <ul class="site-menu site-menu-lvl-1">
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442906">
                <a href="/scan/pages/About" class="nav-link ">About SCAN</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442907">
                <a href="/scan/pages/Editorial_Board" class="nav-link ">Editorial Board</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442908">
                <a href="http://www.oupmediainfo.com/" class="nav-link ">Advertising and Corporate Services</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442909">
                <a href="http://science-and-mathematics-careernetwork.oxfordjournals.org" class="nav-link ">Journals Career Network</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442910">
                <a href="https://academic.oup.com/journals/pages/access_purchase/rights_and_permissions/self_archiving_policy_c" class="nav-link ">Self-Archiving Policy</a>
                
            </li>
            <li class="site-menu-item site-menu-lvl-1" id="site-menu-item-1442911">
                <a href="/scan/pages/Terms_and_Conditions" class="nav-link ">Terms and Conditions</a>
                
            </li>
    </ul>

            </li>
    </ul>
        </nav>
            <div class="navbar-search-container js-navbar-search-container">
                <a href="javascript:;" class="navbar-search-close js_close-navsearch">Close</a>
                    <div class="navbar-search">
                        <div id="MicrositeSearch" class="microsite-search">
                            <label for="navbar-search-filter" class="screenreader-text">search filter</label>
                            <select class="navbar-search-filter" id="navbar-search-filter">
                                                                    <optgroup label="Search within this journal">
                                                <option class="header-search-bar-filters-item" value="Issue" >This issue</option>
                                                <option class="header-search-bar-filters-item" value="" selected=&quot;selected&quot;>All  Social Cognitive and Affective Neuroscience</option>

                                    </optgroup>
                                    <optgroup label="Search beyond this journal">
                                                <option class="header-search-bar-filters-item" value="Journals" >All  Journals</option>
                                    </optgroup>
                            </select>

                            <label for="MicrositeSearchTerm" class="screenreader-text">search input</label>
                            <input class="navbar-search-input microsite-search-term" type="text" maxlength="255" id="MicrositeSearchTerm" title="search input">

                            <a href="javascript:;" id="MicrositeSearchIcon" class="microsite-search-icon navbar-search-submit icon-menu_search"><span class="screenreader-text">Search</span></a>

                        </div>
                    </div>                <div class="navbar-search-advanced"><a href="/scan/advanced-search" class="advanced-search js-advanced-search">Advanced Search</a></div>
            </div>            <div class="navbar-search-collapsed"><a href="javascript:;" class="icon-menu_search js_expand-navsearch"><span class="screenreader-text">Search Menu</span></a></div>
    </div>
</div>

<input id="hfEnableOupOnlineProductsFeatures" name="hfEnableOupOnlineProductsFeatures" type="hidden" value="False" />

    <input type="hidden" name="searchScope" id="hfSolrJournalID" value="" />
    <input type="hidden" id="hfSolrJournalName" value="" />
    <input type="hidden" id="hfSolrMaxAllowSearchChar" value="100" />
    <input type="hidden" id="hfJournalShortName" value="" />
    <input type="hidden" id="hfSearchPlaceholder" value="" />
    <input type="hidden" name="hfGlobalSearchSiteURL" id="hfGlobalSearchSiteURL" value="" />
        <input type="hidden" name="parentSiteName" id="hfParentSiteName" value="Journals" />
        <input type="hidden" name="parentSiteUrl" id="hfParentSiteUrl" value="academic.oup.com/journals" />
        <input type="hidden" name="siteID" id="hfSiteID" value="5242" />
        <input type="hidden" name="parentSiteID" id="hfParentSiteID" value="5567" />
        <input type="hidden" name="journalSiteScope" id="hfJournalSiteScope" value="Journals" />
        <input type="hidden" name="parentSiteScope" id="hfParentSiteScope" value="Parent" />
        <input type="hidden" name="defaultSearchURL" id="hfDefaultSearchURL" value="search-results?page=1&amp;q=" />
        <input type="hidden" name="issueSearch" id="hfIssueSearch" value="&amp;fl_IssueID=65617" />
        <input type="hidden" name="issueSiteScope" id="hfIssueSiteScope" value="Issue" />
<input id="hfDefaultAdvancedSearchUrl" name="hfDefaultAdvancedSearchUrl" type="hidden" value="advanced-search?page=1&amp;q=" />    <input type="hidden" name="hfSearchSiteURL" id="hfSiteURL" value="academic.oup.com/scan" />
    <script type="text/javascript">
        (function () {
            var hfSiteUrl = document.getElementById('hfSiteURL');
            var siteUrl = hfSiteUrl.value;
            var subdomainIndex = siteUrl.indexOf('/');

            hfSiteUrl.value = location.host + (subdomainIndex >= 0 ? siteUrl.substring(subdomainIndex) : '');
        })();
    </script>
<input id="routename" name="RouteName" type="hidden" value="scan" /> 
    </div>

</section>

    <div id="main" class="content-main js-main ui-base">
        <section class="master-main row">
            <div class="center-inner-row no-overflow">
                <a href="#" id="skipNav" tabindex="-1"></a>
                


<div class="page-column-wrap">
<div id="InfoColumn" class="page-column page-column--left js-left-nav-col">
    <div class="mobile-content-topbar hide">
        <button class="toggle-left-col toggle-left-col__article">Article Navigation</button>
    </div>
    <div class="info-inner-wrap js-left-nav">
        <button class="toggle-left-col__close btn-as-icon icon-general-close">
            <span class="screenreader-text">Close mobile search navigation</span>
        </button>
        <div class="responsive-nav-title">Article Navigation</div>
        <div class="info-widget-wrap">
    <div class="widget widget-IssueInfo widget-instance-OUP_IssueInfo_Article">
        

<div id="issueInfo-OUP_IssueInfo_Article" class="article-info-wrap clearfix">
    <i class="icon-general-close mobile-nav-btn nav-open"></i>
    <div class="article-issue-img">
            <a href="/scan/issue/6/4"><img id="issueImage" class="fb-featured-image" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/Issue/6/4/0/m_scan6_4.cover.gif?Expires=1606171022&amp;Signature=hw8hkO8rkRdbecBE4Oyr~q6apXeekDm0Ak~MyUJx0nIDLeaTWl2qFA0-cm89eqSAKp-bWCG7HG~XJsA4YT2sOUytOtsyWmC0C04zmgGCVUW2jzfzOFZIsO1ohgsf9BUWqgTAXbwPUcn2ZYoG9oK0UF~1jCgHr1Vdq-exWP18stCdKMUmI-i7BmZ8MY1jVLUofwk2mQukn0iwp-Epma5Wgjc-EYruq8T4F2JN6Dy5Bu6hUY68m7u33K-WduGYBuMcRE7C8dhEuQ-W27WmnkFiLE0vdh~egqAfGnCo-2zLtDTIYdi7g0V1ss20eVjzI2p5tUQBwWgYrrCdHtGsEwg3TQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Issue Cover" /></a>
    </div>
    <div class="article-issue-info">
        <div class="volume-issue__wrap">

            <a href="/scan/issue/6/4">
                        <div class="volume trailing-comma">Volume 6</div>
                        <div class="issue">Issue 4</div>

            </a>

        </div>
        <div class="ii-pub-date">
September 2011        </div>
        
    </div>

</div> 
    </div>

            <div class="content-nav">
    <div class="widget widget-ArticleJumpLinks widget-instance-OUP_ArticleJumpLinks_Widget">
        

<h3 class="contents-title" >Article Contents</h3>
<ul class="jumplink-list">
        <li class="section-jump-link head-1" link-destination="126925805">
            <div class="section-jump-link__link-wrap">

                <a class="js-jumplink scrollTo" href="#126925805">Abstract</a>
            </div>
        </li>
        <li class="section-jump-link head-1" link-destination="126925807">
            <div class="section-jump-link__link-wrap">

                <a class="js-jumplink scrollTo" href="#126925807">INTRODUCTION</a>
            </div>
        </li>
        <li class="section-jump-link head-1" link-destination="126925817">
            <div class="section-jump-link__link-wrap">

                <a class="js-jumplink scrollTo" href="#126925817">METHODS</a>
            </div>
        </li>
        <li class="section-jump-link head-1" link-destination="126925838">
            <div class="section-jump-link__link-wrap">

                <a class="js-jumplink scrollTo" href="#126925838">RESULTS</a>
            </div>
        </li>
        <li class="section-jump-link head-1" link-destination="126925859">
            <div class="section-jump-link__link-wrap">

                <a class="js-jumplink scrollTo" href="#126925859">DISCUSSION</a>
            </div>
        </li>
        <li class="section-jump-link head-1" link-destination="126925875">
            <div class="section-jump-link__link-wrap">

                <a class="js-jumplink scrollTo" href="#126925875">CONCLUSION</a>
            </div>
        </li>
        <li class="section-jump-link head-1 backReferenceLink" link-destination="126925879">
            <div class="section-jump-link__link-wrap">

                <a class="js-jumplink scrollTo" href="#126925879">REFERENCES</a>
            </div>
        </li>
</ul>
 
    </div>

            </div>
    <div class="widget widget-ArticleNavLinks widget-instance-OUP_ArticleNavLinks_Article">
        <ul class="inline-list">
        <li class="prev arrow">
            <a href="/scan/article/6/4/393/1649259">&lt; Previous</a>
        </li>        
            <li class="next arrow">
            <a href="/scan/article/6/4/417/1647238">Next &gt;</a>
        </li>
</ul> 
    </div>

        </div>
    </div>
</div>
<div class="sticky-toolbar js-sticky-toolbar"></div>
<div id="ContentColumn" class="page-column page-column--center">
    <div class="article-browse-top article-browse-mobile-nav js-mobile-nav">
        <div class="article-browse-mobile-nav-inner js-mobile-nav-inner">
            <button class="toggle-left-col toggle-left-col__article btn-as-link">
                Article Navigation
            </button>
        </div>
    </div>
    <div class="content-inner-wrap">
    <div class="widget widget-ArticleTopInfo widget-instance-OUP_ArticleTop_Info_Widget">
        <div class="module-widget article-top-widget">

    

    
        <div class="access-state-logos all-viewports">
                    </div>


    <div class="widget-items">
                <h1 class="wi-article-title article-title-main">
                    Add a picture for suspense: neural correlates of the interaction between language and visual information in the perception of fear
<i class='icon-availability_open' title='Open Access' ></i>                </h1>
                <div class="wi-authors">
                    <div class="al-authors-list">
                                <span class="al-author-name-more js-flyout-wrap">




                                    <a class="linked-name js-linked-name-trigger" href="javascript:;">Roel M. Willems</a><span class='delimiter'>, </span>

                                    <span class="al-author-info-wrap arrow-up">
<div id="authorInfo_OUP_ArticleTop_Info_Widget" class="info-card-author authorInfo_OUP_ArticleTop_Info_Widget">
    <div class="name-role-wrap">
        <div class="info-card-name">
    Roel M. Willems
</div>

    </div>

    <div class="info-card-affilitation">
        <div class="aff"><span class="label"><sup>1</sup></span>Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, PO Box 9101, 6500 HB Nijmegen, The Netherlands, <sup>2</sup>Helen Wills Neuroscience Institute, University of California Berkeley, 132 Barker Hall, Berkeley, CA 94720-3190, USA, <sup>3</sup>PhD Arts, Academy of the Arts, Humanities Faculty, Leiden University, Rapenburg 38, 2311 EX Leiden, The Netherlands, <sup>4</sup>IVOK, Leuven University, Schapenstraat 34, 3000 Leuven, Belgium, and <sup>5</sup>Max Planck Institute for Psycholinguistics, Wundtlaan 1, 6525 XD Nijmegen, The Netherlands</div>
    </div>

    <div class="info-card-search-label">
        Search for other works by this author on:
    </div>

<div class="info-card-search info-card-search-internal">
    <a href="/scan/search-results?f_Authors=Roel+M.+Willems">Oxford Academic</a>
</div>

    <div class="info-card-search info-card-search-pubmed">
        <a href="http://www.ncbi.nlm.nih.gov/pubmed?cmd=search&amp;term=Willems R">PubMed</a>
    </div>
    <div class="info-card-search info-card-search-google">
        <a href="http://scholar.google.com/scholar?q=author:%22Willems Roel M.%22">Google Scholar</a>
    </div>
</div>                                    </span>
                                </span>
                                <span class="al-author-name-more js-flyout-wrap">




                                    <a class="linked-name js-linked-name-trigger" href="javascript:;">Krien Clevis</a><span class='delimiter'>, </span>

                                    <span class="al-author-info-wrap arrow-up">
<div id="authorInfo_OUP_ArticleTop_Info_Widget" class="info-card-author authorInfo_OUP_ArticleTop_Info_Widget">
    <div class="name-role-wrap">
        <div class="info-card-name">
    Krien Clevis
</div>

    </div>

    <div class="info-card-affilitation">
        <div class="aff"><span class="label"><sup>1</sup></span>Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, PO Box 9101, 6500 HB Nijmegen, The Netherlands, <sup>2</sup>Helen Wills Neuroscience Institute, University of California Berkeley, 132 Barker Hall, Berkeley, CA 94720-3190, USA, <sup>3</sup>PhD Arts, Academy of the Arts, Humanities Faculty, Leiden University, Rapenburg 38, 2311 EX Leiden, The Netherlands, <sup>4</sup>IVOK, Leuven University, Schapenstraat 34, 3000 Leuven, Belgium, and <sup>5</sup>Max Planck Institute for Psycholinguistics, Wundtlaan 1, 6525 XD Nijmegen, The Netherlands</div>
    </div>

    <div class="info-card-search-label">
        Search for other works by this author on:
    </div>

<div class="info-card-search info-card-search-internal">
    <a href="/scan/search-results?f_Authors=Krien+Clevis">Oxford Academic</a>
</div>

    <div class="info-card-search info-card-search-pubmed">
        <a href="http://www.ncbi.nlm.nih.gov/pubmed?cmd=search&amp;term=Clevis K">PubMed</a>
    </div>
    <div class="info-card-search info-card-search-google">
        <a href="http://scholar.google.com/scholar?q=author:%22Clevis Krien%22">Google Scholar</a>
    </div>
</div>                                    </span>
                                </span>
                                <span class="al-author-name-more js-flyout-wrap">




                                    <a class="linked-name js-linked-name-trigger" href="javascript:;">Peter Hagoort</a><span class='delimiter'></span>

                                    <span class="al-author-info-wrap arrow-up">
<div id="authorInfo_OUP_ArticleTop_Info_Widget" class="info-card-author authorInfo_OUP_ArticleTop_Info_Widget">
    <div class="name-role-wrap">
        <div class="info-card-name">
    Peter Hagoort
</div>

    </div>

    <div class="info-card-affilitation">
        <div class="aff"><span class="label"><sup>1</sup></span>Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, PO Box 9101, 6500 HB Nijmegen, The Netherlands, <sup>2</sup>Helen Wills Neuroscience Institute, University of California Berkeley, 132 Barker Hall, Berkeley, CA 94720-3190, USA, <sup>3</sup>PhD Arts, Academy of the Arts, Humanities Faculty, Leiden University, Rapenburg 38, 2311 EX Leiden, The Netherlands, <sup>4</sup>IVOK, Leuven University, Schapenstraat 34, 3000 Leuven, Belgium, and <sup>5</sup>Max Planck Institute for Psycholinguistics, Wundtlaan 1, 6525 XD Nijmegen, The Netherlands</div>
    </div>

    <div class="info-card-search-label">
        Search for other works by this author on:
    </div>

<div class="info-card-search info-card-search-internal">
    <a href="/scan/search-results?f_Authors=Peter+Hagoort">Oxford Academic</a>
</div>

    <div class="info-card-search info-card-search-pubmed">
        <a href="http://www.ncbi.nlm.nih.gov/pubmed?cmd=search&amp;term=Hagoort P">PubMed</a>
    </div>
    <div class="info-card-search info-card-search-google">
        <a href="http://scholar.google.com/scholar?q=author:%22Hagoort Peter%22">Google Scholar</a>
    </div>
</div>                                    </span>
                                </span>

                    </div>
                </div>
<div class="pub-history-wrap clearfix">

        <div class="pub-history-row clearfix">
            <div class="ww-citation-primary"><em>Social Cognitive and Affective Neuroscience</em>, Volume 6, Issue 4, September 2011, Pages 404–416, <a href='https://doi.org/10.1093/scan/nsq050'>https://doi.org/10.1093/scan/nsq050</a></div>
        </div>
        <div class="pub-history-row clearfix">
            <div class="ww-citation-date-wrap">
                <div class="citation-label">Published:</div>
                <div class="citation-date">08 June 2010</div>
            </div>
                <a href="javascript:;" class="ww-citation-history-wrap js-article-history st-article-history">
                    <span>Article history</span><i class="icon-general-arrow-filled-down arrow-icon"></i>
                </a>
        </div>
            <div class="history-entries-wrap js-history-entries-wrap">
                <div class="history-entry">
                    <div class="wi-state">Received:</div>
                    <div class="wi-date">01 March 2010</div>
                </div>
                <div class="history-entry">
                    <div class="wi-state">Accepted:</div>
                    <div class="wi-date">11 May 2010</div>
                </div>
                <div class="history-entry">
                    <div class="wi-state">Published:</div>
                    <div class="wi-date">08 June 2010</div>
                </div>
        </div>
</div>
    </div>
</div>

<script>
    $(document).ready(function () {
        $('.article-top-widget').on('click', '.ati-toggle-trigger', function () {
            $(this).find('.icon-general-add, .icon-minus').toggleClass('icon-minus icon-general-add');
            $(this).siblings('.ati-toggle-content').toggleClass('hide');
        });

        // In Chrome, an anchor tag with target="_blank" and a "mailto:" href opens a new tab/window as well as the email client
        // I suspect this behavior will be corrected in the future
        // Remove the target="_blank"
        $('ul.wi-affiliationList').find('a[href^="mailto:"]').each(function () {
            $(this).removeAttr('target');
        });
    });
</script>

 
    </div>
    <div class="widget widget-ArticleLinks widget-instance-OUP_Article_Links_Widget">
         
    </div>


        <div class="article-body js-content-body">
            <div class="toolbar-wrap js-toolbar-wrap">
                <div class="toolbar-inner-wrap">
                    <ul id="Toolbar" role="navigation">
    <li class="toolbar-item item-pdf">
        <a class="al-link pdf article-pdfLink" data-article-id="1647696" href="/scan/article-pdf/6/4/404/27106151/nsq050.pdf">
            <img src=//oup.silverchair-cdn.com/UI/app/svg/pdf.svg alt="pdf" /><span class="pdf-link-text">PDF</span>
        </a>
    </li>
                                                    <li class="toolbar-item item-link item-split-view">
                                <a href="javascript:;"
                                   class="split-view js-split-view st-split-view"
                                   target="">
                                    <i class="icon-menu_split"></i>
                                    Split View
                                </a>
                            </li>
                        <li class="toolbar-item item-with-dropdown item-views">
                            <a class="at-views-dropdown drop-trigger" href="javascript:;" data-dropdown="FilterDrop" aria-haspopup="true">
                                <i class="icon-menu_views"></i>
                                <div class="toolbar-label">
                                    <div class="toolbar-text">Views</div>
                                    <i class="icon-general-arrow-filled-down arrow-icon"></i>
                                </div>
                            </a>
                            <ul id="ViewsDrop" class="f-dropdown" data-dropdown-content aria-label="submenu">
                                <div class="arrow-up"></div>
                                <li class="article-content-filter js-article-content-filter" data-content-filter="article-content">
                                    <a href="javascript:;"><span>Article contents</span></a>
                                </li>
                                <li class="at-figures-tables article-content-filter js-article-content-filter" data-content-filter="figures-tables">
                                    <a href="javascript:;"><span>Figures &amp; tables</span></a>
                                </li>
                                <li class="article-content-filter js-article-content-filter" data-content-filter="video">
                                    <a href="javascript:;"><span>Video</span></a>
                                </li>
                                <li class="article-content-filter js-article-content-filter" data-content-filter="audio">
                                    <a href="javascript:;"><span>Audio</span></a>
                                </li>
                                <li class="article-content-filter js-article-content-filter" data-content-filter="supplementary-data">
                                    <a href="javascript:;"><span>Supplementary Data</span></a>
                                </li>
                            </ul>
                        </li>
                        <li class="toolbar-item">
    <div class="widget widget-ToolboxGetCitation widget-instance-OUP_Get_Citation">
        <a href="#" class="js-cite-button" data-reveal-id="getCitation" data-reveal><i class="icon-read-more"></i><span>Cite</span></a>

<div id="getCitation" class="reveal-modal" data-reveal>
    <h3 class="modal-title">Cite</h3>
        <div class="oxford-citation-text">
            <p>Roel M. Willems, Krien Clevis, Peter Hagoort,  Add a picture for suspense: neural correlates of the interaction between language and visual information in the perception of fear, <em>Social Cognitive and Affective Neuroscience</em>, Volume 6, Issue 4, September 2011, Pages 404–416, <a href="https://doi.org/10.1093/scan/nsq050">https://doi.org/10.1093/scan/nsq050</a></p>
        </div>

    <div class="citation-download-wrap">
        <form action="/Citation/Download" method="get" id="citationModal">
            <input type="hidden" name="resourceId" value="1647696" />
            <input type="hidden" name="resourceType" value="3" />
            <label for="selectFormat" class="hide">Select Format</label>
            <select required name="citationFormat" class="citation-download-format" id="selectFormat">
                <option selected disabled >Select format</option>
                        <option value="0" >.ris (Mendeley, Papers, Zotero)</option>
                        <option value="1" >.enw (EndNote)</option>
                        <option value="2" >.bibtex (BibTex)</option>
                        <option value="3" >.txt (Medlars, RefWorks)</option>

            </select>
            <button class="btn citation-download-link disabled" type="submit">Download citation</button>
        </form>
    </div>

    <a class="close-reveal-modal" href="javascript:;"><i class="icon-general-close"></i><span class="screenreader-text">Close</span></a>
</div>
 
    </div>

                        </li>
                        <li class="toolbar-item item-tools">
    <div class="widget widget-ToolboxPermissions widget-instance-">
            <div class="module-widget">
        <a href="https://s100.copyright.com/AppDispatchServlet?publisherName=OUP&amp;publication=1749-5024&amp;title=Add%20a%20picture%20for%20suspense%3A%20neural%20correlates%20of%20the%20interaction%20between%20language%20and%20visual%20information%20in%20the%20perception%20of%20fear&amp;publicationDate=2010-06-08&amp;volumeNum=6&amp;issueNum=4&amp;author=Willems%2C%20Roel%20M.%3B%20Clevis%2C%20Krien&amp;startPage=404&amp;endPage=416&amp;contentId=10.1093%2Fscan%2Fnsq050&amp;oa=CC%20BY-NC&amp;copyright=Oxford%20University%20Press&amp;orderBeanReset=True" id="PermissionsLink" class="" target="_blank">
            <i class="icon-menu_permissions">
                <span class="screenreader-text">Permissions Icon</span>
            </i>
            Permissions
        </a>
    </div>
 
    </div>

                        </li>
                        <li class="toolbar-item item-with-dropdown item-share last">
                            <a class="drop-trigger" href="javascript:;" data-dropdown="ShareDrop" aria-haspopup="true">
                                <i class="icon-menu_share"></i>
                                <div class="toolbar-label">
                                    <div class="toolbar-text">Share</div>
                                    <i class="icon-general-arrow-filled-down arrow-icon"></i>
                                </div>
                            </a>
                            <ul id="ShareDrop" class="addthis_toolbox addthis_default_style addthis_20x20_style f-dropdown" data-dropdown-content aria-label="submenu">
                                <div class="arrow-up"></div>
                                <li><a class="addthis_button_email"><span>Email</span></a></li>
                                <li><a class="addthis_button_twitter"><span>Twitter</span></a></li>
                                <li><a class="addthis_button_facebook"><span>Facebook</span></a></li>
                                <li><a class="addthis_button_compact"><span>More</span></a></li>
                            </ul>
                        </li>
                    </ul>
                    <div class="toolbar-search">
    <div class="widget widget-SitePageHeader widget-instance-OUP_ArticleToolbarSearchBox">
        


<div class="dropdown-panel-wrap">

    
    <div class="dropdown-panel mobile-search-dropdown">
        <div class="mobile-search-inner-wrap">
                <div class="navbar-search">
                    <div id="MobileMicrositeSearch" class="mobile-microsite-search">
                        <label for="mobile-navbar-search-filter" class="screenreader-text">Navbar Search Filter</label>
                        <select class="navbar-search-filter" id="mobile-navbar-search-filter">
                                                            <optgroup label="Search within this journal">
<option class="header-search-bar-filters-item" value="Issue">This issue</option><option class="header-search-bar-filters-item" value="">All  Social Cognitive and Affective Neuroscience</option>
                                </optgroup>
                                <optgroup label="Search beyond this journal">
<option class="header-search-bar-filters-item" value="Journals">All  Journals</option>                                </optgroup>
                        </select>





                        <label for="MobileMicrositeSearchTerm" class="screenreader-text">Mobile Microsite Search Term</label>
                        <input class="mobile-search-input mobile-microsite-search-term" type="text" maxlength="255" placeholder="Search" id="MobileMicrositeSearchTerm">

                        <a href="javascript:;" id="MobileMicrositeSearchIcon" class="mobile-microsite-search-icon mobile-search-submit icon-menu_search"><span class="screenreader-text">Search</span></a>

                    </div>
                </div>        </div>
    </div>
    
    <div class="dropdown-panel mobile-account-dropdown">
        <ul class="site-menu site-menu-lvl-0">
            <li class="site-menu-item site-menu-lvl-0">
                <a href="" class="nav-link mobile-account-signin dummy-link js-header-account-info-user-fullname" id="header-account-info-user-fullname-mobile">
                    
Sign In                    <i class="mobile-nav-arrow icon-general_arrow-down"></i>
                </a>
                <ul class="site-menu site-menu-lvl-1 individual-menu">
                    <li class="dropdown-signin-form">
                        <div class="spinner"></div>
                    </li>
                </ul>
            </li>
                            <li class="site-menu-item">
                    <a href="/my-account/register?siteId=5242&amp;returnUrl=%2fscan%2farticle%2f6%2f4%2f404%2f1647696" class="register nav-link">Register</a>
                </li>
        </ul>
    </div>
    
    <div class="dropdown-panel mobile-nav-dropdown">

    </div>

</div>



<div class="navbar">
    <div class="center-inner-row">
        <nav class="navbar-menu">

        </nav>
            <div class="navbar-search-container js-navbar-search-container">
                <a href="javascript:;" class="navbar-search-close js_close-navsearch">Close</a>
                    <div class="navbar-search">
                        <div id="MicrositeSearch" class="microsite-search">
                            <label for="navbar-search-filter" class="screenreader-text">search filter</label>
                            <select class="navbar-search-filter" id="navbar-search-filter">
                                                                    <optgroup label="Search within this journal">
                                                <option class="header-search-bar-filters-item" value="Issue" >This issue</option>
                                                <option class="header-search-bar-filters-item" value="" selected=&quot;selected&quot;>All  Social Cognitive and Affective Neuroscience</option>

                                    </optgroup>
                                    <optgroup label="Search beyond this journal">
                                                <option class="header-search-bar-filters-item" value="Journals" >All  Journals</option>
                                    </optgroup>
                            </select>

                            <label for="MicrositeSearchTerm" class="screenreader-text">search input</label>
                            <input class="navbar-search-input microsite-search-term" type="text" maxlength="255" id="MicrositeSearchTerm" title="search input">

                            <a href="javascript:;" id="MicrositeSearchIcon" class="microsite-search-icon navbar-search-submit icon-menu_search"><span class="screenreader-text">Search</span></a>

                        </div>
                    </div>                <div class="navbar-search-advanced"><a href="/scan/advanced-search" class="advanced-search js-advanced-search">Advanced Search</a></div>
            </div>            <div class="navbar-search-collapsed"><a href="javascript:;" class="icon-menu_search js_expand-navsearch"><span class="screenreader-text">Search Menu</span></a></div>
    </div>
</div>

<input id="hfEnableOupOnlineProductsFeatures" name="hfEnableOupOnlineProductsFeatures" type="hidden" value="False" />

<input id="routename" name="RouteName" type="hidden" value="scan" /> 
    </div>

                    </div>
                </div>
            </div>
            <div id="ContentTab" class="content active">
    <div class="widget widget-ArticleFulltext widget-instance-OUP_Article_FullText_Widget">
        <div class="module-widget">
    <div class="widget-items" data-widgetname="ArticleFulltext">





                    <h2 scrollto-destination=126925805 id="126925805" class="abstract-title" >Abstract</h2>
<section class="abstract"><p class="chapter-para">We investigated how visual and linguistic information interact in the perception of emotion. We borrowed a phenomenon from film theory which states that presentation of an as such neutral visual scene intensifies the percept of fear or suspense induced by a different channel of information, such as language. Our main aim was to investigate how neutral visual scenes can enhance responses to fearful language content in parts of the brain involved in the perception of emotion. Healthy participants’ brain activity was measured (using functional magnetic resonance imaging) while they read fearful and less fearful sentences presented with or without a neutral visual scene. The main idea is that the visual scenes intensify the fearful content of the language by subtly implying and concretizing what is described in the sentence. Activation levels in the right anterior temporal pole were selectively increased when a neutral visual scene was paired with a fearful sentence, compared to reading the sentence alone, as well as to reading of non-fearful sentences presented with the same neutral scene. We conclude that the right anterior temporal pole serves a binding function of emotional information across domains such as visual and linguistic information.</p></section>                        <div class="article-metadata-panel clearfix"></div>
<div class="kwd-group"><a class="kwd-part kwd-main" href="javascript:;" data-keyword="language">language</a>, <a class="kwd-part kwd-main" href="javascript:;" data-keyword="emotion">emotion</a>, <a class="kwd-part kwd-main" href="javascript:;" data-keyword="&quot;film theory&quot;">film theory</a>, <a class="kwd-part kwd-main" href="javascript:;" data-keyword="fMRI">fMRI</a>, <a class="kwd-part kwd-main" href="javascript:;" data-keyword="scenes">scenes</a>, <a class="kwd-part kwd-main" href="javascript:;" data-keyword="&quot;temporal pole&quot;">temporal pole</a></div>                    <h2 scrollto-destination=126925807 id="126925807" class="section-title" >INTRODUCTION</h2>
<p class="chapter-para">It is relatively well known how emotionally laden stimuli such as fearful or threatening faces activate parts of the neural circuitry involved in emotion perception (e.g. <span class="xrefLink" id="jumplink-B33"></span><a href="javascript:;" reveal-id="B33" data-open="B33" class="link link-ref link-reveal xref-bibr">Pessoa and Ungerleider, 2004</a>; <span class="xrefLink" id="jumplink-B9"></span><a href="javascript:;" reveal-id="B9" data-open="B9" class="link link-ref link-reveal xref-bibr">de Gelder, 2006</a>; <span class="xrefLink" id="jumplink-B1"></span><a href="javascript:;" reveal-id="B1" data-open="B1" class="link link-ref link-reveal xref-bibr">Adolphs, 2008</a>). Also reading emotionally relevant words leads to activation of parts of the emotional circuitry in the brain. For instance <span class="xrefLink" id="jumplink-B21"></span><a href="javascript:;" reveal-id="B21" data-open="B21" class="link link-ref link-reveal xref-bibr">Isenberg and colleagues (1999)</a> showed increased activation levels in the amygdala bilaterally when healthy participants read fearful words (e.g. ‘death’, ‘threat’, ‘suffocate’) as compared to more neutral words (e.g. ‘desk’, ‘sweater’, ‘consider’) (see also <span class="xrefLink" id="jumplink-B19"></span><a href="javascript:;" reveal-id="B19" data-open="B19" class="link link-ref link-reveal xref-bibr">Herbert <em>et al.</em>, 2009</a>). In the present study we investigate how linguistic and visual information interact in influencing emotion perception in the brain. To this end we used a phenomenon from film theory which implies that the presence of a neutral visual scene intensifies the percept of fear or suspense induced by a different channel of information (such as language, we elaborate on this below). So instead of focusing on the perception of emotion in linguistic or visual stimuli per se, we investigate how visual and linguistic information interact in the perception of emotion, more specifically the perception of fear.</p><p class="chapter-para">We borrow a phenomenon from film theory which describes how pairing a fearful context with a neutral visual scene leads to a stronger sense of suspense than when the same fearful context is paired with a horror-type of scene which is emotional/fearful on its own. Director Alfred Hitchcock for instance describes how giving the audience additional information not known to the characters in a movie can create a strong sense of suspense (e.g. <span class="xrefLink" id="jumplink-B35"></span><a href="javascript:;" reveal-id="B35" data-open="B35" class="link link-ref link-reveal xref-bibr">Pisters, 2004</a>). The idea is to engage the audience by letting them ‘play God’ (<span class="xrefLink" id="jumplink-B15"></span><a href="javascript:;" reveal-id="B15" data-open="B15" class="link link-ref link-reveal xref-bibr">Gottlieb, 1995</a>), which leads to a much more implied type of fear or suspense as compared to gruesome horror scenes. A modern example is the movie <em>The Blair Witch Project</em> (1999), which has a high amount of suspense, without ever showing something which is literally scary: all the suspense is implied, mainly by using an unsteady home-video style of filming. The apparent neutrality of the visual scene is dramatically altered by the information that the audience has, despite the fact that the visual information is not fearful on its own right (<span class="xrefLink" id="jumplink-B15"></span><a href="javascript:;" reveal-id="B15" data-open="B15" class="link link-ref link-reveal xref-bibr">Gottlieb, 1995</a>; <span class="xrefLink" id="jumplink-B35"></span><a href="javascript:;" reveal-id="B35" data-open="B35" class="link link-ref link-reveal xref-bibr">Pisters, 2004</a>).</p><p class="chapter-para">In our experiment we operationalized this by presenting sentences with fearful/suspenseful content together with neutral pictures, and compared neural responses to these stimulus combinations to sentences with less fearful content presented together with the same neutral pictures. Consider the first example in <span class="xrefLink" id="jumplink-T1"></span><a href="javascript:;" reveal-id="T1" data-open="T1" class="link link-reveal link-table xref-fig">Table 1</a>. In this example we paired the visual scene of a young child on the beach either with the sentence ‘They never found the boy back again’ or with ‘The boy stepped bravely across the beach’. The first sentence is clearly more emotionally laden since it implies that something bad happened to the child, as compared to the more neutral second sentence. The idea is that by presenting the emotional sentence together with the as such neutral picture, the audience/reader is more strongly emotionally engaged with the stimulus because the reader knows/infers that something happened to this child. We hypothesize that there will be a stronger emotional response as compared to when we read the sentence without a picture, or when we read the less emotional sentence with the same neutral picture. It should be clear from the examples in <span class="xrefLink" id="jumplink-T1"></span><a href="javascript:;" reveal-id="T1" data-open="T1" class="link link-reveal link-table xref-fig">Table 1</a> that our sentence materials were not fearful in an obvious ‘shocking’ sense, but rather <em>implied</em> suspense. The sentences did not contain words that were in themselves obviously fearful, but fear was implied by the output of a compositional process on a series of non-fearful words. We label these sentences ‘fearful’ in the remainder of the manuscript mainly for ease of reading. </p>                        <a id="126925811" scrollto-destination="126925811"></a>
<div content-id="T1" class="table-modal table-full-width-wrap"><div class="table-wrap table-wide"><div class="table-wrap-title" id="T1" data-id="T1"><span class="label">Table 1</span><div class="caption"><p class="chapter-para">Two examples of the stimuli</p></div> </div><div class="table-overflow"><table><tbody><tr><td><img class="contentFigures" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050i1.jpeg?Expires=1605396424&amp;Signature=ERgEJ8xsMV1pj5J1m2fA0Bws5xnGXlcLnFT9s57HbuQJ7KSo5VmGmnWXehvYo9VC0tw0nCU5QETL1EaxTq6-B6j0VWwu5uAtujP8R5I9evv~ZTXG5Dfwx8zy8yjOCW5fYgad1YKvFY-LRG2tYkt292RSrqtkBbUPMxv-u5QuI~QqBHqZCTt9xlU7S6OMj~GFIjsiYx0Px-MrzolTMU0Ag9Ti5ZMKzEjiU7UR~Oq0LFax55zqOK-hqpgU3y~ffSPEsgE89er-76SN73EyuQN1DqW4VXEdKU9t0EsoKVc6Y4nvKY6hCw2dJp7nG38exAvDm3~7CiC4OBMy9jziyfpftg__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="graphic" data-path-from-xml="nsq050i1.jpeg" /> </td></tr></tbody></table></div><div class="table-modal"><table><tbody><tr><td><img class="contentFigures" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050i1.jpeg?Expires=1605396424&amp;Signature=ERgEJ8xsMV1pj5J1m2fA0Bws5xnGXlcLnFT9s57HbuQJ7KSo5VmGmnWXehvYo9VC0tw0nCU5QETL1EaxTq6-B6j0VWwu5uAtujP8R5I9evv~ZTXG5Dfwx8zy8yjOCW5fYgad1YKvFY-LRG2tYkt292RSrqtkBbUPMxv-u5QuI~QqBHqZCTt9xlU7S6OMj~GFIjsiYx0Px-MrzolTMU0Ag9Ti5ZMKzEjiU7UR~Oq0LFax55zqOK-hqpgU3y~ffSPEsgE89er-76SN73EyuQN1DqW4VXEdKU9t0EsoKVc6Y4nvKY6hCw2dJp7nG38exAvDm3~7CiC4OBMy9jziyfpftg__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="graphic" data-path-from-xml="nsq050i1.jpeg" /> </td></tr></tbody></table></div><div class="table-wrap-foot"><span id="fn-TF1"></span><div content-id="TF1"><div class="fn"><p class="chapter-para">Stimuli consisted of emotion-inducing sentences and sentences without clear emotional implications. The sentences were either presented together with a picture of a neutral visual scene or in the absence of a picture (on a black background). The top panel of each example shows the sentences in Dutch as well as their literal English translation. On the right side is the neutral picture that went together with these sentences. The box labeled ‘conditions’ illustrates the five experimental conditions. The first two conditions are the fearful (i) and non-fearful (ii) sentences presented without visual input (black screen). Conditions 3 and 4 are the same two sentences but now combined with the neutral visual scene, and condition 5 is presentation of the visual scene without language.</p></div></div></div><div class="graphic-wrap"><a class="fig-view-orig openInAnotherWindow btn js-view-large" href="/view-large/126925811" target="_blank">Open in new tab</a></div></div></div><div class="table-full-width-wrap"><div class="table-wrap table-wide"><div class="table-wrap-title" id="T1" data-id="T1"><span class="label">Table 1</span><div class="caption"><p class="chapter-para">Two examples of the stimuli</p></div> </div><div class="table-overflow"><table><tbody><tr><td><img class="contentFigures" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050i1.jpeg?Expires=1605396424&amp;Signature=ERgEJ8xsMV1pj5J1m2fA0Bws5xnGXlcLnFT9s57HbuQJ7KSo5VmGmnWXehvYo9VC0tw0nCU5QETL1EaxTq6-B6j0VWwu5uAtujP8R5I9evv~ZTXG5Dfwx8zy8yjOCW5fYgad1YKvFY-LRG2tYkt292RSrqtkBbUPMxv-u5QuI~QqBHqZCTt9xlU7S6OMj~GFIjsiYx0Px-MrzolTMU0Ag9Ti5ZMKzEjiU7UR~Oq0LFax55zqOK-hqpgU3y~ffSPEsgE89er-76SN73EyuQN1DqW4VXEdKU9t0EsoKVc6Y4nvKY6hCw2dJp7nG38exAvDm3~7CiC4OBMy9jziyfpftg__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="graphic" data-path-from-xml="nsq050i1.jpeg" /> </td></tr></tbody></table></div><div class="table-modal"><table><tbody><tr><td><img class="contentFigures" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050i1.jpeg?Expires=1605396424&amp;Signature=ERgEJ8xsMV1pj5J1m2fA0Bws5xnGXlcLnFT9s57HbuQJ7KSo5VmGmnWXehvYo9VC0tw0nCU5QETL1EaxTq6-B6j0VWwu5uAtujP8R5I9evv~ZTXG5Dfwx8zy8yjOCW5fYgad1YKvFY-LRG2tYkt292RSrqtkBbUPMxv-u5QuI~QqBHqZCTt9xlU7S6OMj~GFIjsiYx0Px-MrzolTMU0Ag9Ti5ZMKzEjiU7UR~Oq0LFax55zqOK-hqpgU3y~ffSPEsgE89er-76SN73EyuQN1DqW4VXEdKU9t0EsoKVc6Y4nvKY6hCw2dJp7nG38exAvDm3~7CiC4OBMy9jziyfpftg__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="graphic" data-path-from-xml="nsq050i1.jpeg" /> </td></tr></tbody></table></div><div class="table-wrap-foot"><span id="fn-TF1"></span><div content-id="TF1"><div class="fn"><p class="chapter-para">Stimuli consisted of emotion-inducing sentences and sentences without clear emotional implications. The sentences were either presented together with a picture of a neutral visual scene or in the absence of a picture (on a black background). The top panel of each example shows the sentences in Dutch as well as their literal English translation. On the right side is the neutral picture that went together with these sentences. The box labeled ‘conditions’ illustrates the five experimental conditions. The first two conditions are the fearful (i) and non-fearful (ii) sentences presented without visual input (black screen). Conditions 3 and 4 are the same two sentences but now combined with the neutral visual scene, and condition 5 is presentation of the visual scene without language.</p></div></div></div><div class="graphic-wrap"><a class="fig-view-orig openInAnotherWindow btn js-view-large" href="/view-large/126925811" target="_blank">Open in new tab</a></div></div></div><p class="chapter-para">We also investigated a closely related question, namely whether reading fearful/suspenseful sentences leads to stronger activation of the emotional system as compared to less fearful sentences. Previous research on emotional language processing has mostly studied single words expressing emotions (emotion words). Examples are fearful words (e.g. ‘threat’ and ‘death’, etc.) as well as words expressing positive emotions (e.g. ‘successful’, ‘happy’) (<span class="xrefLink" id="jumplink-B19"></span><a href="javascript:;" reveal-id="B19" data-open="B19" class="link link-ref link-reveal xref-bibr">Herbert <em>et al.</em>, 2009</a>). In our materials fear was not described by the sentence, but implied by the combination of non-fearful words. The important question is whether implied meaning as conveyed through language will also mediate responses in areas usually implicated in the direct perception of emotional events or by emotional words. Such an effect of emotional word meaning upon for instance the amygdala is reported in some (<span class="xrefLink" id="jumplink-B21"></span><a href="javascript:;" reveal-id="B21" data-open="B21" class="link link-ref link-reveal xref-bibr">Isenberg <em>et al.</em>, 1999</a>; <span class="xrefLink" id="jumplink-B41"></span><a href="javascript:;" reveal-id="B41" data-open="B41" class="link link-ref link-reveal xref-bibr">Strange <em>et al.</em>, 2000</a>; <span class="xrefLink" id="jumplink-B19"></span><a href="javascript:;" reveal-id="B19" data-open="B19" class="link link-ref link-reveal xref-bibr">Herbert <em>et al.</em>, 2009</a>), but not in other (<span class="xrefLink" id="jumplink-B5"></span><a href="javascript:;" reveal-id="B5" data-open="B5" class="link link-ref link-reveal xref-bibr">Beauregard <em>et al.</em>, 1997</a>; <span class="xrefLink" id="jumplink-B6"></span><a href="javascript:;" reveal-id="B6" data-open="B6" class="link link-ref link-reveal xref-bibr">Cato <em>et al.</em>, 2004</a>; <span class="xrefLink" id="jumplink-B24"></span><a href="javascript:;" reveal-id="B24" data-open="B24" class="link link-ref link-reveal xref-bibr">Kuchinke <em>et al.</em>, 2005</a>) neuroimaging investigations.</p><p class="chapter-para">Finally, we investigated how perceiving neutral visual scenes together with sentences expressing fearful content changes subsequent perception of the visual scenes in isolation. In the first two runs of the experiment participants read sentences presented together with neutral pictures, sentences presented on their own, or pictures presented on their own. In the third and final run of the experiment we presented the neutral pictures again, now without concomitant sentences. The rationale of this experimental manipulation was to see whether the pairing of a neutral picture with a fearful sentence would carry over to the perception of the visual scene when presented on its own. An indication of such a carry-over effect would be increased activation to pictures paired with fearful sentences as compared to activation to pictures paired with non-fearful sentences in parts of the brain involved in emotion.</p><p class="chapter-para">In summary the purpose of the present study was 3-fold: first, we explored the influence of pairing emotion-inducing language with visual scenes. Importantly, we paired language with neutral visual scenes, the rationale for which we described above. We hypothesize that parts of the brain circuitry involved in emotion will show a stronger effect of the fearful content expressed by sentences when these sentences are paired with a neutral visual scene than when they are presented on their own. A prime candidate to show such an effect is the amygdala, which has been implicated in the reading of emotional language (<span class="xrefLink" id="jumplink-B19"></span><a href="javascript:;" reveal-id="B19" data-open="B19" class="link link-ref link-reveal xref-bibr">Herbert <em>et al.</em>, 2009</a>; <span class="xrefLink" id="jumplink-B21"></span><a href="javascript:;" reveal-id="B21" data-open="B21" class="link link-ref link-reveal xref-bibr">Isenberg <em>et al.</em>, 1999</a>) but which is perhaps activated more robustly when emotional visual scenes (e.g. faces) are perceived (e.g. <span class="xrefLink" id="jumplink-B1"></span><a href="javascript:;" reveal-id="B1" data-open="B1" class="link link-ref link-reveal xref-bibr">Adolphs, 2008</a>). Alternatively, it may be that areas ‘bind’ information from language and picture together and that they do so more strongly in the case of emotional language content than in the case of less emotion-inducing language. A prime candidate to show such an effect is the right temporal pole, since a previous study found an interaction between emotion expressed by faces and the valence of a preceding context (<span class="xrefLink" id="jumplink-B29"></span><a href="javascript:;" reveal-id="B29" data-open="B29" class="link link-ref link-reveal xref-bibr">Mobbs <em>et al.</em>, 2006</a>).</p><p class="chapter-para">Second we investigated whether reading emotional sentences modulates activity in the neural circuitry implicated in perception of emotions. This would be in analogy with previous findings implicating sensori-motor cortex in the understanding of action-related or ‘visual’ language (e.g. <span class="xrefLink" id="jumplink-B37"></span><a href="javascript:;" reveal-id="B37" data-open="B37" class="link link-ref link-reveal xref-bibr">Pulvermuller, 2005</a>; <span class="xrefLink" id="jumplink-B47"></span><a href="javascript:;" reveal-id="B47" data-open="B47" class="link link-ref link-reveal xref-bibr">Willems and Hagoort, 2007</a>; <span class="xrefLink" id="jumplink-B3"></span><a href="javascript:;" reveal-id="B3" data-open="B3" class="link link-ref link-reveal xref-bibr">Barsalou, 2008</a>). It would be an extension of previous literature which has mainly focused on reading of emotional words, whereas in our materials the emotional meaning was established at the sentence level (cf. <span class="xrefLink" id="jumplink-B38"></span><a href="javascript:;" reveal-id="B38" data-open="B38" class="link link-ref link-reveal xref-bibr">Razafimandimby <em>et al.</em>, 2009</a>).</p><p class="chapter-para">Finally we looked at how pairing a neutral picture with a fearful sentence carries over to perception of the same picture in isolation. We hypothesize to see a ‘tag’ for the emotional content that the pictures were paired with, expressed as increased activation in parts of the brain that are involved in emotion processing.</p>                    <h2 scrollto-destination=126925817 id="126925817" class="section-title" >METHODS</h2>
                    <h3 scrollto-destination=126925818 id="126925818" class="section-title" >Participants</h3>
<p class="chapter-para">Fifteen young healthy individuals took part in the study (12 female, mean age 20.6 years, range 18–25). All participants were right-handed as assessed with the Edinburgh handedness inventory (<span class="xrefLink" id="jumplink-B30"></span><a href="javascript:;" reveal-id="B30" data-open="B30" class="link link-ref link-reveal xref-bibr">Oldfield, 1971</a>), and none had a history of neurological or psychiatric problems. Participants had no dyslexia as assessed through self-report and all had normal or corrected-to-normal vision and reported having Dutch as their mother tongue. The study was in line with the regulations laid down in the Declaration of Helsinki and was approved by the local ethics committee. Participants were paid for participation.</p>                    <h3 scrollto-destination=126925820 id="126925820" class="section-title" >Stimuli</h3>
<p class="chapter-para">We created 180 pairs of sentences in Dutch. Each sentence pair consisted of one item with fearful content (sentence_fear) and one item with less fearful content (sentence_nofear). Emotional content of the stimuli was pretested in a separate pretest in which raters (<em>n</em> = 12), who did not participate in the functional magnetic resonance imaging session, rated a larger set of sentences on how much fear they thought was expressed by each sentence (1–7 point scale). Sentences were selected based upon the results of the pretest such that the fearful sentences were perceived as more fearful (mean = 3.89, s.d. = 0.72) and the non-fearful sentences as less fearful (mean = 1.27, s.d. = 0.28). This difference was statistically significant [<em>t</em>(178) = 47.2, <em>P</em> &lt; 0.001]. Sentences in the two conditions were matched for sentence length (number of words; <em>t</em> &lt; 1), lexical frequency of the words [derived from the CELEX database (<span class="xrefLink" id="jumplink-B2"></span><a href="javascript:;" reveal-id="B2" data-open="B2" class="link link-ref link-reveal xref-bibr">Baayen <em>et al.</em>, 1993</a>); <em>t</em> &lt; 1] and syntactic structure.</p><p class="chapter-para">The visual stimuli were photographs of neutral scenes. They encompassed a wide variety of topics, from holiday-type pictures of landscapes to everyday situations such as people walking on the street. Importantly, none of these pictures displayed emotional of fearful content.</p><p class="chapter-para">In accordance with the rationale for the experiment, sentences and pictures were presented in five conditions (see also <span class="xrefLink" id="jumplink-T1"></span><a href="javascript:;" reveal-id="T1" data-open="T1" class="link link-reveal link-table xref-fig">Table 1</a>): </p><ol class="order"><li><p class="chapter-para">Sentence fear (sent_fear);</p></li><li><p class="chapter-para">Sentence no fear (sent_nofear);</p></li><li><p class="chapter-para">Sentence fear + picture (sent_fear_pict);</p></li><li><p class="chapter-para">Sentence no fear + picture (sent_nofear_pict);</p></li><li><p class="chapter-para">Picture alone (pict_alone).</p></li></ol><p class="chapter-para">The sentences were presented below the pictures in the conditions in which sentences and pictures were paired.</p>                    <h3 scrollto-destination=126925826 id="126925826" class="section-title" >Experimental procedure</h3>
<p class="chapter-para">Participants took part in three runs (<span class="xrefLink" id="jumplink-F1"></span><a href="javascript:;" reveal-id="F1" data-open="F1" class="link link-reveal link-table xref-fig">Figure 1</a>). In runs 1 and 2, participants were presented with the stimuli in the five conditions outlined above. In run 3, participants were presented with the pictures that they had perceived in runs 1 and 2. Note that in run 3 only pictures were presented. </p>                        <a id="126925828" scrollto-destination="126925828"></a>
<div data-id="F1" class="fig fig-section"><div class="label fig-label">Fig. 1</div><div class="graphic-wrap"><img class="content-image" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050f1.jpeg?Expires=1605396424&amp;Signature=XcHSl~PsMQJLlhif4sb1Vra1De9MxeH7SXJCk3~cRSNhXuBFtEbVYvGEJgAV7I0F1m9oBepb6YRB4xfNw3xGtqxQW4OqvcoY4WlWn9p6EJxhKaJIimh9L-11E15X5PbqO6Y1lmr~xhzGrujKC5n1MnIOQgjyXVzMrcv5AUlPl~j30U1HLZTD5R9GAQ~SWU2YKnYulAz-2ClCcLDlD3QaBu1NH3pb0ROdULep8RZ3mbKT6yvV1c-VVYR50VvF0d19ZFTgE890AwY00WaAJw607ITwdsYGo5YJdY6jaZLQJRNIFkSjgZx9SWeUhLWZsDZlqbiqDOoGR~Tp~z0O4tIZcA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Experimental design. The experiment consisted of three runs: in runs 1 and 2, the five conditions as illustrated in Table 1 were presented. That is, participants read fear-inducing or non-fearful sentences presented without a visual scene (conditions 1 and 2), or presented together with a neutral visual scene (conditions 3 and 4), or observed the visual scenes without language (condition 5). In run 3, participants observed the same visual scenes as they had observed in runs 1 and 2, but now presented without language. The visual scenes could have been previously paired with fear-inducing language (i), with non-fearful language (ii) or presented without language (iii) in runs 1 and 2." data-path-from-xml="nsq050f1.jpeg" /><div class="fig-orig original-slide"><a class="fig-view-orig js-view-large openInAnotherWindow" href="/view-large/figure/126925828/nsq050f1.jpeg" data-path-from-xml="nsq050f1.jpeg" target="_blank">Open in new tab</a><a data-section="126925828" href="/DownloadFile/DownloadImage.aspx?image=https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/nsq050f1.jpeg?Expires=1605396424&Signature=4rWYYUDGKyWuSf-wb3d5zOVB9F2pHqi7WOCfsxlhGfm31byHmXNq9TLbp5dG5jdM5Bt-UI4gE3vFGmjzmPYIT1vMhb~Jtrlo1SmKZJMcdOty8Kk6Wkc4ACv0ZEoFi~tn0PEDyLpV-zL7J5mUXwLLR108CGuPYn5y~hfE~QowF6PmPRs7uHIpU4~Q~CXBoD7actWFj3~LTJcrPOXdlZDMgZETOshqpPo6jhBKqN75uUpeyRXTvYRGd-QeBqlkVRX6gx6oQCxEhAyH~s4zIP4QS3n9PKuG0ckP4HNkArh16X5XGnhwbRTewflJ7lU2Jybo11c0hKYfXcLj510Twcgvjg__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=126925828&ar=1647696&xsltPath=~/UI/app/XSLT&imagename=&siteId=5242" class="download-slide" data-path-from-xml="nsq050f1.jpeg">Download slide</a></div></div><div class="caption fig-caption"><p class="chapter-para">Experimental design. The experiment consisted of three runs: in runs 1 and 2, the five conditions as illustrated in <span class="xrefLink" id="jumplink-T1"></span><a href="javascript:;" reveal-id="T1" data-open="T1" class="link link-reveal link-table xref-fig">Table 1</a> were presented. That is, participants read fear-inducing or non-fearful sentences presented without a visual scene (conditions 1 and 2), or presented together with a neutral visual scene (conditions 3 and 4), or observed the visual scenes without language (condition 5). In run 3, participants observed the same visual scenes as they had observed in runs 1 and 2, but now presented without language. The visual scenes could have been previously paired with fear-inducing language (i), with non-fearful language (ii) or presented without language (iii) in runs 1 and 2.</p></div></div><div content-id="F1" class="fig fig-modal reveal-modal"><div class="label fig-label">Fig. 1</div><div class="graphic-wrap"><img class="content-image" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050f1.jpeg?Expires=1605396424&amp;Signature=XcHSl~PsMQJLlhif4sb1Vra1De9MxeH7SXJCk3~cRSNhXuBFtEbVYvGEJgAV7I0F1m9oBepb6YRB4xfNw3xGtqxQW4OqvcoY4WlWn9p6EJxhKaJIimh9L-11E15X5PbqO6Y1lmr~xhzGrujKC5n1MnIOQgjyXVzMrcv5AUlPl~j30U1HLZTD5R9GAQ~SWU2YKnYulAz-2ClCcLDlD3QaBu1NH3pb0ROdULep8RZ3mbKT6yvV1c-VVYR50VvF0d19ZFTgE890AwY00WaAJw607ITwdsYGo5YJdY6jaZLQJRNIFkSjgZx9SWeUhLWZsDZlqbiqDOoGR~Tp~z0O4tIZcA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Experimental design. The experiment consisted of three runs: in runs 1 and 2, the five conditions as illustrated in Table 1 were presented. That is, participants read fear-inducing or non-fearful sentences presented without a visual scene (conditions 1 and 2), or presented together with a neutral visual scene (conditions 3 and 4), or observed the visual scenes without language (condition 5). In run 3, participants observed the same visual scenes as they had observed in runs 1 and 2, but now presented without language. The visual scenes could have been previously paired with fear-inducing language (i), with non-fearful language (ii) or presented without language (iii) in runs 1 and 2." data-path-from-xml="nsq050f1.jpeg" /><div class="fig-orig original-slide"><a class="fig-view-orig js-view-large openInAnotherWindow" href="/view-large/figure/126925828/nsq050f1.jpeg" data-path-from-xml="nsq050f1.jpeg" target="_blank">Open in new tab</a><a data-section="126925828" href="/DownloadFile/DownloadImage.aspx?image=https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/nsq050f1.jpeg?Expires=1605396424&Signature=4rWYYUDGKyWuSf-wb3d5zOVB9F2pHqi7WOCfsxlhGfm31byHmXNq9TLbp5dG5jdM5Bt-UI4gE3vFGmjzmPYIT1vMhb~Jtrlo1SmKZJMcdOty8Kk6Wkc4ACv0ZEoFi~tn0PEDyLpV-zL7J5mUXwLLR108CGuPYn5y~hfE~QowF6PmPRs7uHIpU4~Q~CXBoD7actWFj3~LTJcrPOXdlZDMgZETOshqpPo6jhBKqN75uUpeyRXTvYRGd-QeBqlkVRX6gx6oQCxEhAyH~s4zIP4QS3n9PKuG0ckP4HNkArh16X5XGnhwbRTewflJ7lU2Jybo11c0hKYfXcLj510Twcgvjg__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=126925828&ar=1647696&xsltPath=~/UI/app/XSLT&imagename=&siteId=5242" class="download-slide" data-path-from-xml="nsq050f1.jpeg">Download slide</a></div></div><div class="caption fig-caption"><p class="chapter-para">Experimental design. The experiment consisted of three runs: in runs 1 and 2, the five conditions as illustrated in <span class="xrefLink" id="jumplink-T1"></span><a href="javascript:;" reveal-id="T1" data-open="T1" class="link link-reveal link-table xref-fig">Table 1</a> were presented. That is, participants read fear-inducing or non-fearful sentences presented without a visual scene (conditions 1 and 2), or presented together with a neutral visual scene (conditions 3 and 4), or observed the visual scenes without language (condition 5). In run 3, participants observed the same visual scenes as they had observed in runs 1 and 2, but now presented without language. The visual scenes could have been previously paired with fear-inducing language (i), with non-fearful language (ii) or presented without language (iii) in runs 1 and 2.</p></div></div><p class="chapter-para">Stimuli were presented in an event-related manner. In runs 1 and 2 trial duration was 4 s, with a variable inter-trial interval ranging between 2 and 4 s (mean = 3 s) in steps of 250 ms, to effectively jitter onset of image acquisition and stimulus presentation (<span class="xrefLink" id="jumplink-B8"></span><a href="javascript:;" reveal-id="B8" data-open="B8" class="link link-ref link-reveal xref-bibr">Dale, 1999</a>). This presentation scheme ensures that the height of the hemodynamic response function can be effectively estimated despite the fact that the BOLD response peaks several seconds after presentation of a stimulus (<span class="xrefLink" id="jumplink-B28"></span><a href="javascript:;" reveal-id="B28" data-open="B28" class="link link-ref link-reveal xref-bibr">Miezin <em>et al.</em>, 2000</a>). Conditions were rotated over participants such that a participant only saw one item from a stimulus set (<span class="xrefLink" id="jumplink-T1"></span><a href="javascript:;" reveal-id="T1" data-open="T1" class="link link-reveal link-table xref-fig">Table 1</a>). This means that there were five stimulus lists, each consisting of 150 items. Stimuli were presented in two blocks of 75 items, lasting 12 min each. Eight (out of 15) participants were presented with a mirrored version of the stimulus list.</p><p class="chapter-para">In run 3 (when only pictures were presented) stimulus duration was 2 s, with the same inter-trial interval as in runs 1 and 2. Participants were presented with 108 items in total, and eight (out of 14) participants were presented with a mirrored version of the stimulus list. Each participant was presented with all pictures that were shown in the previous runs, resulting in three conditions: pictures previously presented without a sentence (pict_nosent), pictures previously presented with a fearful sentence (pict_fear), picture previously presented with a non-fear sentence (pict_nofear).</p><p class="chapter-para">The order of runs 1 and 2 was counterbalanced across participants. Run 3 by necessity always followed runs 1 and 2, given that the conditions in run 3 depended upon how pictures were presented in runs 1 and 2.</p><p class="chapter-para">In all runs participants were instructed to attentively read and watch the materials. Participants were told that general questions about the materials would be asked after the experiment, but that they did not have to memorize the items. We choose not to have an explicit task in order not to focus participants’ attention to a particular aspect of the stimuli. Moreover, previous work from our laboratory shows that presenting sentence materials without an explicit tasks leads to robust and reproducible activations (e.g. <span class="xrefLink" id="jumplink-B18"></span><a href="javascript:;" reveal-id="B18" data-open="B18" class="link link-ref link-reveal xref-bibr">Hagoort <em>et al.</em>, 2004</a>; <span class="xrefLink" id="jumplink-B32"></span><a href="javascript:;" reveal-id="B32" data-open="B32" class="link link-ref link-reveal xref-bibr">Özyürek <em>et al.</em>, 2007</a>; Tesink <em>et al.</em>, 2008; <span class="xrefLink" id="jumplink-B50"></span><a href="javascript:;" reveal-id="B50" data-open="B50" class="link link-ref link-reveal xref-bibr">Willems <em>et al.</em>, 2007</a>, <span class="xrefLink" id="jumplink-B49"></span><a href="javascript:;" reveal-id="B49" data-open="B49" class="link link-ref link-reveal xref-bibr">2008a</a>, <span class="xrefLink" id="jumplink-B51"></span><a href="javascript:;" reveal-id="B51" data-open="B51" class="link link-ref link-reveal xref-bibr">b</a>). Since no behavioral response was required, we used an infrared eyetracker to assess vigilance/wakefulness of participants. It was checked online whether participants remained attentive with their eyes open during the whole session. Participants were familiarized with the experimental procedure by means of 10 practice trials that were shown before the start of the first run. These contained materials not used in the remainder of the experiment. The practice trials also served to ensure that participants could read the sentences.</p>                    <h3 scrollto-destination=126925833 id="126925833" class="section-title" >Data acquisition and analysis</h3>
<p class="chapter-para">Echo-Planar Images (EPI) covering the whole brain were acquired with a 8 channel head coil on a Siemens MR system with 1.5 T magnetic field strength (TR = 2340 ms; TE = 35 ms; flip angle 90°, 32 transversal slices; voxel size 3.125 × 3.125 × 3.5 mm, 0.35 mm gap between slices). Data analysis was done using SPM5 (<a class="link link-uri openInAnotherWindow" href="http://www.fil.ion.ucl.ac.uk/spm/software/spm5/" target="_blank">http://www.fil.ion.ucl.ac.uk/spm/software/spm5/</a>). Preprocessing involved realignment through rigid body registration to correct for head motion and correction for differences in slice timing acquisition to the onset of the first slice. Subsequently for each participant a mean image from all EPI images was created, and this image was normalized to Montreal Neurological Institute (MNI) space by means of a least-squares affine transformation. The parameters obtained from the normalization procedure were applied to all EPI images. Data were interpolated to 2 × 2 × 2 mm voxel size, and spatially smoothed with an isotropic Gaussian kernel of 8 mm full-width at half maximum.</p><p class="chapter-para">First-level analysis involved estimation of beta weights in a multiple regression analysis with regressors describing the expected hemodynamic responses (<span class="xrefLink" id="jumplink-B12"></span><a href="javascript:;" reveal-id="B12" data-open="B12" class="link link-ref link-reveal xref-bibr">Friston <em>et al.</em>, 1995</a>) for each of the conditions (sent_fear, sent_nofear, sent_fear_pict, sent_nofear_pict, pict_alone in runs 1 and 2, and pict_fear, pict_nofear, pict_nosent in run 3). Stimuli were modeled as their actual duration (4 s in data from runs 1 and 2, 2 s in data from run 3) and regressors were convolved with a canonical two gamma hemodynamic response function (e.g. <span class="xrefLink" id="jumplink-B11"></span><a href="javascript:;" reveal-id="B11" data-open="B11" class="link link-ref link-reveal xref-bibr">Friston <em>et al.</em>, 1996</a>). The six motion parameters obtained from the motion correction algorithm (three translations and three rotations) were included as regressors of no interest.</p><p class="chapter-para">Second-level group analysis involved testing a mixed model with subjects as a random factor (‘random effects analysis’) (<span class="xrefLink" id="jumplink-B13"></span><a href="javascript:;" reveal-id="B13" data-open="B13" class="link link-ref link-reveal xref-bibr">Friston <em>et al.</em>, 1999</a>). We first looked at which areas responded more strongly to fearful as compared to non-fearful sentences, collapsed over conditions (sent_fear + sent_fear_pict &gt; sent_nofear + sent_nofear_pict). Given our hypothesis about the ‘additive’ effect of adding a neutral picture to a fearful sentence, we next looked for regions showing a stronger response to fearful as compared to non-fearful sentences combined with a picture as compared to fearful compared to non-fearful sentences without a picture (a directed interaction effect: [(sent_fear_pict &gt; sent_nofear_pict) &gt; (sent_fear &gt; sent_nofear)]. Finally, we tested for areas which were more strongly activated to reading fearful sentences as compared to non-fearful sentences when presented without pictures (sent_fear &gt; sent_nofear), and in addition which areas responded more strongly to fearful sentences combined with a pictures as compared to non-fearful sentences combined with a picture (sent_fear_pict &gt; sent_nofear_pict). Group statistical maps were corrected for multiple comparisons by combining an activation level threshold of <em>P</em> &lt; 0.001 at the individual subject level with a cluster extent threshold computed using the theory of Gaussian random fields, to arrive at a statistical threshold with a <em>P</em> &lt; 0.05 significance level, corrected for multiple comparisons (<span class="xrefLink" id="jumplink-B11"></span><a href="javascript:;" reveal-id="B11" data-open="B11" class="link link-ref link-reveal xref-bibr">Friston <em>et al.</em>, 1996</a>; <span class="xrefLink" id="jumplink-B36"></span><a href="javascript:;" reveal-id="B36" data-open="B36" class="link link-ref link-reveal xref-bibr">Poline <em>et al.</em>, 1997</a>).</p><p class="chapter-para">Given our a priori hypothesis (see Introduction section), we assessed responses of left and right amygdala in anatomically defined regions of interest (ROIs). These were created using the automated anatomical labeling (AAL) template, which is based upon a landmark guided parcellation of the MNI brain template (<span class="xrefLink" id="jumplink-B45"></span><a href="javascript:;" reveal-id="B45" data-open="B45" class="link link-ref link-reveal xref-bibr">Tzourio-Mazoyer <em>et al.</em>, 2002</a>). Moreover, we used the AAL template to create a region of interest encompassing the right temporal pole (both superior and middle part), in line with our prediction for this area as laid down in the Introduction section.</p>                    <h2 scrollto-destination=126925838 id="126925838" class="section-title" >RESULTS</h2>
                    <h3 scrollto-destination=126925839 id="126925839" class="section-title" >Results from sentence reading (runs 1 and 2)</h3>
<p class="chapter-para">We first tested for areas that responded more strongly to fearful sentences as compared to non-fearful sentences, collapsed over conditions with and without a picture (sent_fear + sent_fear_pict &gt; sent_nofear + sent_nofear_pict). This comparison revealed areas in left inferior frontal gyrus, the middle temporal gyri bilaterally, as well as the temporal poles bilaterally, to be more strongly activated to fearful as compared to non-fearful sentences (<span class="xrefLink" id="jumplink-T2"></span><a href="javascript:;" reveal-id="T2" data-open="T2" class="link link-reveal link-table xref-fig">Table 2</a> and <span class="xrefLink" id="jumplink-F2"></span><a href="javascript:;" reveal-id="F2" data-open="F2" class="link link-reveal link-table xref-fig">Figure 2</a>). </p>                        <a id="126925841" scrollto-destination="126925841"></a>
<div data-id="F2" class="fig fig-section"><div class="label fig-label">Fig. 2</div><div class="graphic-wrap"><img class="content-image" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050f2.jpeg?Expires=1605396424&amp;Signature=gbglOHtMjjphfO4QFJ9fB5audB1CaBkCMcl4DJSIwFfar0ilykETTaVGS9R0kzJg2eiBu6hNXEptnDUetx4wZ1fWuXY-sBCdGJ0~ZGRWeBy1efChthrXFaZmauSc9s2Vm0RaUY91sV5f7Cv7MAhQBTOpZqpdzRs-ifS6RRKfZIS86lCzRx678RltXp9XkN1EOmdHL-yOxIEHFaYcfE2V2ilcyuew0SDnouOGwo2VTQQanUOfsH7sv~YbTBIlYF9c7TevcJLKp1ntLGNqsFHCUqk~6jsTt5i0CIHQuNLX6vIw0av00hSkPlpATHvpkLa5YlG8geXdu3yQAe0hFVvVwQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Results of whole brain analysis comparing fearful to non-fearful sentences. This contrast collapsed over sentence alone and sentence combined with picture conditions, testing a main effect of fear &gt; no fear (sent_fear + sent_fear_pict) &gt; (sent_nofear + sent_nofear_pict). Results are corrected for multiple comparisons at the P &lt;0.05 level and displayed on a brain rendering that was created using MRIcron (http://www.sph.sc.edu/comd/rorden/mricron/)." data-path-from-xml="nsq050f2.jpeg" /><div class="fig-orig original-slide"><a class="fig-view-orig js-view-large openInAnotherWindow" href="/view-large/figure/126925841/nsq050f2.jpeg" data-path-from-xml="nsq050f2.jpeg" target="_blank">Open in new tab</a><a data-section="126925841" href="/DownloadFile/DownloadImage.aspx?image=https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/nsq050f2.jpeg?Expires=1605396424&Signature=ZHMew8A696OJ8FMjqDaxjOkxFjLylpFaw3QGnABoynSoDAU3p6NOmuKUQw~sHSDsPzxZsZB9a0DxcKX3ItOByEK3uLuLhjlZzyx~TFzindN4u6ZXmCTfg4rONum2ihpFXcnnbSDb6mq~q8pgEQ1Gk4523CP28D4dROS5y5jBeKW-UjhR9LLEfmStwBcQ5xqmcZ5c-w3A323~-HYgcSxyymcB72iZ8S4Y7G5vLbx8v1iBiPdNUHWBYaFXpB19vJJhOrCHML2j4Z7SNiQN8hkcZl9U9C5i8cHoKHwno2OqGwLduHx11yMViiJRMrCRDT4g5X40xYbS5~c1pEXeNvASaA__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=126925841&ar=1647696&xsltPath=~/UI/app/XSLT&imagename=&siteId=5242" class="download-slide" data-path-from-xml="nsq050f2.jpeg">Download slide</a></div></div><div class="caption fig-caption"><p class="chapter-para">Results of whole brain analysis comparing fearful to non-fearful sentences. This contrast collapsed over sentence alone and sentence combined with picture conditions, testing a main effect of fear &gt; no fear (sent_fear + sent_fear_pict) &gt; (sent_nofear + sent_nofear_pict). Results are corrected for multiple comparisons at the <em>P</em> &lt;0.05 level and displayed on a brain rendering that was created using MRIcron (<a class="link link-uri openInAnotherWindow" href="http://www.sph.sc.edu/comd/rorden/mricron/" target="_blank">http://www.sph.sc.edu/comd/rorden/mricron/</a>).</p></div></div><div content-id="F2" class="fig fig-modal reveal-modal"><div class="label fig-label">Fig. 2</div><div class="graphic-wrap"><img class="content-image" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050f2.jpeg?Expires=1605396424&amp;Signature=gbglOHtMjjphfO4QFJ9fB5audB1CaBkCMcl4DJSIwFfar0ilykETTaVGS9R0kzJg2eiBu6hNXEptnDUetx4wZ1fWuXY-sBCdGJ0~ZGRWeBy1efChthrXFaZmauSc9s2Vm0RaUY91sV5f7Cv7MAhQBTOpZqpdzRs-ifS6RRKfZIS86lCzRx678RltXp9XkN1EOmdHL-yOxIEHFaYcfE2V2ilcyuew0SDnouOGwo2VTQQanUOfsH7sv~YbTBIlYF9c7TevcJLKp1ntLGNqsFHCUqk~6jsTt5i0CIHQuNLX6vIw0av00hSkPlpATHvpkLa5YlG8geXdu3yQAe0hFVvVwQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Results of whole brain analysis comparing fearful to non-fearful sentences. This contrast collapsed over sentence alone and sentence combined with picture conditions, testing a main effect of fear &gt; no fear (sent_fear + sent_fear_pict) &gt; (sent_nofear + sent_nofear_pict). Results are corrected for multiple comparisons at the P &lt;0.05 level and displayed on a brain rendering that was created using MRIcron (http://www.sph.sc.edu/comd/rorden/mricron/)." data-path-from-xml="nsq050f2.jpeg" /><div class="fig-orig original-slide"><a class="fig-view-orig js-view-large openInAnotherWindow" href="/view-large/figure/126925841/nsq050f2.jpeg" data-path-from-xml="nsq050f2.jpeg" target="_blank">Open in new tab</a><a data-section="126925841" href="/DownloadFile/DownloadImage.aspx?image=https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/nsq050f2.jpeg?Expires=1605396424&Signature=ZHMew8A696OJ8FMjqDaxjOkxFjLylpFaw3QGnABoynSoDAU3p6NOmuKUQw~sHSDsPzxZsZB9a0DxcKX3ItOByEK3uLuLhjlZzyx~TFzindN4u6ZXmCTfg4rONum2ihpFXcnnbSDb6mq~q8pgEQ1Gk4523CP28D4dROS5y5jBeKW-UjhR9LLEfmStwBcQ5xqmcZ5c-w3A323~-HYgcSxyymcB72iZ8S4Y7G5vLbx8v1iBiPdNUHWBYaFXpB19vJJhOrCHML2j4Z7SNiQN8hkcZl9U9C5i8cHoKHwno2OqGwLduHx11yMViiJRMrCRDT4g5X40xYbS5~c1pEXeNvASaA__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=126925841&ar=1647696&xsltPath=~/UI/app/XSLT&imagename=&siteId=5242" class="download-slide" data-path-from-xml="nsq050f2.jpeg">Download slide</a></div></div><div class="caption fig-caption"><p class="chapter-para">Results of whole brain analysis comparing fearful to non-fearful sentences. This contrast collapsed over sentence alone and sentence combined with picture conditions, testing a main effect of fear &gt; no fear (sent_fear + sent_fear_pict) &gt; (sent_nofear + sent_nofear_pict). Results are corrected for multiple comparisons at the <em>P</em> &lt;0.05 level and displayed on a brain rendering that was created using MRIcron (<a class="link link-uri openInAnotherWindow" href="http://www.sph.sc.edu/comd/rorden/mricron/" target="_blank">http://www.sph.sc.edu/comd/rorden/mricron/</a>).</p></div></div>                        <a id="126925842" scrollto-destination="126925842"></a>
<div content-id="T2" class="table-modal table-full-width-wrap"><div class="table-wrap table-wide"><div class="table-wrap-title" id="T2" data-id="T2"><span class="label">Table 2</span><div class="caption"><p class="chapter-para">Results from whole brain analysis of runs 1 and 2</p></div> </div><div class="table-overflow"><table><thead><tr><th>Comparison<span aria-hidden="true" style="display: none;">
            . </span></th><th>MNI coordinates (<em>x, y, z</em>)<span aria-hidden="true" style="display: none;">
            . </span></th><th><em>T</em>(max)<span aria-hidden="true" style="display: none;">
            . </span></th><th>Size (2 × 2 × 2 mm voxels)<span aria-hidden="true" style="display: none;">
            . </span></th></tr></thead><tbody><tr><td><em>Fear &gt; no fear</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Left anterior inferior frontal gyrus </td><td>−46, 28, 4 </td><td>4.90 </td><td>1768 </td></tr><tr><td>    Left middle temporal gyrus </td><td>−62, −24, −14 </td><td> </td><td> </td></tr><tr><td>    Left temporal pole </td><td>−44, 24, −22 </td><td> </td><td> </td></tr><tr><td>     </td><td>−48, 12, −28 </td><td> </td><td> </td></tr><tr><td>    Right middle temporal gyrus </td><td>  48, −30, −8 </td><td>4.18 </td><td>200 </td></tr><tr><td>     </td><td>  50, −18, −14 </td><td> </td><td> </td></tr><tr><td>     </td><td>  48, −32, 2 </td><td> </td><td> </td></tr><tr><td>    Right temporal pole </td><td>  52, 12, −22 </td><td>4.05 </td><td>161 </td></tr><tr><td>     </td><td>  46, 10, −36 </td><td> </td><td> </td></tr><tr><td>     </td><td>  48, 22, −22 </td><td> </td><td> </td></tr><tr><td><em>Sent_fear &gt; Sent_nofear</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Left insula </td><td>−44, 24, −22 </td><td>4.66 </td><td>185 </td></tr><tr><td>     </td><td>−32, 26, −8 </td><td> </td><td> </td></tr><tr><td>    Left temporal pole </td><td>−30, 20, −32 </td><td> </td><td> </td></tr><tr><td>    Left anterior inferior frontal gyrus </td><td>−56, 20, 2 </td><td>4.28 </td><td>195 </td></tr><tr><td>     </td><td>−54, 22, 12 </td><td> </td><td> </td></tr><tr><td><em>Sent_fear_pict &gt; Sent_nofear_pict</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Left temporal pole/middle  temporal sulcus </td><td>−60, −26, −6 </td><td>3.91 </td><td>244 </td></tr><tr><td>     </td><td>−64, −4, −16 </td><td> </td><td> </td></tr><tr><td>     </td><td>−62, −14, −28 </td><td> </td><td> </td></tr><tr><td>    Right cerebellum </td><td>  18, −76, −38 </td><td>4.52 </td><td>162 </td></tr><tr><td>     </td><td>  14, −72, −22 </td><td> </td><td> </td></tr></tbody></table></div><div class="table-modal"><table><thead><tr><th>Comparison<span aria-hidden="true" style="display: none;">
            . </span></th><th>MNI coordinates (<em>x, y, z</em>)<span aria-hidden="true" style="display: none;">
            . </span></th><th><em>T</em>(max)<span aria-hidden="true" style="display: none;">
            . </span></th><th>Size (2 × 2 × 2 mm voxels)<span aria-hidden="true" style="display: none;">
            . </span></th></tr></thead><tbody><tr><td><em>Fear &gt; no fear</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Left anterior inferior frontal gyrus </td><td>−46, 28, 4 </td><td>4.90 </td><td>1768 </td></tr><tr><td>    Left middle temporal gyrus </td><td>−62, −24, −14 </td><td> </td><td> </td></tr><tr><td>    Left temporal pole </td><td>−44, 24, −22 </td><td> </td><td> </td></tr><tr><td>     </td><td>−48, 12, −28 </td><td> </td><td> </td></tr><tr><td>    Right middle temporal gyrus </td><td>  48, −30, −8 </td><td>4.18 </td><td>200 </td></tr><tr><td>     </td><td>  50, −18, −14 </td><td> </td><td> </td></tr><tr><td>     </td><td>  48, −32, 2 </td><td> </td><td> </td></tr><tr><td>    Right temporal pole </td><td>  52, 12, −22 </td><td>4.05 </td><td>161 </td></tr><tr><td>     </td><td>  46, 10, −36 </td><td> </td><td> </td></tr><tr><td>     </td><td>  48, 22, −22 </td><td> </td><td> </td></tr><tr><td><em>Sent_fear &gt; Sent_nofear</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Left insula </td><td>−44, 24, −22 </td><td>4.66 </td><td>185 </td></tr><tr><td>     </td><td>−32, 26, −8 </td><td> </td><td> </td></tr><tr><td>    Left temporal pole </td><td>−30, 20, −32 </td><td> </td><td> </td></tr><tr><td>    Left anterior inferior frontal gyrus </td><td>−56, 20, 2 </td><td>4.28 </td><td>195 </td></tr><tr><td>     </td><td>−54, 22, 12 </td><td> </td><td> </td></tr><tr><td><em>Sent_fear_pict &gt; Sent_nofear_pict</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Left temporal pole/middle  temporal sulcus </td><td>−60, −26, −6 </td><td>3.91 </td><td>244 </td></tr><tr><td>     </td><td>−64, −4, −16 </td><td> </td><td> </td></tr><tr><td>     </td><td>−62, −14, −28 </td><td> </td><td> </td></tr><tr><td>    Right cerebellum </td><td>  18, −76, −38 </td><td>4.52 </td><td>162 </td></tr><tr><td>     </td><td>  14, −72, −22 </td><td> </td><td> </td></tr></tbody></table></div><div class="table-wrap-foot"><span id="fn-TF2"></span><div content-id="TF2"><div class="fn"><p class="chapter-para">Half of the stimuli consisted of fearful or non-fearful sentences presented alone (sent_fear, sent_nofear). The other half of the stimuli were fearful and non-fearful sentences presented with neutral pictures (sent_fear_pict and sent_nofear_pict). The table shows the specificcomparison, a description of the activated region, the MNI coordinates, the <em>t</em>-value of peak activations within a cluster, as well as the size of each cluster in number of voxels (2 × 2 × 2 voxels). Results are corrected for multiple comparisons at the <em>P</em> &lt; 0.05 level.</p></div></div></div><div class="graphic-wrap"><a class="fig-view-orig openInAnotherWindow btn js-view-large" href="/view-large/126925842" target="_blank">Open in new tab</a></div></div></div><div class="table-full-width-wrap"><div class="table-wrap table-wide"><div class="table-wrap-title" id="T2" data-id="T2"><span class="label">Table 2</span><div class="caption"><p class="chapter-para">Results from whole brain analysis of runs 1 and 2</p></div> </div><div class="table-overflow"><table><thead><tr><th>Comparison<span aria-hidden="true" style="display: none;">
            . </span></th><th>MNI coordinates (<em>x, y, z</em>)<span aria-hidden="true" style="display: none;">
            . </span></th><th><em>T</em>(max)<span aria-hidden="true" style="display: none;">
            . </span></th><th>Size (2 × 2 × 2 mm voxels)<span aria-hidden="true" style="display: none;">
            . </span></th></tr></thead><tbody><tr><td><em>Fear &gt; no fear</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Left anterior inferior frontal gyrus </td><td>−46, 28, 4 </td><td>4.90 </td><td>1768 </td></tr><tr><td>    Left middle temporal gyrus </td><td>−62, −24, −14 </td><td> </td><td> </td></tr><tr><td>    Left temporal pole </td><td>−44, 24, −22 </td><td> </td><td> </td></tr><tr><td>     </td><td>−48, 12, −28 </td><td> </td><td> </td></tr><tr><td>    Right middle temporal gyrus </td><td>  48, −30, −8 </td><td>4.18 </td><td>200 </td></tr><tr><td>     </td><td>  50, −18, −14 </td><td> </td><td> </td></tr><tr><td>     </td><td>  48, −32, 2 </td><td> </td><td> </td></tr><tr><td>    Right temporal pole </td><td>  52, 12, −22 </td><td>4.05 </td><td>161 </td></tr><tr><td>     </td><td>  46, 10, −36 </td><td> </td><td> </td></tr><tr><td>     </td><td>  48, 22, −22 </td><td> </td><td> </td></tr><tr><td><em>Sent_fear &gt; Sent_nofear</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Left insula </td><td>−44, 24, −22 </td><td>4.66 </td><td>185 </td></tr><tr><td>     </td><td>−32, 26, −8 </td><td> </td><td> </td></tr><tr><td>    Left temporal pole </td><td>−30, 20, −32 </td><td> </td><td> </td></tr><tr><td>    Left anterior inferior frontal gyrus </td><td>−56, 20, 2 </td><td>4.28 </td><td>195 </td></tr><tr><td>     </td><td>−54, 22, 12 </td><td> </td><td> </td></tr><tr><td><em>Sent_fear_pict &gt; Sent_nofear_pict</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Left temporal pole/middle  temporal sulcus </td><td>−60, −26, −6 </td><td>3.91 </td><td>244 </td></tr><tr><td>     </td><td>−64, −4, −16 </td><td> </td><td> </td></tr><tr><td>     </td><td>−62, −14, −28 </td><td> </td><td> </td></tr><tr><td>    Right cerebellum </td><td>  18, −76, −38 </td><td>4.52 </td><td>162 </td></tr><tr><td>     </td><td>  14, −72, −22 </td><td> </td><td> </td></tr></tbody></table></div><div class="table-modal"><table><thead><tr><th>Comparison<span aria-hidden="true" style="display: none;">
            . </span></th><th>MNI coordinates (<em>x, y, z</em>)<span aria-hidden="true" style="display: none;">
            . </span></th><th><em>T</em>(max)<span aria-hidden="true" style="display: none;">
            . </span></th><th>Size (2 × 2 × 2 mm voxels)<span aria-hidden="true" style="display: none;">
            . </span></th></tr></thead><tbody><tr><td><em>Fear &gt; no fear</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Left anterior inferior frontal gyrus </td><td>−46, 28, 4 </td><td>4.90 </td><td>1768 </td></tr><tr><td>    Left middle temporal gyrus </td><td>−62, −24, −14 </td><td> </td><td> </td></tr><tr><td>    Left temporal pole </td><td>−44, 24, −22 </td><td> </td><td> </td></tr><tr><td>     </td><td>−48, 12, −28 </td><td> </td><td> </td></tr><tr><td>    Right middle temporal gyrus </td><td>  48, −30, −8 </td><td>4.18 </td><td>200 </td></tr><tr><td>     </td><td>  50, −18, −14 </td><td> </td><td> </td></tr><tr><td>     </td><td>  48, −32, 2 </td><td> </td><td> </td></tr><tr><td>    Right temporal pole </td><td>  52, 12, −22 </td><td>4.05 </td><td>161 </td></tr><tr><td>     </td><td>  46, 10, −36 </td><td> </td><td> </td></tr><tr><td>     </td><td>  48, 22, −22 </td><td> </td><td> </td></tr><tr><td><em>Sent_fear &gt; Sent_nofear</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Left insula </td><td>−44, 24, −22 </td><td>4.66 </td><td>185 </td></tr><tr><td>     </td><td>−32, 26, −8 </td><td> </td><td> </td></tr><tr><td>    Left temporal pole </td><td>−30, 20, −32 </td><td> </td><td> </td></tr><tr><td>    Left anterior inferior frontal gyrus </td><td>−56, 20, 2 </td><td>4.28 </td><td>195 </td></tr><tr><td>     </td><td>−54, 22, 12 </td><td> </td><td> </td></tr><tr><td><em>Sent_fear_pict &gt; Sent_nofear_pict</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Left temporal pole/middle  temporal sulcus </td><td>−60, −26, −6 </td><td>3.91 </td><td>244 </td></tr><tr><td>     </td><td>−64, −4, −16 </td><td> </td><td> </td></tr><tr><td>     </td><td>−62, −14, −28 </td><td> </td><td> </td></tr><tr><td>    Right cerebellum </td><td>  18, −76, −38 </td><td>4.52 </td><td>162 </td></tr><tr><td>     </td><td>  14, −72, −22 </td><td> </td><td> </td></tr></tbody></table></div><div class="table-wrap-foot"><span id="fn-TF2"></span><div content-id="TF2"><div class="fn"><p class="chapter-para">Half of the stimuli consisted of fearful or non-fearful sentences presented alone (sent_fear, sent_nofear). The other half of the stimuli were fearful and non-fearful sentences presented with neutral pictures (sent_fear_pict and sent_nofear_pict). The table shows the specificcomparison, a description of the activated region, the MNI coordinates, the <em>t</em>-value of peak activations within a cluster, as well as the size of each cluster in number of voxels (2 × 2 × 2 voxels). Results are corrected for multiple comparisons at the <em>P</em> &lt; 0.05 level.</p></div></div></div><div class="graphic-wrap"><a class="fig-view-orig openInAnotherWindow btn js-view-large" href="/view-large/126925842" target="_blank">Open in new tab</a></div></div></div><p class="chapter-para">We next tested for areas in which the influence of fearful content was bigger when a picture was presented than when no picture was presented [i.e. directed interaction effect (sent_fear_pict &gt; sent_nofear_pict) &gt; (sent_fear &gt; sent_nofear)]. This is the interaction effect that we predicted in the Introduction section. Small volume correction to anatomically defined right temporal pole showed this area to be sensitive to this comparison. At the whole brain level no clusters survived the cluster extent threshold, but the cluster in right temporal pole was sensitive to this comparison at the <em>P</em> &lt; 0.001 uncorrected level threshold (<span class="xrefLink" id="jumplink-F3"></span><a href="javascript:;" reveal-id="F3" data-open="F3" class="link link-reveal link-table xref-fig">Figure 3</a>). No areas were sensitive to the opposite contrast. </p>                        <a id="126925844" scrollto-destination="126925844"></a>
<div data-id="F3" class="fig fig-section"><div class="label fig-label">Fig. 3</div><div class="graphic-wrap"><img class="content-image" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050f3.jpeg?Expires=1605396424&amp;Signature=1KRURWLxIvyXCIjvfL9VYClxMu3DIWo77mR7tzRlA3pN~woeYyE9tQW6IBKjL3g1AjXeUM23gwzyjnXArFVFBd3dhqFrt5P0u9m9X-WL8iLdwbR2qf~YY8-~cLrlglftemONeKzDlQqc7UuMSeYsqHIV5FZnZJbQxmTIo3ioiBJWX5FQCJRzXCBJMu4tGyRDNxOcCUTu1JDqMJFOXGEHwp1GHXCNa493-Y3a167Ff98T86ZHkEAXgys~ETelSwv~~TBIAnlLlGNt8UdrpEN~Y9BIQ6YL212O7toIv2zNe-PCdC1kn~g-GVejFmXjDrV9EEMgzuZWwX5DbO8PC9k-OQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Results of whole brain analysis testing the additive effect of combining a neutral picture with a fear-inducing sentence. The directed interaction effect tested for regions that showed a bigger differential response to fearful than to non-fearful sentences when combined with a neutral picture, as compared to the difference between fearful and non-fearful sentences presented without a neutral picture [(sent_fear_pict &gt; sent_nofear_pict) &gt; (sent_fear &gt; sent_nofear)]. No areas survived a whole brain corrected statistical treshold. Correction for multiple comparisons was done by means of small volume correction (SVC) with the right temporal pole as the region of interest. The bar graphs represent percent signal change compared to the implicit session baseline. Coordinates refer to the MNI coordinates at which the image is displayed." data-path-from-xml="nsq050f3.jpeg" /><div class="fig-orig original-slide"><a class="fig-view-orig js-view-large openInAnotherWindow" href="/view-large/figure/126925844/nsq050f3.jpeg" data-path-from-xml="nsq050f3.jpeg" target="_blank">Open in new tab</a><a data-section="126925844" href="/DownloadFile/DownloadImage.aspx?image=https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/nsq050f3.jpeg?Expires=1605396424&Signature=py2wfP7TX~F7odHRtd~Fd4h-P1PN5fYVBCc4qY747KJMSTsA4RWUz4ybD2wpcziV8z9-WDfzRn~xcXd6gntsoEmyhprj-cShbwI-BmReJ5qsHlN8ejMdTMdEiga0aB36XWVTD6HPDKR1BiWjc026brvf1Taqx1xIBMhtm4DnX7E0iZdZR9MUwMmdmR2wCymV2g-z4QjQzTttcvaGLYEYxLXaJjzAoGr-lrDyhWEW55dIPY7urKp6x~Vdl~-RDOD5b3rjRWS5iD40DjEYkpKrSvjn4OMNtmsxpC8o-1gIb3p6tT9hERxsdKamaCiRkuZ59iXwCiRwvfHJGMg7gR~WiQ__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=126925844&ar=1647696&xsltPath=~/UI/app/XSLT&imagename=&siteId=5242" class="download-slide" data-path-from-xml="nsq050f3.jpeg">Download slide</a></div></div><div class="caption fig-caption"><p class="chapter-para">Results of whole brain analysis testing the additive effect of combining a neutral picture with a fear-inducing sentence. The directed interaction effect tested for regions that showed a bigger differential response to fearful than to non-fearful sentences when combined with a neutral picture, as compared to the difference between fearful and non-fearful sentences presented without a neutral picture [(sent_fear_pict &gt; sent_nofear_pict) &gt; (sent_fear &gt; sent_nofear)]. No areas survived a whole brain corrected statistical treshold. Correction for multiple comparisons was done by means of small volume correction (SVC) with the right temporal pole as the region of interest. The bar graphs represent percent signal change compared to the implicit session baseline. Coordinates refer to the MNI coordinates at which the image is displayed.</p></div></div><div content-id="F3" class="fig fig-modal reveal-modal"><div class="label fig-label">Fig. 3</div><div class="graphic-wrap"><img class="content-image" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050f3.jpeg?Expires=1605396424&amp;Signature=1KRURWLxIvyXCIjvfL9VYClxMu3DIWo77mR7tzRlA3pN~woeYyE9tQW6IBKjL3g1AjXeUM23gwzyjnXArFVFBd3dhqFrt5P0u9m9X-WL8iLdwbR2qf~YY8-~cLrlglftemONeKzDlQqc7UuMSeYsqHIV5FZnZJbQxmTIo3ioiBJWX5FQCJRzXCBJMu4tGyRDNxOcCUTu1JDqMJFOXGEHwp1GHXCNa493-Y3a167Ff98T86ZHkEAXgys~ETelSwv~~TBIAnlLlGNt8UdrpEN~Y9BIQ6YL212O7toIv2zNe-PCdC1kn~g-GVejFmXjDrV9EEMgzuZWwX5DbO8PC9k-OQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Results of whole brain analysis testing the additive effect of combining a neutral picture with a fear-inducing sentence. The directed interaction effect tested for regions that showed a bigger differential response to fearful than to non-fearful sentences when combined with a neutral picture, as compared to the difference between fearful and non-fearful sentences presented without a neutral picture [(sent_fear_pict &gt; sent_nofear_pict) &gt; (sent_fear &gt; sent_nofear)]. No areas survived a whole brain corrected statistical treshold. Correction for multiple comparisons was done by means of small volume correction (SVC) with the right temporal pole as the region of interest. The bar graphs represent percent signal change compared to the implicit session baseline. Coordinates refer to the MNI coordinates at which the image is displayed." data-path-from-xml="nsq050f3.jpeg" /><div class="fig-orig original-slide"><a class="fig-view-orig js-view-large openInAnotherWindow" href="/view-large/figure/126925844/nsq050f3.jpeg" data-path-from-xml="nsq050f3.jpeg" target="_blank">Open in new tab</a><a data-section="126925844" href="/DownloadFile/DownloadImage.aspx?image=https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/nsq050f3.jpeg?Expires=1605396424&Signature=py2wfP7TX~F7odHRtd~Fd4h-P1PN5fYVBCc4qY747KJMSTsA4RWUz4ybD2wpcziV8z9-WDfzRn~xcXd6gntsoEmyhprj-cShbwI-BmReJ5qsHlN8ejMdTMdEiga0aB36XWVTD6HPDKR1BiWjc026brvf1Taqx1xIBMhtm4DnX7E0iZdZR9MUwMmdmR2wCymV2g-z4QjQzTttcvaGLYEYxLXaJjzAoGr-lrDyhWEW55dIPY7urKp6x~Vdl~-RDOD5b3rjRWS5iD40DjEYkpKrSvjn4OMNtmsxpC8o-1gIb3p6tT9hERxsdKamaCiRkuZ59iXwCiRwvfHJGMg7gR~WiQ__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=126925844&ar=1647696&xsltPath=~/UI/app/XSLT&imagename=&siteId=5242" class="download-slide" data-path-from-xml="nsq050f3.jpeg">Download slide</a></div></div><div class="caption fig-caption"><p class="chapter-para">Results of whole brain analysis testing the additive effect of combining a neutral picture with a fear-inducing sentence. The directed interaction effect tested for regions that showed a bigger differential response to fearful than to non-fearful sentences when combined with a neutral picture, as compared to the difference between fearful and non-fearful sentences presented without a neutral picture [(sent_fear_pict &gt; sent_nofear_pict) &gt; (sent_fear &gt; sent_nofear)]. No areas survived a whole brain corrected statistical treshold. Correction for multiple comparisons was done by means of small volume correction (SVC) with the right temporal pole as the region of interest. The bar graphs represent percent signal change compared to the implicit session baseline. Coordinates refer to the MNI coordinates at which the image is displayed.</p></div></div><p class="chapter-para">Comparing fearful sentences to non-fearful sentences (sent_fear &gt; sent_nofear) revealed clusters of activation in the left insula, in the left temporal pole and in the anterior part of the left inferior frontal gyrus (<span class="xrefLink" id="jumplink-T2"></span><a href="javascript:;" reveal-id="T2" data-open="T2" class="link link-reveal link-table xref-fig">Table 2</a> and <span class="xrefLink" id="jumplink-F4"></span><a href="javascript:;" reveal-id="F4" data-open="F4" class="link link-reveal link-table xref-fig">Figure 4</a>). The opposite contrast (sent_nofear &gt; sent_fear) did not reveal any cluster of activation. </p>                        <a id="126925846" scrollto-destination="126925846"></a>
<div data-id="F4" class="fig fig-section"><div class="label fig-label">Fig. 4</div><div class="graphic-wrap"><img class="content-image" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050f4.jpeg?Expires=1605396424&amp;Signature=RLeorra63OFAnzM7pyrkGWKV8TE71lOSriJRDi4Bw6kdkNTTAfG49kKwAWAzhBCyXuLkZYeMmxGzOLYT64JbxclIJpPRu45qCogONbhVWKc7QJAWsVgkxi4TKj055RUEnNz3Tg1O2MdRlvWElLEN2~-iMPRRtIBPSz1kRLtnvzZvS-kNbPpAguzIdaE2vQ3-8UoB6UZ0wcvFGIkyxhgz3UL2h5MVKgZmRp6IG5SGOULbAlKThiZlK9xv1ECQYhMSPsDlcQckUwBAOef1sLC5AjS3xzmP7Xb4ADwZYxcHyZMp1VhXgyP5I8aPfZInKYOZUcyHVeKzAauSJz9M45H5pQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Results of whole brain analysis comparing sentences with fear-inducing content with sentences without fearful content (sent_fear &gt; sent_nofear). Results are corrected for multiple comparisons at the P &lt; 0.05 level. The bar graphs represent percent signal change compared to the implicit session baseline. Coordinates refer to MNI coordinates at which the image is displayed." data-path-from-xml="nsq050f4.jpeg" /><div class="fig-orig original-slide"><a class="fig-view-orig js-view-large openInAnotherWindow" href="/view-large/figure/126925846/nsq050f4.jpeg" data-path-from-xml="nsq050f4.jpeg" target="_blank">Open in new tab</a><a data-section="126925846" href="/DownloadFile/DownloadImage.aspx?image=https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/nsq050f4.jpeg?Expires=1605396424&Signature=Nte-3X3s8vMQgZm4J5Rfyz04gZeuX6FM3vH7L8fgBni3dxrzHaJpy4X2auB3FLeFvJFe7oPAlwrGzy3Ox~KuvtJHceYlWe--ni1yF21l947JBSVVDVcP8NAnap3PjWeQ33fvxVhJW5XiE3K5wWPfScm0H9R2PylBATWstI6S1uamYip7v3Se9pZFqNIJ0DbwM~Ekxfxy9wc9t0Uupy4EYTqjk2RAN9XRCODqtA-GV3T7~MA7lyxRVwfTarOTHDwUM2TJzVfBayyMhqiL0d0ln35PNu~FiP7OtLVI-~dFgLZziZ-gbFT~Qq8JDHML11emFiHVNGJd1ljVAiLr5AsZ6g__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=126925846&ar=1647696&xsltPath=~/UI/app/XSLT&imagename=&siteId=5242" class="download-slide" data-path-from-xml="nsq050f4.jpeg">Download slide</a></div></div><div class="caption fig-caption"><p class="chapter-para">Results of whole brain analysis comparing sentences with fear-inducing content with sentences without fearful content (sent_fear &gt; sent_nofear). Results are corrected for multiple comparisons at the <em>P</em> &lt; 0.05 level. The bar graphs represent percent signal change compared to the implicit session baseline. Coordinates refer to MNI coordinates at which the image is displayed.</p></div></div><div content-id="F4" class="fig fig-modal reveal-modal"><div class="label fig-label">Fig. 4</div><div class="graphic-wrap"><img class="content-image" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050f4.jpeg?Expires=1605396424&amp;Signature=RLeorra63OFAnzM7pyrkGWKV8TE71lOSriJRDi4Bw6kdkNTTAfG49kKwAWAzhBCyXuLkZYeMmxGzOLYT64JbxclIJpPRu45qCogONbhVWKc7QJAWsVgkxi4TKj055RUEnNz3Tg1O2MdRlvWElLEN2~-iMPRRtIBPSz1kRLtnvzZvS-kNbPpAguzIdaE2vQ3-8UoB6UZ0wcvFGIkyxhgz3UL2h5MVKgZmRp6IG5SGOULbAlKThiZlK9xv1ECQYhMSPsDlcQckUwBAOef1sLC5AjS3xzmP7Xb4ADwZYxcHyZMp1VhXgyP5I8aPfZInKYOZUcyHVeKzAauSJz9M45H5pQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Results of whole brain analysis comparing sentences with fear-inducing content with sentences without fearful content (sent_fear &gt; sent_nofear). Results are corrected for multiple comparisons at the P &lt; 0.05 level. The bar graphs represent percent signal change compared to the implicit session baseline. Coordinates refer to MNI coordinates at which the image is displayed." data-path-from-xml="nsq050f4.jpeg" /><div class="fig-orig original-slide"><a class="fig-view-orig js-view-large openInAnotherWindow" href="/view-large/figure/126925846/nsq050f4.jpeg" data-path-from-xml="nsq050f4.jpeg" target="_blank">Open in new tab</a><a data-section="126925846" href="/DownloadFile/DownloadImage.aspx?image=https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/nsq050f4.jpeg?Expires=1605396424&Signature=Nte-3X3s8vMQgZm4J5Rfyz04gZeuX6FM3vH7L8fgBni3dxrzHaJpy4X2auB3FLeFvJFe7oPAlwrGzy3Ox~KuvtJHceYlWe--ni1yF21l947JBSVVDVcP8NAnap3PjWeQ33fvxVhJW5XiE3K5wWPfScm0H9R2PylBATWstI6S1uamYip7v3Se9pZFqNIJ0DbwM~Ekxfxy9wc9t0Uupy4EYTqjk2RAN9XRCODqtA-GV3T7~MA7lyxRVwfTarOTHDwUM2TJzVfBayyMhqiL0d0ln35PNu~FiP7OtLVI-~dFgLZziZ-gbFT~Qq8JDHML11emFiHVNGJd1ljVAiLr5AsZ6g__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=126925846&ar=1647696&xsltPath=~/UI/app/XSLT&imagename=&siteId=5242" class="download-slide" data-path-from-xml="nsq050f4.jpeg">Download slide</a></div></div><div class="caption fig-caption"><p class="chapter-para">Results of whole brain analysis comparing sentences with fear-inducing content with sentences without fearful content (sent_fear &gt; sent_nofear). Results are corrected for multiple comparisons at the <em>P</em> &lt; 0.05 level. The bar graphs represent percent signal change compared to the implicit session baseline. Coordinates refer to MNI coordinates at which the image is displayed.</p></div></div><p class="chapter-para">Next we compared the effect of fearful content in the sentences presented together with the pictures. Comparing fearful sentences presented with pictures to non-fearful sentences presented with pictures (sent_fear_pict &gt; sent_nofear_pict) revealed clusters of activation in left temporal pole, extending into the middle temporal sulcus and in the right cerebellum (<span class="xrefLink" id="jumplink-T2"></span><a href="javascript:;" reveal-id="T2" data-open="T2" class="link link-reveal link-table xref-fig">Table 2</a> and <span class="xrefLink" id="jumplink-F5"></span><a href="javascript:;" reveal-id="F5" data-open="F5" class="link link-reveal link-table xref-fig">Figure 5</a>). Informal inspection at the <em>P</em> &lt; 0.001 uncorrected level also revealed activations in the right temporal pole and in the left amygdala. The opposite contrast (sent_nofear_pict &gt; sent_fear_pict) revealed no activations. </p>                        <a id="126925848" scrollto-destination="126925848"></a>
<div data-id="F5" class="fig fig-section"><div class="label fig-label">Fig. 5</div><div class="graphic-wrap"><img class="content-image" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050f5.jpeg?Expires=1605396424&amp;Signature=ixLhuMpe-AEJQ2j~V7M6jv5vGmwQo-xcF0tHvDD1sfV6WfzvxWAepgtRwpxX9Iq7dGq28mLBASiahuglKj1Z1nDdag865a2LrvIl8r1QoUDjEzjvd96kLhD2ncnE6771LuHTY35irQE4T1y8W7Zr4Se0XgHQcZxHL6nkDkUNalz0CufA83FpIbk582Eguxn2TrP0LEv3BSWKI-fH8jOmyGOF9CW6vCZTACCkItKJgiTEg3d7IqhaJm088-3rx73c0s-dqYASjO7GuG-Qz6mPC-y3TLh6uui~MNnIVBEdgONFtiTGU4Ymbeo8ktfa4~DCD88zy0-XNt7JVwpmjtVdTA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Results of whole brain analysis comparing sentences with fearful content combined with neutral pictures, to sentences without fearful content combined with the same pictures (sent_ fear_pict &gt; sent_nofear_pict). Note that the pictures were always neutral visual scenes, the emotional content was solely induced by the sentences. Results are corrected for multiple comparisons at the P &lt; 0.05 level. The bar graphs represent percent signal change compared to the implicit session baseline. Coordinates refer to MNI coordinates at which the image is displayed." data-path-from-xml="nsq050f5.jpeg" /><div class="fig-orig original-slide"><a class="fig-view-orig js-view-large openInAnotherWindow" href="/view-large/figure/126925848/nsq050f5.jpeg" data-path-from-xml="nsq050f5.jpeg" target="_blank">Open in new tab</a><a data-section="126925848" href="/DownloadFile/DownloadImage.aspx?image=https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/nsq050f5.jpeg?Expires=1605396424&Signature=slGOsHVCRuSFqBqk5ALvFxdYEuPHevm-JDTHvweSI9sOhfPCRrvWQ56wg5L2R8TL9edi8SPT93vuXafpL8YzOXvQ-FcISIQqMtZrALUtM77P5M4kWThjXJZQkqfhy8hn98A48mjAvKt5P85UO4DKnqTnvdjNz6WnBCpMl24T-KlrYqwt4cjqHLgwlQhTkwGDPFN~U8opsKIVOwUQR1ORGAZ2Ja82XiGZXk-VRV0Nbm5zyRST5C3q~GXsyMGgaZhc7kFScxQEeTZilIiYZQYysngqGS8lu579bNvxts9iMDYRVXM8MryABhcy1HJozsucvwNteU4FSbnY7jUY~Aa0Rw__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=126925848&ar=1647696&xsltPath=~/UI/app/XSLT&imagename=&siteId=5242" class="download-slide" data-path-from-xml="nsq050f5.jpeg">Download slide</a></div></div><div class="caption fig-caption"><p class="chapter-para">Results of whole brain analysis comparing sentences with fearful content combined with neutral pictures, to sentences without fearful content combined with the same pictures (sent_ fear_pict &gt; sent_nofear_pict). Note that the pictures were always neutral visual scenes, the emotional content was solely induced by the sentences. Results are corrected for multiple comparisons at the <em>P</em> &lt; 0.05 level. The bar graphs represent percent signal change compared to the implicit session baseline. Coordinates refer to MNI coordinates at which the image is displayed.</p></div></div><div content-id="F5" class="fig fig-modal reveal-modal"><div class="label fig-label">Fig. 5</div><div class="graphic-wrap"><img class="content-image" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050f5.jpeg?Expires=1605396424&amp;Signature=ixLhuMpe-AEJQ2j~V7M6jv5vGmwQo-xcF0tHvDD1sfV6WfzvxWAepgtRwpxX9Iq7dGq28mLBASiahuglKj1Z1nDdag865a2LrvIl8r1QoUDjEzjvd96kLhD2ncnE6771LuHTY35irQE4T1y8W7Zr4Se0XgHQcZxHL6nkDkUNalz0CufA83FpIbk582Eguxn2TrP0LEv3BSWKI-fH8jOmyGOF9CW6vCZTACCkItKJgiTEg3d7IqhaJm088-3rx73c0s-dqYASjO7GuG-Qz6mPC-y3TLh6uui~MNnIVBEdgONFtiTGU4Ymbeo8ktfa4~DCD88zy0-XNt7JVwpmjtVdTA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Results of whole brain analysis comparing sentences with fearful content combined with neutral pictures, to sentences without fearful content combined with the same pictures (sent_ fear_pict &gt; sent_nofear_pict). Note that the pictures were always neutral visual scenes, the emotional content was solely induced by the sentences. Results are corrected for multiple comparisons at the P &lt; 0.05 level. The bar graphs represent percent signal change compared to the implicit session baseline. Coordinates refer to MNI coordinates at which the image is displayed." data-path-from-xml="nsq050f5.jpeg" /><div class="fig-orig original-slide"><a class="fig-view-orig js-view-large openInAnotherWindow" href="/view-large/figure/126925848/nsq050f5.jpeg" data-path-from-xml="nsq050f5.jpeg" target="_blank">Open in new tab</a><a data-section="126925848" href="/DownloadFile/DownloadImage.aspx?image=https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/nsq050f5.jpeg?Expires=1605396424&Signature=slGOsHVCRuSFqBqk5ALvFxdYEuPHevm-JDTHvweSI9sOhfPCRrvWQ56wg5L2R8TL9edi8SPT93vuXafpL8YzOXvQ-FcISIQqMtZrALUtM77P5M4kWThjXJZQkqfhy8hn98A48mjAvKt5P85UO4DKnqTnvdjNz6WnBCpMl24T-KlrYqwt4cjqHLgwlQhTkwGDPFN~U8opsKIVOwUQR1ORGAZ2Ja82XiGZXk-VRV0Nbm5zyRST5C3q~GXsyMGgaZhc7kFScxQEeTZilIiYZQYysngqGS8lu579bNvxts9iMDYRVXM8MryABhcy1HJozsucvwNteU4FSbnY7jUY~Aa0Rw__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=126925848&ar=1647696&xsltPath=~/UI/app/XSLT&imagename=&siteId=5242" class="download-slide" data-path-from-xml="nsq050f5.jpeg">Download slide</a></div></div><div class="caption fig-caption"><p class="chapter-para">Results of whole brain analysis comparing sentences with fearful content combined with neutral pictures, to sentences without fearful content combined with the same pictures (sent_ fear_pict &gt; sent_nofear_pict). Note that the pictures were always neutral visual scenes, the emotional content was solely induced by the sentences. Results are corrected for multiple comparisons at the <em>P</em> &lt; 0.05 level. The bar graphs represent percent signal change compared to the implicit session baseline. Coordinates refer to MNI coordinates at which the image is displayed.</p></div></div><p class="chapter-para">Given our a priori hypothesis for the amygdala, we tested the same contrasts on the parameter estimates taken from anatomically defined ROIs in left and right amygdala separately. None of the ROIs showed the predicted interaction effect [(sent_fear_pict &gt; sent_nofear_pict) &gt; (sent_fear &gt; sent_nofear)] (all <em>t</em>’s &lt;1). Planned comparisons showed that there was a stronger response to fearful sentences as compared to non-fearful sentences (sent_fear &gt; sent_nofear), but this difference was not statistically significant in either left or right amygdala (<span class="xrefLink" id="jumplink-F6"></span><a href="javascript:;" reveal-id="F6" data-open="F6" class="link link-reveal link-table xref-fig">Figure 6</a>; one-sided <em>t</em>-tests: left: <em>t</em>(14) = 1.22, <em>P</em> = 0.11; right: <em>t</em>(14) = 1.12, <em>P</em> = 0.14). In both ROIs there was a stronger response to fearful sentences presented with pictures as compared to non-fearful sentences presented with pictures [one-sided <em>t</em>-tests: left: <em>t</em>(14) = 1.71, <em>P</em> = 0.045; right: <em>t</em>(14) = 1.62, <em>P</em> = 0.056]. This suggests that the increase in response to fearful sentence content was bigger when a picture was presented as when no picture was presented, but it should be noted that the interaction effect testing this additive effect was far from significant (see above). </p>                        <a id="126925850" scrollto-destination="126925850"></a>
<div data-id="F6" class="fig fig-section"><div class="label fig-label">Fig. 6</div><div class="graphic-wrap"><img class="content-image" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050f6.jpeg?Expires=1605396424&amp;Signature=Ya-16LGeIoTGPS0FoMbC0U~RFwCvYuGvP-2G6fo87ygD6yu9v1OdcTW3Je3kbpWxQ2m8cKaffQkn-gNr8-6CPhrJ8-mXqGfs7LA5ixWWbV2nKpIpshYrSb5K2DaoeAq93HxNgqPyTQrNZhFDiNN9wChdDuKkwc3MeRRxciEaEx~gfWkYZkRx-hIyw~jkWcTigHG7kpzroD3ByBtq1QPgJycQj2OCr1gL3-hVUq5IsoISzOZ-PXSFVLamoKVqhdxqAL14uF1~jVUI7J~KGweLShuBBiZh01Lx2c3z4FAeg4Q0890kYiTZHzY-5kF25bPplDNJVQxhuZ0W~dYVRfKB4Q__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Results of analysis in a priori defined ROIs in left and right amygdala. Presented are the parameter estimates (expressed as percentage signal change) to presentation of fearful (black) or non-fearful (white) sentences when presented alone (A), or when presented together with a neutral picture (B). The bar graphs represent percent signal change compared to the implicit session baseline. Asterisks indicate statistical significance at the P &lt; 0.05 level; n.s.: not significant." data-path-from-xml="nsq050f6.jpeg" /><div class="fig-orig original-slide"><a class="fig-view-orig js-view-large openInAnotherWindow" href="/view-large/figure/126925850/nsq050f6.jpeg" data-path-from-xml="nsq050f6.jpeg" target="_blank">Open in new tab</a><a data-section="126925850" href="/DownloadFile/DownloadImage.aspx?image=https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/nsq050f6.jpeg?Expires=1605396424&Signature=YS105vcL60-XWAnMJ1uBkXg7PaxO1iSu9n7BWR-EI~jC96BQi4gdWBoA4hezi0Us5MvtpR3lVmiert6anevcpcZ186gMsyAMrmx4mSWAsV79hKxuGfqMJQM-y~dH0OUdn4aB4T7Q39prqYDkXO8GoIlaeRZfGxnSBtQdD1ehEYZN7nI0DDsPEoJaeqGVD9pZbvGqOwC3IwM2noDbeCghc~iwuuXLbOUNGEubMebeJk3LDZK3WfDBQnkpioRKzeC86ljrKXrXVsKf38ijjw77MLR~wJAvsW18-EE0T3yUYVIrzLzjZfm0CObxQXouk73VOFt~pAdjkUdkKZF~oGuP1g__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=126925850&ar=1647696&xsltPath=~/UI/app/XSLT&imagename=&siteId=5242" class="download-slide" data-path-from-xml="nsq050f6.jpeg">Download slide</a></div></div><div class="caption fig-caption"><p class="chapter-para">Results of analysis in a priori defined ROIs in left and right amygdala. Presented are the parameter estimates (expressed as percentage signal change) to presentation of fearful (black) or non-fearful (white) sentences when presented alone (<strong>A</strong>), or when presented together with a neutral picture (<strong>B</strong>). The bar graphs represent percent signal change compared to the implicit session baseline. Asterisks indicate statistical significance at the <em>P</em> &lt; 0.05 level; n.s.: not significant.</p></div></div><div content-id="F6" class="fig fig-modal reveal-modal"><div class="label fig-label">Fig. 6</div><div class="graphic-wrap"><img class="content-image" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050f6.jpeg?Expires=1605396424&amp;Signature=Ya-16LGeIoTGPS0FoMbC0U~RFwCvYuGvP-2G6fo87ygD6yu9v1OdcTW3Je3kbpWxQ2m8cKaffQkn-gNr8-6CPhrJ8-mXqGfs7LA5ixWWbV2nKpIpshYrSb5K2DaoeAq93HxNgqPyTQrNZhFDiNN9wChdDuKkwc3MeRRxciEaEx~gfWkYZkRx-hIyw~jkWcTigHG7kpzroD3ByBtq1QPgJycQj2OCr1gL3-hVUq5IsoISzOZ-PXSFVLamoKVqhdxqAL14uF1~jVUI7J~KGweLShuBBiZh01Lx2c3z4FAeg4Q0890kYiTZHzY-5kF25bPplDNJVQxhuZ0W~dYVRfKB4Q__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Results of analysis in a priori defined ROIs in left and right amygdala. Presented are the parameter estimates (expressed as percentage signal change) to presentation of fearful (black) or non-fearful (white) sentences when presented alone (A), or when presented together with a neutral picture (B). The bar graphs represent percent signal change compared to the implicit session baseline. Asterisks indicate statistical significance at the P &lt; 0.05 level; n.s.: not significant." data-path-from-xml="nsq050f6.jpeg" /><div class="fig-orig original-slide"><a class="fig-view-orig js-view-large openInAnotherWindow" href="/view-large/figure/126925850/nsq050f6.jpeg" data-path-from-xml="nsq050f6.jpeg" target="_blank">Open in new tab</a><a data-section="126925850" href="/DownloadFile/DownloadImage.aspx?image=https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/nsq050f6.jpeg?Expires=1605396424&Signature=YS105vcL60-XWAnMJ1uBkXg7PaxO1iSu9n7BWR-EI~jC96BQi4gdWBoA4hezi0Us5MvtpR3lVmiert6anevcpcZ186gMsyAMrmx4mSWAsV79hKxuGfqMJQM-y~dH0OUdn4aB4T7Q39prqYDkXO8GoIlaeRZfGxnSBtQdD1ehEYZN7nI0DDsPEoJaeqGVD9pZbvGqOwC3IwM2noDbeCghc~iwuuXLbOUNGEubMebeJk3LDZK3WfDBQnkpioRKzeC86ljrKXrXVsKf38ijjw77MLR~wJAvsW18-EE0T3yUYVIrzLzjZfm0CObxQXouk73VOFt~pAdjkUdkKZF~oGuP1g__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=126925850&ar=1647696&xsltPath=~/UI/app/XSLT&imagename=&siteId=5242" class="download-slide" data-path-from-xml="nsq050f6.jpeg">Download slide</a></div></div><div class="caption fig-caption"><p class="chapter-para">Results of analysis in a priori defined ROIs in left and right amygdala. Presented are the parameter estimates (expressed as percentage signal change) to presentation of fearful (black) or non-fearful (white) sentences when presented alone (<strong>A</strong>), or when presented together with a neutral picture (<strong>B</strong>). The bar graphs represent percent signal change compared to the implicit session baseline. Asterisks indicate statistical significance at the <em>P</em> &lt; 0.05 level; n.s.: not significant.</p></div></div>                    <h3 scrollto-destination=126925851 id="126925851" class="section-title" >Results from presentation of pictures alone (run 3)</h3>
<p class="chapter-para">In run 3 the same pictures were presented as in runs 1 and 2. These pictures expressed neutral scenes, which could have been paired with a fearful sentence (pict_fear), with a non-fearful sentence (pict_nofear) or without a sentence (pict_nosent) in runs 1 and 2. It is important to stress that the suffixes ‘_fear’, ‘_nofear’ and ‘_nosent’ refer to the presentation condition in runs 1 and 2; in run 3 pictures were always presented without a sentence.</p><p class="chapter-para">We first compared neural responses to pictures previously paired with a fearful sentence (pict_fear) with pictures presented with a non-fearful sentence (pict_nofear). This led to a large subcortical cluster of activation encompassing the caudate nucleus bilaterally, as well as the thalamus bilaterally (<span class="xrefLink" id="jumplink-T3"></span><a href="javascript:;" reveal-id="T3" data-open="T3" class="link link-reveal link-table xref-fig">Table 3</a> and <span class="xrefLink" id="jumplink-F7"></span><a href="javascript:;" reveal-id="F7" data-open="F7" class="link link-reveal link-table xref-fig">Figure 7</a>A). </p>                        <a id="126925854" scrollto-destination="126925854"></a>
<div data-id="F7" class="fig fig-section"><div class="label fig-label">Fig. 7</div><div class="graphic-wrap"><img class="content-image" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050f7.jpeg?Expires=1605396424&amp;Signature=xhmBclo6u7uQx2vadV8Wdy13bl~qdqj2ByoYYb-cuMhSukqrHvmBkeEj-HLjbJPsbKId~nLi9ivDh01Tt2rVyLRux9~nQbh3kY6boeaWVkwh6FXWWfeLslWjJ6YylFCWSw3EEiEnjdUoSZ8FZdbViMkf7vcpuULUDgeKZSH5K38IMKkOc-sIuLGt5bRCrrrQLureESDFEVkHlPr4w-vu-xTRg1czTJOjw2Wmirrknzt3sZ-hzcN8~Wfk6WA1N6PlkXM6jG-DwSr1Q6A0KrnDbVdYM29q8kKASnscjexFRpSSnK4tLVgB0Gv-6flCrVfDGDXOdqrQojhDHg~zbqDHIw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Results of whole brain analysis of the data from run 3, in which only pictures were presented. (A) Areas are shown that were more strongly activated to the presentation of the pictures that were previously paired with fearful sentences as compared to pictures that were paired with neutral sentences (Pict_fear &gt; Pict_nofear). Results are corrected for multiple comparisons at the P &lt; 0.05 level. (B) Responses in a priori defined ROIs in left and right amygdala to presentation of pictures that were previously paired with fearful sentences, neutral sentences, or pictures without a concomitant sentence. The bar graphs represent percent signal change compared to the implicit session baseline. Asterisks indicate statistical significance at the P &lt; 0.05 level; n.s.: not significant." data-path-from-xml="nsq050f7.jpeg" /><div class="fig-orig original-slide"><a class="fig-view-orig js-view-large openInAnotherWindow" href="/view-large/figure/126925854/nsq050f7.jpeg" data-path-from-xml="nsq050f7.jpeg" target="_blank">Open in new tab</a><a data-section="126925854" href="/DownloadFile/DownloadImage.aspx?image=https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/nsq050f7.jpeg?Expires=1605396424&Signature=w7jKnTkV5WQDJGlm6wU6gVsHbmawlQkqVzeJuDoLAYzNnWjWyYQ2H9vR1s5VqtEfCHsg88~1GUKJo7pSZ8BJQ7~X17q9rN~xzbNHV-wXOLTcOh0tqXHBEAqQjFB3UaiMDnohgnsDlVHDUnhIGCovr~wBviFS90x9ei7NtEgTpOLuyEzyYiAmO2Wl5qbPyxQF89nmKH9uXa8yOI8Ntz0VKjx04HiPHTWb2Wa9bYoopB~Q5DDNRK9jpy-1ujHOCnA0pb4TYGCtKXMF9WvamHPmKEtccuaRZuwnOk8XZ0pNc9l0iek0gGIYa1jQYcD19XboushA7rwhgnZGXDXIe587Gw__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=126925854&ar=1647696&xsltPath=~/UI/app/XSLT&imagename=&siteId=5242" class="download-slide" data-path-from-xml="nsq050f7.jpeg">Download slide</a></div></div><div class="caption fig-caption"><p class="chapter-para">Results of whole brain analysis of the data from run 3, in which only pictures were presented. (<strong>A</strong>) Areas are shown that were more strongly activated to the presentation of the pictures that were previously paired with fearful sentences as compared to pictures that were paired with neutral sentences (Pict_fear &gt; Pict_nofear). Results are corrected for multiple comparisons at the <em>P</em> &lt; 0.05 level. (<strong>B</strong>) Responses in a priori defined ROIs in left and right amygdala to presentation of pictures that were previously paired with fearful sentences, neutral sentences, or pictures without a concomitant sentence. The bar graphs represent percent signal change compared to the implicit session baseline. Asterisks indicate statistical significance at the <em>P</em> &lt; 0.05 level; n.s.: not significant.</p></div></div><div content-id="F7" class="fig fig-modal reveal-modal"><div class="label fig-label">Fig. 7</div><div class="graphic-wrap"><img class="content-image" src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/m_nsq050f7.jpeg?Expires=1605396424&amp;Signature=xhmBclo6u7uQx2vadV8Wdy13bl~qdqj2ByoYYb-cuMhSukqrHvmBkeEj-HLjbJPsbKId~nLi9ivDh01Tt2rVyLRux9~nQbh3kY6boeaWVkwh6FXWWfeLslWjJ6YylFCWSw3EEiEnjdUoSZ8FZdbViMkf7vcpuULUDgeKZSH5K38IMKkOc-sIuLGt5bRCrrrQLureESDFEVkHlPr4w-vu-xTRg1czTJOjw2Wmirrknzt3sZ-hzcN8~Wfk6WA1N6PlkXM6jG-DwSr1Q6A0KrnDbVdYM29q8kKASnscjexFRpSSnK4tLVgB0Gv-6flCrVfDGDXOdqrQojhDHg~zbqDHIw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Results of whole brain analysis of the data from run 3, in which only pictures were presented. (A) Areas are shown that were more strongly activated to the presentation of the pictures that were previously paired with fearful sentences as compared to pictures that were paired with neutral sentences (Pict_fear &gt; Pict_nofear). Results are corrected for multiple comparisons at the P &lt; 0.05 level. (B) Responses in a priori defined ROIs in left and right amygdala to presentation of pictures that were previously paired with fearful sentences, neutral sentences, or pictures without a concomitant sentence. The bar graphs represent percent signal change compared to the implicit session baseline. Asterisks indicate statistical significance at the P &lt; 0.05 level; n.s.: not significant." data-path-from-xml="nsq050f7.jpeg" /><div class="fig-orig original-slide"><a class="fig-view-orig js-view-large openInAnotherWindow" href="/view-large/figure/126925854/nsq050f7.jpeg" data-path-from-xml="nsq050f7.jpeg" target="_blank">Open in new tab</a><a data-section="126925854" href="/DownloadFile/DownloadImage.aspx?image=https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/scan/6/4/10.1093_scan_nsq050/4/nsq050f7.jpeg?Expires=1605396424&Signature=w7jKnTkV5WQDJGlm6wU6gVsHbmawlQkqVzeJuDoLAYzNnWjWyYQ2H9vR1s5VqtEfCHsg88~1GUKJo7pSZ8BJQ7~X17q9rN~xzbNHV-wXOLTcOh0tqXHBEAqQjFB3UaiMDnohgnsDlVHDUnhIGCovr~wBviFS90x9ei7NtEgTpOLuyEzyYiAmO2Wl5qbPyxQF89nmKH9uXa8yOI8Ntz0VKjx04HiPHTWb2Wa9bYoopB~Q5DDNRK9jpy-1ujHOCnA0pb4TYGCtKXMF9WvamHPmKEtccuaRZuwnOk8XZ0pNc9l0iek0gGIYa1jQYcD19XboushA7rwhgnZGXDXIe587Gw__&Key-Pair-Id=APKAIE5G5CRDK6RD3PGA&sec=126925854&ar=1647696&xsltPath=~/UI/app/XSLT&imagename=&siteId=5242" class="download-slide" data-path-from-xml="nsq050f7.jpeg">Download slide</a></div></div><div class="caption fig-caption"><p class="chapter-para">Results of whole brain analysis of the data from run 3, in which only pictures were presented. (<strong>A</strong>) Areas are shown that were more strongly activated to the presentation of the pictures that were previously paired with fearful sentences as compared to pictures that were paired with neutral sentences (Pict_fear &gt; Pict_nofear). Results are corrected for multiple comparisons at the <em>P</em> &lt; 0.05 level. (<strong>B</strong>) Responses in a priori defined ROIs in left and right amygdala to presentation of pictures that were previously paired with fearful sentences, neutral sentences, or pictures without a concomitant sentence. The bar graphs represent percent signal change compared to the implicit session baseline. Asterisks indicate statistical significance at the <em>P</em> &lt; 0.05 level; n.s.: not significant.</p></div></div>                        <a id="126925855" scrollto-destination="126925855"></a>
<div content-id="T3" class="table-modal table-full-width-wrap"><div class="table-wrap table-wide"><div class="table-wrap-title" id="T3" data-id="T3"><span class="label">Table 3</span><div class="caption"><p class="chapter-para">Results from whole brain analysis of run 3 in which only picture were presented</p></div> </div><div class="table-overflow"><table><thead><tr><th>Comparison<span aria-hidden="true" style="display: none;">
            . </span></th><th>MNI coordinates (<em>x, y, z</em>)<span aria-hidden="true" style="display: none;">
            . </span></th><th><em>T</em>(max)<span aria-hidden="true" style="display: none;">
            . </span></th><th>Size (2 × 2 × 2 mm voxels)<span aria-hidden="true" style="display: none;">
            . </span></th></tr></thead><tbody><tr><td><em>Pict_fear&gt;Pict_nofear</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Thalamus bilateral </td><td>−8,   −4, 0 </td><td>5.46 </td><td>734 </td></tr><tr><td>     </td><td>−2,  2, −4 </td><td> </td><td> </td></tr><tr><td>    Left caudate nucleus </td><td>−5, 11,   10 </td><td>3.38 </td><td> </td></tr><tr><td>    Right caudate nucleus </td><td>  10, 13, 9 </td><td>3.58 </td><td> </td></tr><tr><td>     </td><td> </td><td> </td><td> </td></tr><tr><td>    Left cerebellum </td><td>−32,  −78, −32 </td><td>5.89 </td><td>177 </td></tr><tr><td><em>Pict_fear&gt;Pict_nosent</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Thalamus bilaterally </td><td>4,  −2,  2 </td><td>6.55 </td><td>793 </td></tr><tr><td>     </td><td>−8,  −6, −2 </td><td> </td><td> </td></tr><tr><td>    Left caudate nucleus </td><td>−11,   10, 2 </td><td>3.72 </td><td> </td></tr><tr><td>     </td><td>−7,   12,   10 </td><td> </td><td> </td></tr><tr><td>    Right cerebellum </td><td>  12, −78, −36 </td><td>4.41 </td><td>189 </td></tr><tr><td>     </td><td>  36, −74, −36 </td><td> </td><td> </td></tr><tr><td>     </td><td>  24, −78, −38 </td><td> </td><td> </td></tr></tbody></table></div><div class="table-modal"><table><thead><tr><th>Comparison<span aria-hidden="true" style="display: none;">
            . </span></th><th>MNI coordinates (<em>x, y, z</em>)<span aria-hidden="true" style="display: none;">
            . </span></th><th><em>T</em>(max)<span aria-hidden="true" style="display: none;">
            . </span></th><th>Size (2 × 2 × 2 mm voxels)<span aria-hidden="true" style="display: none;">
            . </span></th></tr></thead><tbody><tr><td><em>Pict_fear&gt;Pict_nofear</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Thalamus bilateral </td><td>−8,   −4, 0 </td><td>5.46 </td><td>734 </td></tr><tr><td>     </td><td>−2,  2, −4 </td><td> </td><td> </td></tr><tr><td>    Left caudate nucleus </td><td>−5, 11,   10 </td><td>3.38 </td><td> </td></tr><tr><td>    Right caudate nucleus </td><td>  10, 13, 9 </td><td>3.58 </td><td> </td></tr><tr><td>     </td><td> </td><td> </td><td> </td></tr><tr><td>    Left cerebellum </td><td>−32,  −78, −32 </td><td>5.89 </td><td>177 </td></tr><tr><td><em>Pict_fear&gt;Pict_nosent</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Thalamus bilaterally </td><td>4,  −2,  2 </td><td>6.55 </td><td>793 </td></tr><tr><td>     </td><td>−8,  −6, −2 </td><td> </td><td> </td></tr><tr><td>    Left caudate nucleus </td><td>−11,   10, 2 </td><td>3.72 </td><td> </td></tr><tr><td>     </td><td>−7,   12,   10 </td><td> </td><td> </td></tr><tr><td>    Right cerebellum </td><td>  12, −78, −36 </td><td>4.41 </td><td>189 </td></tr><tr><td>     </td><td>  36, −74, −36 </td><td> </td><td> </td></tr><tr><td>     </td><td>  24, −78, −38 </td><td> </td><td> </td></tr></tbody></table></div><div class="table-wrap-foot"><span id="fn-TF3"></span><div content-id="TF3"><div class="fn"><p class="chapter-para">Pictures were paired in runs 1 and 2 with a fearful sentence (Pict_fear), with a non-fear sentence (Pict_nofear), or presented without a sentence (Pict_nosent). Note that the results displayed here reflect brain activations that were obtained when only the pictures were presented. The ‘fear’ and ‘nofear’ suffixes relate to the presentation of the picture with a fearful or non-fearful sentence in the <em>previous </em>runs. The pictures themselves were neutral. The table shows the specific comparison, a description of the activated region, the MNI coordinates, the <em>t</em>-value of peak activations within a cluster, as well as the size of each cluster in number of voxels (2 × 2 × 2 voxels). Results are corrected for multiple comparisons at the <em>P</em> &lt; 0.05 level.</p></div></div></div><div class="graphic-wrap"><a class="fig-view-orig openInAnotherWindow btn js-view-large" href="/view-large/126925855" target="_blank">Open in new tab</a></div></div></div><div class="table-full-width-wrap"><div class="table-wrap table-wide"><div class="table-wrap-title" id="T3" data-id="T3"><span class="label">Table 3</span><div class="caption"><p class="chapter-para">Results from whole brain analysis of run 3 in which only picture were presented</p></div> </div><div class="table-overflow"><table><thead><tr><th>Comparison<span aria-hidden="true" style="display: none;">
            . </span></th><th>MNI coordinates (<em>x, y, z</em>)<span aria-hidden="true" style="display: none;">
            . </span></th><th><em>T</em>(max)<span aria-hidden="true" style="display: none;">
            . </span></th><th>Size (2 × 2 × 2 mm voxels)<span aria-hidden="true" style="display: none;">
            . </span></th></tr></thead><tbody><tr><td><em>Pict_fear&gt;Pict_nofear</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Thalamus bilateral </td><td>−8,   −4, 0 </td><td>5.46 </td><td>734 </td></tr><tr><td>     </td><td>−2,  2, −4 </td><td> </td><td> </td></tr><tr><td>    Left caudate nucleus </td><td>−5, 11,   10 </td><td>3.38 </td><td> </td></tr><tr><td>    Right caudate nucleus </td><td>  10, 13, 9 </td><td>3.58 </td><td> </td></tr><tr><td>     </td><td> </td><td> </td><td> </td></tr><tr><td>    Left cerebellum </td><td>−32,  −78, −32 </td><td>5.89 </td><td>177 </td></tr><tr><td><em>Pict_fear&gt;Pict_nosent</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Thalamus bilaterally </td><td>4,  −2,  2 </td><td>6.55 </td><td>793 </td></tr><tr><td>     </td><td>−8,  −6, −2 </td><td> </td><td> </td></tr><tr><td>    Left caudate nucleus </td><td>−11,   10, 2 </td><td>3.72 </td><td> </td></tr><tr><td>     </td><td>−7,   12,   10 </td><td> </td><td> </td></tr><tr><td>    Right cerebellum </td><td>  12, −78, −36 </td><td>4.41 </td><td>189 </td></tr><tr><td>     </td><td>  36, −74, −36 </td><td> </td><td> </td></tr><tr><td>     </td><td>  24, −78, −38 </td><td> </td><td> </td></tr></tbody></table></div><div class="table-modal"><table><thead><tr><th>Comparison<span aria-hidden="true" style="display: none;">
            . </span></th><th>MNI coordinates (<em>x, y, z</em>)<span aria-hidden="true" style="display: none;">
            . </span></th><th><em>T</em>(max)<span aria-hidden="true" style="display: none;">
            . </span></th><th>Size (2 × 2 × 2 mm voxels)<span aria-hidden="true" style="display: none;">
            . </span></th></tr></thead><tbody><tr><td><em>Pict_fear&gt;Pict_nofear</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Thalamus bilateral </td><td>−8,   −4, 0 </td><td>5.46 </td><td>734 </td></tr><tr><td>     </td><td>−2,  2, −4 </td><td> </td><td> </td></tr><tr><td>    Left caudate nucleus </td><td>−5, 11,   10 </td><td>3.38 </td><td> </td></tr><tr><td>    Right caudate nucleus </td><td>  10, 13, 9 </td><td>3.58 </td><td> </td></tr><tr><td>     </td><td> </td><td> </td><td> </td></tr><tr><td>    Left cerebellum </td><td>−32,  −78, −32 </td><td>5.89 </td><td>177 </td></tr><tr><td><em>Pict_fear&gt;Pict_nosent</em> </td><td> </td><td> </td><td> </td></tr><tr><td>    Thalamus bilaterally </td><td>4,  −2,  2 </td><td>6.55 </td><td>793 </td></tr><tr><td>     </td><td>−8,  −6, −2 </td><td> </td><td> </td></tr><tr><td>    Left caudate nucleus </td><td>−11,   10, 2 </td><td>3.72 </td><td> </td></tr><tr><td>     </td><td>−7,   12,   10 </td><td> </td><td> </td></tr><tr><td>    Right cerebellum </td><td>  12, −78, −36 </td><td>4.41 </td><td>189 </td></tr><tr><td>     </td><td>  36, −74, −36 </td><td> </td><td> </td></tr><tr><td>     </td><td>  24, −78, −38 </td><td> </td><td> </td></tr></tbody></table></div><div class="table-wrap-foot"><span id="fn-TF3"></span><div content-id="TF3"><div class="fn"><p class="chapter-para">Pictures were paired in runs 1 and 2 with a fearful sentence (Pict_fear), with a non-fear sentence (Pict_nofear), or presented without a sentence (Pict_nosent). Note that the results displayed here reflect brain activations that were obtained when only the pictures were presented. The ‘fear’ and ‘nofear’ suffixes relate to the presentation of the picture with a fearful or non-fearful sentence in the <em>previous </em>runs. The pictures themselves were neutral. The table shows the specific comparison, a description of the activated region, the MNI coordinates, the <em>t</em>-value of peak activations within a cluster, as well as the size of each cluster in number of voxels (2 × 2 × 2 voxels). Results are corrected for multiple comparisons at the <em>P</em> &lt; 0.05 level.</p></div></div></div><div class="graphic-wrap"><a class="fig-view-orig openInAnotherWindow btn js-view-large" href="/view-large/126925855" target="_blank">Open in new tab</a></div></div></div><p class="chapter-para">Next we compared the observation of pictures previously paired with a fearful sentence (pict_fear) to pictures previously presented without sentence (pict_nosent). This comparison led to activation in essentially the same cluster of activation as the previous comparison, that is, bilateral caudate nucleus and thalamus (<span class="xrefLink" id="jumplink-T3"></span><a href="javascript:;" reveal-id="T3" data-open="T3" class="link link-reveal link-table xref-fig">Table 3</a>).</p><p class="chapter-para">Finally, we assessed responses to pictures previously presented with a non-fear sentence (pict_nofear) to pictures previously presented without a sentence (pict_nosent). No areas were activated in this contrast.</p><p class="chapter-para">As in the analysis of the sentence-picture pairs, we assessed responses of left and right amygdala to the three picture conditions. There was no main effect of Condition in either left or right amygdala [left: <em>F</em>(2,42) &lt;1; right: <em>F</em>(2,42) &lt;1). Follow-up planned comparisons showed that in left amygdala the response to pictures that were paired with a fearful sentence was significantly higher than to pictures that were previously paired with a non-fearful sentence [one-sided <em>t</em>-test: <em>t</em>(14) = 1.71, <em>P</em> = 0.055; <span class="xrefLink" id="jumplink-F7"></span><a href="javascript:;" reveal-id="F7" data-open="F7" class="link link-reveal link-table xref-fig">Figure 7</a>B]. Moreover, pictures that were previously presented with a fearful sentence elicited stronger responses that pictures presented without a sentence [pict_fear &gt; pict_nosent: <em>t</em>(14) = 2.10, <em>P</em> = 0.027, one-sided; <span class="xrefLink" id="jumplink-F7"></span><a href="javascript:;" reveal-id="F7" data-open="F7" class="link link-reveal link-table xref-fig">Figure 7</a>B]. No such effect was observed for the pictures previously presented with a non-fearful sentence [pict_nofear &gt; pict_nosent: <em>t</em>(14) &lt;1]. A similar pattern of responses was observed in right amygdala although the pict_fear versus pict_nofear difference was not statistically significant [pict_fear &gt; pict_nofear: <em>t</em>(14) = 1.29, <em>P</em> = 0.108, one-sided; pict_fear &gt; pict_nosent: <em>t</em>(14) = 1.79, <em>P</em> = 0.048, one-sided; pict_nofear &gt; pict_nosent: <em>t</em>(14) &lt; 1).</p>                    <h2 scrollto-destination=126925859 id="126925859" class="section-title" >DISCUSSION</h2>
<p class="chapter-para">In the current study we had participants read emotion-inducing (‘fearful’) or less emotional (‘non-fearful’) sentences either presented together with a neutral visual scene, or without a visual scene. We had three experimental questions: first, we asked whether there are brain areas that show an additive response to the combination of sentences and neutral pictures, when the sentence context is emotional/fearful. Second, we looked at whether the fearful content of sentences influences activation levels in parts of the brain involved in emotion. Finally, we looked at how pairing a neutral picture with a fearful sentence influences later processing of this picture when presented without a sentence context.</p>                    <h3 scrollto-destination=126925861 id="126925861" class="section-title" >Interaction of language and picture in emotional processing</h3>
<p class="chapter-para">In the Introduction section we predicted an additive effect of adding a (neutral) picture to an emotion-inducing sentence, a prediction that we derived from film theory. The prediction was that the difference between fearful sentences combined with a picture as compared to non-fearful sentences combined with a picture, would be bigger than the fearful versus non-fearful sentences presented on their own. The right amygdala shows the predicted response pattern, in the sense that the response to fearful as compared to non-fearful sentences presented together with pictures is significantly different, and the difference between fearful sentences as compared to non-fearful sentences when presented on their own is not (<span class="xrefLink" id="jumplink-F3"></span><a href="javascript:;" reveal-id="F3" data-open="F3" class="link link-reveal link-table xref-fig">Figure 3</a>). This effect is not robust however, given that the interaction effect was far from statistically significant.</p><p class="chapter-para">The only region to show the additive pattern of adding a picture on processing of the emotional picture was the right temporal pole. This finding is closely related to the results of Mobbs and colleagues who showed a similar context effect on right temporal pole activation in response to the processing of faces (<span class="xrefLink" id="jumplink-B29"></span><a href="javascript:;" reveal-id="B29" data-open="B29" class="link link-ref link-reveal xref-bibr">Mobbs <em>et al.</em>, 2006</a>). Participants rated the emotional expression of faces that could be preceded by movie clips with positive or negative content. Right temporal pole showed a stronger activation difference to fearful as compared to neutral faces when the faces where preceded by a negative context as compared to when they were presented by a neutral context. Interestingly, a similar interaction effect was observed for happy faces preceded by a positive context, suggesting a general binding role for the temporal poles of emotional information.</p><p class="chapter-para">Anatomically the temporal poles are ideally situated to exhibit such a binding effect: They are strongly connected to the limbic system (including the amygdala) as well as with the insular cortex and the sensory cortices (<span class="xrefLink" id="jumplink-B27"></span><a href="javascript:;" reveal-id="B27" data-open="B27" class="link link-ref link-reveal xref-bibr">Mesulam, 2000</a>; <span class="xrefLink" id="jumplink-B31"></span><a href="javascript:;" reveal-id="B31" data-open="B31" class="link link-ref link-reveal xref-bibr">Olson <em>et al.</em>, 2007</a>). Atrophy to the right temporal pole leads to marked personality changes, mostly involving a reduction of emotional expressiveness (e.g. <span class="xrefLink" id="jumplink-B14"></span><a href="javascript:;" reveal-id="B14" data-open="B14" class="link link-ref link-reveal xref-bibr">Gorno-Tempini <em>et al.</em>, 2004</a>). In their comprehensive review of the literature Olson and colleagues conclude that the temporal poles’ main function is to ‘couple emotional responses to highly processed sensory stimuli’ (<span class="xrefLink" id="jumplink-B31"></span><a href="javascript:;" reveal-id="B31" data-open="B31" class="link link-ref link-reveal xref-bibr">Olson <em>et al.</em>, 2007</a>, p. 1727). In line with this we interpret the additive effect that we observed in the right temporal pole as reflecting binding of visual and linguistic information under conditions of increased emotional content. The emotional component is crucial, since no ‘general’ binding of linguistic and visual information was observed in this region (see also <span class="xrefLink" id="jumplink-B29"></span><a href="javascript:;" reveal-id="B29" data-open="B29" class="link link-ref link-reveal xref-bibr">Mobbs <em>et al.</em>, 2006</a>).</p><p class="chapter-para">Somewhat at odds with this interpretation is a study by Kim and colleagues in which the effect of positive or negative sentences on subsequent processing of faces was assessed (<span class="xrefLink" id="jumplink-B22"></span><a href="javascript:;" reveal-id="B22" data-open="B22" class="link link-ref link-reveal xref-bibr">Kim <em>et al.</em>, 2004</a>). Participants read sentence like ‘She just lost $500’ versus ‘She just found $500’ and saw a picture of a face with a surprised expression immediately afterwards. No effect of context was observed in the temporal poles. On the contrary, left amygdala was more strongly activated to faces preceded by a negative sentence as compared to faces preceded by a positive sentence, but was not sensitive to the valence expressed by the sentences as such. The latter is in accordance with our present finding, but we did no observe a robust interaction between presence of a picture and valence expressed in the sentences in the amygdala. It is unclear why Kim and colleagues did not find modulation of the temporal poles whereas Mobbs <em>et al.</em>’s data as well as the present finding suggest that the temporal poles serve a binding function of emotionally salient information.</p><p class="chapter-para">A related interpretation refers to the role of the temporal poles in language processing, especially when language comprehension goes beyond single sentence comprehension, such as when participants read short stories as compared to a set of sentences that are thematically unlinked (<span class="xrefLink" id="jumplink-B10"></span><a href="javascript:;" reveal-id="B10" data-open="B10" class="link link-ref link-reveal xref-bibr">Ferstl <em>et al.</em>, 2008</a>). In our experiment it may be that the fearful sentences engaged participants more, and that they formed a richer interpretation of the fearful sentence—picture pairs as compared to the non-fearful sentence—picture pairs. This interpretation is unlikely since the right temporal pole was not activated above baseline in two of the four conditions, despite the fact that these involved linguistic materials (<span class="xrefLink" id="jumplink-F3"></span><a href="javascript:;" reveal-id="F3" data-open="F3" class="link link-reveal link-table xref-fig">Figure 3</a>).</p>                    <h3 scrollto-destination=126925867 id="126925867" class="section-title" >Emotion-inducing language</h3>
<p class="chapter-para">An overall effect of reading fearful as compared to non-fearful sentences was observed in parts of the brain traditionally implicated in language understanding such as left inferior frontal gyrus and bilateral middle temporal gyri. These areas are implicated in language comprehension, including semantic aspects of sentence comprehension (e.g. <span class="xrefLink" id="jumplink-B18"></span><a href="javascript:;" reveal-id="B18" data-open="B18" class="link link-ref link-reveal xref-bibr">Hagoort <em>et al.</em>, 2004</a>, <span class="xrefLink" id="jumplink-B17"></span><a href="javascript:;" reveal-id="B17" data-open="B17" class="link link-ref link-reveal xref-bibr">2009</a>; <span class="xrefLink" id="jumplink-B16"></span><a href="javascript:;" reveal-id="B16" data-open="B16" class="link link-ref link-reveal xref-bibr">Hagoort, 2005</a>; <span class="xrefLink" id="jumplink-B50"></span><a href="javascript:;" reveal-id="B50" data-open="B50" class="link link-ref link-reveal xref-bibr">Willems, <em>et al.</em>, 2007</a>, <span class="xrefLink" id="jumplink-B51"></span><a href="javascript:;" reveal-id="B51" data-open="B51" class="link link-ref link-reveal xref-bibr">2008b</a>, <span class="xrefLink" id="jumplink-B52"></span><a href="javascript:;" reveal-id="B52" data-open="B52" class="link link-ref link-reveal xref-bibr">2009</a>). Holt and colleagues showed that emotional endings of single sentences lead to an increased N400 amplitude, an indicator of semantic processing as derived from electro-encephalography (<span class="xrefLink" id="jumplink-B20"></span><a href="javascript:;" reveal-id="B20" data-open="B20" class="link link-ref link-reveal xref-bibr">Holt <em>et al.</em>, 2009</a>). Also previous neuroimaging studies report similar increases in left inferior frontal and/or middle temporal regions to processing of emotional as compared to more neutral single words (<span class="xrefLink" id="jumplink-B5"></span><a href="javascript:;" reveal-id="B5" data-open="B5" class="link link-ref link-reveal xref-bibr">Beauregard <em>et al.</em>, 1997</a>; <span class="xrefLink" id="jumplink-B41"></span><a href="javascript:;" reveal-id="B41" data-open="B41" class="link link-ref link-reveal xref-bibr">Strange <em>et al.</em>, 2000</a>; <span class="xrefLink" id="jumplink-B6"></span><a href="javascript:;" reveal-id="B6" data-open="B6" class="link link-ref link-reveal xref-bibr">Cato <em>et al.</em>, 2004</a>; <span class="xrefLink" id="jumplink-B24"></span><a href="javascript:;" reveal-id="B24" data-open="B24" class="link link-ref link-reveal xref-bibr">Kuchinke <em>et al.</em>, 2005</a>; <span class="xrefLink" id="jumplink-B4"></span><a href="javascript:;" reveal-id="B4" data-open="B4" class="link link-ref link-reveal xref-bibr">Beaucousin <em>et al.</em>, 2007</a>; <span class="xrefLink" id="jumplink-B38"></span><a href="javascript:;" reveal-id="B38" data-open="B38" class="link link-ref link-reveal xref-bibr">Razafimandimby <em>et al.</em>, 2009</a>). Hence it is conceivable that reading of fearful sentences leads to stronger semantic processing which explains the increased activation in LIFG and middle temporal gyri that we observed. Interestingly, in our study this was not a consequence of the activation of lexical items with a strong emotional valence. The individual words that made up the emotion-inducing sentences were not themselves emotion words. This implies that the emotional content of the sentences was inferred through a compositional process that creates an emotional interpretation from non-emotional lexical building blocks. The fact that the activation was also stronger in parts of temporal cortex presumably involved in lexical retrieval, supports the idea that semantic composition is instantiated by a dynamic interaction between areas involved in lexical retrieval and areas crucial for unification, such as inferior frontal cortex (see G. Baggio and P. Hagoort, submitted for publication; <span class="xrefLink" id="jumplink-B40"></span><a href="javascript:;" reveal-id="B40" data-open="B40" class="link link-ref link-reveal xref-bibr">Snijders <em>et al.</em>, 2009</a>).</p><p class="chapter-para">Interestingly, comparing sentences with a fearful/suspense type of content to sentences with more neutral content, but without a concomitant visual scene, revealed increased activation levels in the left anterior insula as well as in the left portion of the temporal pole. A large body of evidence implicates the insula in awareness of emotional stimuli (<span class="xrefLink" id="jumplink-B34"></span><a href="javascript:;" reveal-id="B34" data-open="B34" class="link link-ref link-reveal xref-bibr">Phan <em>et al.</em>, 2002</a>; <span class="xrefLink" id="jumplink-B23"></span><a href="javascript:;" reveal-id="B23" data-open="B23" class="link link-ref link-reveal xref-bibr">Kober <em>et al.</em>, 2008</a>), and it is especially the anterior portion of the insula that becomes activated when participants explicitly pay attention to interoceptive feelings (see <span class="xrefLink" id="jumplink-B7"></span><a href="javascript:;" reveal-id="B7" data-open="B7" class="link link-ref link-reveal xref-bibr">Craig, 2009</a>; <span class="xrefLink" id="jumplink-B39"></span><a href="javascript:;" reveal-id="B39" data-open="B39" class="link link-ref link-reveal xref-bibr">Singer <em>et al.</em>, 2009</a> for review). For instance, activation of the anterior insula is observed when participants smell unpleasant odors (leading to a negative emotion of disgust), as well as when they perceive others smelling an unpleasant odor which leads to a reaction of disgust in the perceived other (<span class="xrefLink" id="jumplink-B46"></span><a href="javascript:;" reveal-id="B46" data-open="B46" class="link link-ref link-reveal xref-bibr">Wicker <em>et al.</em>, 2003</a>). Similarly, the reading of the fearful sentences in this experiment may have led participants to ‘feel along’ with the implied meaning of the sentence.</p><p class="chapter-para">It should be noted that we did not replicate previous findings of amygdala involvement in the understanding of emotional/fearful language. We only observed that the amygdalae were sensitive to the emotional content of the sentences when they were paired with a visual stimulus. This is in contrast to some earlier studies that did find increased amygdala activation to language stimuli presented on their own. For instance <span class="xrefLink" id="jumplink-B21"></span><a href="javascript:;" reveal-id="B21" data-open="B21" class="link link-ref link-reveal xref-bibr">Isenberg and colleagues (1999)</a> showed increased amygdala activation to the reading of words like ‘threat’ and ‘hate’ as compared to more neutral words as ‘candle’ and ‘bookcase’ (see also <span class="xrefLink" id="jumplink-B41"></span><a href="javascript:;" reveal-id="B41" data-open="B41" class="link link-ref link-reveal xref-bibr">Strange <em>et al.</em>, 2000</a>; <span class="xrefLink" id="jumplink-B19"></span><a href="javascript:;" reveal-id="B19" data-open="B19" class="link link-ref link-reveal xref-bibr">Herbert <em>et al.</em>, 2009</a>). On the other hand, there are several studies that have failed to replicate this finding (<span class="xrefLink" id="jumplink-B5"></span><a href="javascript:;" reveal-id="B5" data-open="B5" class="link link-ref link-reveal xref-bibr">Beauregard <em>et al.</em>, 1997</a>; <span class="xrefLink" id="jumplink-B6"></span><a href="javascript:;" reveal-id="B6" data-open="B6" class="link link-ref link-reveal xref-bibr">Cato <em>et al.</em>, 2004</a>; <span class="xrefLink" id="jumplink-B24"></span><a href="javascript:;" reveal-id="B24" data-open="B24" class="link link-ref link-reveal xref-bibr">Kuchinke <em>et al.</em>, 2005</a>), or only observed amygdala activation to emotional words in an explicit categorization task (<span class="xrefLink" id="jumplink-B42"></span><a href="javascript:;" reveal-id="B42" data-open="B42" class="link link-ref link-reveal xref-bibr">Tabert <em>et al.</em>, 2001</a>). At present it is unclear why some studies do and others do not find amygdala activation in reaction to reading of emotional words. One reason may be decreased sensitivity in the amygdala due to its high sensitivity to susceptibility artifacts (<span class="xrefLink" id="jumplink-B25"></span><a href="javascript:;" reveal-id="B25" data-open="B25" class="link link-ref link-reveal xref-bibr">LaBar <em>et al.</em>, 2001</a>). This is an unlikely explanation in the present study since we did observe differential activation of the amygdala to the sentences when they were presented together with pictures. In the absence of a strong associative link between the individual words and their emotional content, the amygdala might need the input from the temporal pole to show an effect. The right temporal pole showed a clear increase in activation when emotion-inducing sentences were paired with the neutral pictures. As we hypothesized above, the temporal pole might play a role in grounding the compositional process of interpreting the implied emotional meaning of the sentences with a concrete visual scene referent. Thereby, a stronger emotional valence is generated, which is a trigger for the amygdala response.</p><p class="chapter-para">The involvement of the anterior insula in reading of emotional language is in line with the general notion that language understanding engages parts of the brain related to the content of the linguistic information. These include areas outside of the traditional language areas, such as in this case the insular cortex. A related finding is that when participants read about action-related language, parts of the cortical motor system become activated (e.g. <span class="xrefLink" id="jumplink-B47"></span><a href="javascript:;" reveal-id="B47" data-open="B47" class="link link-ref link-reveal xref-bibr">Willems and Hagoort, 2007</a>; <span class="xrefLink" id="jumplink-B3"></span><a href="javascript:;" reveal-id="B3" data-open="B3" class="link link-ref link-reveal xref-bibr">Barsalou, 2008</a>; <span class="xrefLink" id="jumplink-B48"></span><a href="javascript:;" reveal-id="B48" data-open="B48" class="link link-ref link-reveal xref-bibr">Willems <em>et al.</em>, 2010</a>). Here we add to this growing literature by showing involvement of a core region of the emotional system in the brain during reading about fearful as compared to less fearful sentence content.</p>                    <h3 scrollto-destination=126925872 id="126925872" class="section-title" >The influence of pairing a picture with an emotion-inducing sentence upon later processing of the picture</h3>
<p class="chapter-para">Finally, we noted that pairing neutral visual stimuli with a fearful sentence leads to increased activation in the amygdala when the neutral pictures are observed later, without being paired with a sentence. This shows that the emotional response to the picture–sentence pairs is retained and recalled at a later moment in time. Put differently, the sight of the picture alone triggers the emotional flavor of the linguistic information. The picture is tagged as emotionally salient by the linguistic information, and subsequent perception of the neutral picture brings back this emotional component to the previous stimulus pair. The present finding is reminiscent of the finding that labeling emotional faces with a word <em>decreases</em> amygdala activation upon subsequent perception of the faces (<span class="xrefLink" id="jumplink-B26"></span><a href="javascript:;" reveal-id="B26" data-open="B26" class="link link-ref link-reveal xref-bibr">Lieberman <em>et al.</em>, 2007</a>; see also <span class="xrefLink" id="jumplink-B43"></span><a href="javascript:;" reveal-id="B43" data-open="B43" class="link link-ref link-reveal xref-bibr">Tabibnia <em>et al.</em>, 2008</a>). The crucial difference between this earlier work and our present paper is that in the work by Lieberman and colleagues the visual stimuli were emotional/fearful on their own (fearful faces and disturbing visual scenes). Labeling of such stimuli with linguistic stimuli leads to a dampening of responses in the emotional system. On the contrary, in our study the visual scenes were inherently non-emotional/neutral. Combining such stimuli with emotional language leads to an enhancement of response in parts of the emotional brain system.</p><p class="chapter-para">The caudate nucleus was also more strongly activated to pictures that were previously paired with a fearful sentences as compared to pictures previously paired with a less fearful sentence. We did not have a hypothesis about activation of this area and we accordingly do not present a strong interpretation of its meaning. In their meta-analysis Kober and colleagues label the basal ganglia/striatum ‘reacting in response to salient events in the environment’ (<span class="xrefLink" id="jumplink-B23"></span><a href="javascript:;" reveal-id="B23" data-open="B23" class="link link-ref link-reveal xref-bibr">Kober <em>et al.</em>, 2008</a>, p. 1016), which seems an apt description of the pictures that were paired with the fearful sentences as compared to the pictures paired with the other sentences.</p>                    <h2 scrollto-destination=126925875 id="126925875" class="section-title" >CONCLUSION</h2>
<p class="chapter-para">In conclusion we observed that the right temporal pole showed an additive effect of adding a neutral picture to a fearful sentence (‘the movie effect’). This area presumably serves a binding role, combining visual and linguistic information when the content of the language is emotional. We also showed that reading sentences with fearful content leads to increased activation of left anterior insular cortex, which we interpret as a manifestation of the reader ‘moving along’ with the emotional meaning of the sentence. Future research should be aimed at investigating how the neural integration of information from different senses with language leads to the experience of emotions in general, and fear in particular.</p><p class="chapter-para">Supported by The Netherlands Organisation for scientific research (NWO) through a grant in the CO-OPs ‘Inter-territorial explorations in art and science’ program as well as by a ‘Rubicon’ grant (NWO 446-08-008) and by the Niels Stensen foundation. We thank two anonymous reviewers for helpful comments on an earlier version of the manuscript.</p>                    <h2 scrollto-destination=126925879 id="126925879" class="backreferences-title" >REFERENCES</h2>
<div class="ref-list"><div content-id="B1" data-legacy-id="B1"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B1" href="javascript:;" aria-label="jumplink-B1"></a></span></div><div class="ref false"><div id="ref-auto-B1" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Adolphs</div> <div class="given-names">R</div></div>. </span><div class="article-title">Fear, faces, and the human amygdala</div>, <div class="source ">Current Opinion in Neurobiology</div>, <div class="year">2008</div>, vol. <div class="volume">18</div> <div class="issue">2</div>(pg. <div class="fpage">166</div>-<div class="lpage">72</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Fear%2C%20faces%2C%20and%20the%20human%20amygdala&amp;author=R%20Adolphs&amp;publication_year=2008&amp;journal=Current%20Opinion%20in%20Neurobiology&amp;volume=18&amp;pages=166-72" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1016/j.conb.2008.06.006" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1016%2Fj.conb.2008.06.006" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1016%2Fj.conb.2008.06.006"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/18655833" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Fear%2C%20faces%2C%20and%20the%20human%20amygdala&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B2" data-legacy-id="B2"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B2" href="javascript:;" aria-label="jumplink-B2"></a></span></div><div class="ref false"><div id="ref-auto-B2" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Baayen</div> <div class="given-names">RH</div></div>,  <div class="name"><div class="surname">Piepenbrock</div> <div class="given-names">R</div></div>,  <div class="name"><div class="surname">Rijn</div> <div class="given-names">Hv</div></div>. </span>, <div class="source ">The CELEX Lexical Database</div>, <div class="year">1993</div><div class="publisher-loc">Philadelphia, PA</div><div class="publisher-name">Linguistic Data Consortium, University of Pennsylvania</div><!--citationLinks: case 2--><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=The%20CELEX%20Lexical%20Database&amp;author=RH%20Baayen&amp;author=R%20Piepenbrock&amp;author=Hv%20Rijn&amp;publication_year=1993&amp;book=The%20CELEX%20Lexical%20Database" target="_blank">Google Scholar</a></span></p><p class="citation-links-compatibility"><span class="google-preview-ref-link js-google-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.google.com/search?q=The%20CELEX%20Lexical%20Database&amp;btnG=Search+Books&amp;tbm=bks&amp;tbo=1" target="_blank">Google Preview</a></span></p><div class="xslopenurl empty-target"><span class="js-inst-open-url-holders-nodoi"><a class="openInAnotherWindow js-open-url-link" target="_blank" data-href-template="{targetURL}?sid=oup:orr&amp;genre=book&amp;title=The%20CELEX%20Lexical%20Database&amp;aulast=Baayen&amp;date=1993" href="javascript:;"><span class="screenreader-text">OpenURL Placeholder Text</span></a></span></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:The%20CELEX%20Lexical%20Database&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p><div class="copac-reference-ref-link js-copac-preview-ref-link" style="display:none" data-pubtype="book"><span class="inst-copac"><a class="openInAnotherWindow" target="_blank" href="http://copac.ac.uk/search?ti=The%20CELEX%20Lexical%20Database">COPAC</a></span></div> </div></div></div></div></div><div content-id="B3" data-legacy-id="B3"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B3" href="javascript:;" aria-label="jumplink-B3"></a></span></div><div class="ref false"><div id="ref-auto-B3" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Barsalou</div> <div class="given-names">LW</div></div>. </span><div class="article-title">Grounded cognition</div>, <div class="source ">Annual Review of Psychology</div>, <div class="year">2008</div>, vol. <div class="volume">59</div> (pg. <div class="fpage">617</div>-<div class="lpage">45</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Grounded%20cognition&amp;author=LW%20Barsalou&amp;publication_year=2008&amp;journal=Annual%20Review%20of%20Psychology&amp;volume=59&amp;pages=617-45" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1146/annurev.psych.59.103006.093639" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1146%2Fannurev.psych.59.103006.093639" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1146%2Fannurev.psych.59.103006.093639"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/17705682" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Grounded%20cognition&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B4" data-legacy-id="B4"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B4" href="javascript:;" aria-label="jumplink-B4"></a></span></div><div class="ref false"><div id="ref-auto-B4" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Beaucousin</div> <div class="given-names">V</div></div>,  <div class="name"><div class="surname">Lacheret</div> <div class="given-names">A</div></div>,  <div class="name"><div class="surname">Turbelin</div> <div class="given-names">MR</div></div>,  <div class="name"><div class="surname">Morel</div> <div class="given-names">M</div></div>,  <div class="name"><div class="surname">Mazoyer</div> <div class="given-names">B</div></div>,  <div class="name"><div class="surname">Tzourio-Mazoyer</div> <div class="given-names">N</div></div>. </span><div class="article-title">FMRI study of emotional speech comprehension</div>, <div class="source ">Cerebral Cortex</div>, <div class="year">2007</div>, vol. <div class="volume">17</div> <div class="issue">2</div>(pg. <div class="fpage">339</div>-<div class="lpage">52</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=FMRI%20study%20of%20emotional%20speech%20comprehension&amp;author=V%20Beaucousin&amp;author=A%20Lacheret&amp;author=MR%20Turbelin&amp;author=M%20Morel&amp;author=B%20Mazoyer&amp;author=N%20Tzourio-Mazoyer&amp;publication_year=2007&amp;journal=Cerebral%20Cortex&amp;volume=17&amp;pages=339-52" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1093/cercor/bhj151" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1093%2Fcercor%2Fbhj151" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1093%2Fcercor%2Fbhj151"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/16525130" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:FMRI%20study%20of%20emotional%20speech%20comprehension&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B5" data-legacy-id="B5"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B5" href="javascript:;" aria-label="jumplink-B5"></a></span></div><div class="ref false"><div id="ref-auto-B5" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Beauregard</div> <div class="given-names">M</div></div>,  <div class="name"><div class="surname">Chertkow</div> <div class="given-names">H</div></div>,  <div class="name"><div class="surname">Bub</div> <div class="given-names">D</div></div>,  <div class="name"><div class="surname">Murtha</div> <div class="given-names">S</div></div>,  <div class="name"><div class="surname">Dixon</div> <div class="given-names">R</div></div>,  <div class="name"><div class="surname">Evans</div> <div class="given-names">A</div></div>. </span><div class="article-title">The neural substrate for concrete, abstract, and emotional word lexica: a positron emission tomography study</div>, <div class="source ">Journal of Cognitive Neuroscience</div>, <div class="year">1997</div>, vol. <div class="volume">9</div> <div class="issue">4</div>(pg. <div class="fpage">441</div>-<div class="lpage">61</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=The%20neural%20substrate%20for%20concrete%2C%20abstract%2C%20and%20emotional%20word%20lexica%3A%20a%20positron%20emission%20tomography%20study&amp;author=M%20Beauregard&amp;author=H%20Chertkow&amp;author=D%20Bub&amp;author=S%20Murtha&amp;author=R%20Dixon&amp;author=A%20Evans&amp;publication_year=1997&amp;journal=Journal%20of%20Cognitive%20Neuroscience&amp;volume=9&amp;pages=441-61" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1162/jocn.1997.9.4.441" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1162%2Fjocn.1997.9.4.441" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1162%2Fjocn.1997.9.4.441"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/23968210" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:The%20neural%20substrate%20for%20concrete%2C%20abstract%2C%20and%20emotional%20word%20lexica%3A%20a%20positron%20emission%20tomography%20study&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B6" data-legacy-id="B6"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B6" href="javascript:;" aria-label="jumplink-B6"></a></span></div><div class="ref false"><div id="ref-auto-B6" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Cato</div> <div class="given-names">MA</div></div>,  <div class="name"><div class="surname">Crosson</div> <div class="given-names">B</div></div>,  <div class="name"><div class="surname">Gokcay</div> <div class="given-names">D</div></div>, et al. </span><div class="article-title">Processing words with emotional connotation: An fMR1 study of time course and laterality in rostral frontal and retrosplenial cortices</div>, <div class="source ">Journal of Cognitive Neuroscience</div>, <div class="year">2004</div>, vol. <div class="volume">16</div> <div class="issue">2</div>(pg. <div class="fpage">167</div>-<div class="lpage">77</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Processing%20words%20with%20emotional%20connotation%3A%20An%20fMR1%20study%20of%20time%20course%20and%20laterality%20in%20rostral%20frontal%20and%20retrosplenial%20cortices&amp;author=MA%20Cato&amp;author=B%20Crosson&amp;author=D%20Gokcay&amp;publication_year=2004&amp;journal=Journal%20of%20Cognitive%20Neuroscience&amp;volume=16&amp;pages=167-77" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1162/089892904322984481" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1162%2F089892904322984481" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1162%2F089892904322984481"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/15068589" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Processing%20words%20with%20emotional%20connotation%3A%20An%20fMR1%20study%20of%20time%20course%20and%20laterality%20in%20rostral%20frontal%20and%20retrosplenial%20cortices&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B7" data-legacy-id="B7"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B7" href="javascript:;" aria-label="jumplink-B7"></a></span></div><div class="ref false"><div id="ref-auto-B7" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Craig</div> <div class="given-names">AD</div></div>. </span><div class="article-title">How do you feel–now? The anterior insula and human awareness</div>, <div class="source ">Nature reviews. Neuroscience</div>, <div class="year">2009</div>, vol. <div class="volume">10</div> <div class="issue">1</div>(pg. <div class="fpage">59</div>-<div class="lpage">70</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=How%20do%20you%20feel%E2%80%93now%3F%20The%20anterior%20insula%20and%20human%20awareness&amp;author=AD%20Craig&amp;publication_year=2009&amp;journal=Nature%20reviews.%20Neuroscience&amp;volume=10&amp;pages=59-70" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1038/nrn2555" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1038%2Fnrn2555" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1038%2Fnrn2555"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/19096369" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:How%20do%20you%20feel%E2%80%93now%3F%20The%20anterior%20insula%20and%20human%20awareness&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B8" data-legacy-id="B8"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B8" href="javascript:;" aria-label="jumplink-B8"></a></span></div><div class="ref false"><div id="ref-auto-B8" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Dale</div> <div class="given-names">AM</div></div>. </span><div class="article-title">Optimal experimental design for event-related fMRI</div>, <div class="source ">Human Brain Mapping</div>, <div class="year">1999</div>, vol. <div class="volume">8</div> <div class="issue">2–3</div>(pg. <div class="fpage">109</div>-<div class="lpage">14</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Optimal%20experimental%20design%20for%20event-related%20fMRI&amp;author=AM%20Dale&amp;publication_year=1999&amp;journal=Human%20Brain%20Mapping&amp;volume=8&amp;pages=109-14" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1002/(ISSN)1097-0193" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1002%2F(ISSN)1097-0193" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1002%2F(ISSN)1097-0193"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/10524601" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Optimal%20experimental%20design%20for%20event-related%20fMRI&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B9" data-legacy-id="B9"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B9" href="javascript:;" aria-label="jumplink-B9"></a></span></div><div class="ref false"><div id="ref-auto-B9" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">de Gelder</div> <div class="given-names">B</div></div>. </span><div class="article-title">Towards the neurobiology of emotional body language</div>, <div class="source ">Nature Reviews. Neuroscience</div>, <div class="year">2006</div>, vol. <div class="volume">7</div> <div class="issue">3</div>(pg. <div class="fpage">242</div>-<div class="lpage">9</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Towards%20the%20neurobiology%20of%20emotional%20body%20language&amp;author=B%20de%20Gelder&amp;publication_year=2006&amp;journal=Nature%20Reviews.%20Neuroscience&amp;volume=7&amp;pages=242-9" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1038/nrn1872" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1038%2Fnrn1872" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1038%2Fnrn1872"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/16495945" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Towards%20the%20neurobiology%20of%20emotional%20body%20language&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B10" data-legacy-id="B10"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B10" href="javascript:;" aria-label="jumplink-B10"></a></span></div><div class="ref false"><div id="ref-auto-B10" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Ferstl</div> <div class="given-names">EC</div></div>,  <div class="name"><div class="surname">Neumann</div> <div class="given-names">J</div></div>,  <div class="name"><div class="surname">Bogler</div> <div class="given-names">C</div></div>,  <div class="name"><div class="surname">von Cramon</div> <div class="given-names">DY</div></div>. </span><div class="article-title">The extended language network: A meta-analysis of neuroimaging studies on text comprehension</div>, <div class="source ">Human Brain Mapping</div>, <div class="year">2008</div>, vol. <div class="volume">29</div> <div class="issue">5</div>(pg. <div class="fpage">581</div>-<div class="lpage">93</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=The%20extended%20language%20network%3A%20A%20meta-analysis%20of%20neuroimaging%20studies%20on%20text%20comprehension&amp;author=EC%20Ferstl&amp;author=J%20Neumann&amp;author=C%20Bogler&amp;author=DY%20von%20Cramon&amp;publication_year=2008&amp;journal=Human%20Brain%20Mapping&amp;volume=29&amp;pages=581-93" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1002/(ISSN)1097-0193" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1002%2F(ISSN)1097-0193" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1002%2F(ISSN)1097-0193"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/17557297" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:The%20extended%20language%20network%3A%20A%20meta-analysis%20of%20neuroimaging%20studies%20on%20text%20comprehension&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B11" data-legacy-id="B11"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B11" href="javascript:;" aria-label="jumplink-B11"></a></span></div><div class="ref false"><div id="ref-auto-B11" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Friston</div> <div class="given-names">KJ</div></div>,  <div class="name"><div class="surname">Holmes</div> <div class="given-names">A</div></div>,  <div class="name"><div class="surname">Poline</div> <div class="given-names">JB</div></div>,  <div class="name"><div class="surname">Price</div> <div class="given-names">CJ</div></div>,  <div class="name"><div class="surname">Frith</div> <div class="given-names">CD</div></div>. </span><div class="article-title">Detecting activations in PET and fMRI: levels of inference and power</div>, <div class="source ">NeuroImage</div>, <div class="year">1996</div>, vol. <div class="volume">4</div> <div class="issue">3 Pt 1</div>(pg. <div class="fpage">223</div>-<div class="lpage">35</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Detecting%20activations%20in%20PET%20and%20fMRI%3A%20levels%20of%20inference%20and%20power&amp;author=KJ%20Friston&amp;author=A%20Holmes&amp;author=JB%20Poline&amp;author=CJ%20Price&amp;author=CD%20Frith&amp;publication_year=1996&amp;journal=NeuroImage&amp;volume=4&amp;pages=223-35" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1006/nimg.1996.0074" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1006%2Fnimg.1996.0074" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1006%2Fnimg.1996.0074"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/9345513" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Detecting%20activations%20in%20PET%20and%20fMRI%3A%20levels%20of%20inference%20and%20power&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B12" data-legacy-id="B12"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B12" href="javascript:;" aria-label="jumplink-B12"></a></span></div><div class="ref false"><div id="ref-auto-B12" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Friston</div> <div class="given-names">KJ</div></div>,  <div class="name"><div class="surname">Holmes</div> <div class="given-names">A</div></div>,  <div class="name"><div class="surname">Worsley</div> <div class="given-names">KJ</div></div>,  <div class="name"><div class="surname">Poline</div> <div class="given-names">J-B</div></div>,  <div class="name"><div class="surname">Frith</div> <div class="given-names">CD</div></div>,  <div class="name"><div class="surname">Frackowiak</div> <div class="given-names">RS</div></div>. </span><div class="article-title">Statistical parametric maps in functional imaging: a general linear approach</div>, <div class="source ">Human Brain Mapping</div>, <div class="year">1995</div>, vol. <div class="volume">2</div> (pg. <div class="fpage">189</div>-<div class="lpage">210</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Statistical%20parametric%20maps%20in%20functional%20imaging%3A%20a%20general%20linear%20approach&amp;author=KJ%20Friston&amp;author=A%20Holmes&amp;author=KJ%20Worsley&amp;author=J-B%20Poline&amp;author=CD%20Frith&amp;author=RS%20Frackowiak&amp;publication_year=1995&amp;journal=Human%20Brain%20Mapping&amp;volume=2&amp;pages=189-210" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1002/hbm.v2:4" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1002%2Fhbm.v2:4" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1002%2Fhbm.v2:4"> </span></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Statistical%20parametric%20maps%20in%20functional%20imaging%3A%20a%20general%20linear%20approach&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B13" data-legacy-id="B13"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B13" href="javascript:;" aria-label="jumplink-B13"></a></span></div><div class="ref false"><div id="ref-auto-B13" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Friston</div> <div class="given-names">KJ</div></div>,  <div class="name"><div class="surname">Holmes</div> <div class="given-names">AP</div></div>,  <div class="name"><div class="surname">Price</div> <div class="given-names">CJ</div></div>,  <div class="name"><div class="surname">Buchel</div> <div class="given-names">C</div></div>,  <div class="name"><div class="surname">Worsley</div> <div class="given-names">KJ</div></div>. </span><div class="article-title">Multisubject fMRI studies and conjunction analyses</div>, <div class="source ">Neuroimage</div>, <div class="year">1999</div>, vol. <div class="volume">10</div> <div class="issue">4</div>(pg. <div class="fpage">385</div>-<div class="lpage">396</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Multisubject%20fMRI%20studies%20and%20conjunction%20analyses&amp;author=KJ%20Friston&amp;author=AP%20Holmes&amp;author=CJ%20Price&amp;author=C%20Buchel&amp;author=KJ%20Worsley&amp;publication_year=1999&amp;journal=Neuroimage&amp;volume=10&amp;pages=385-396" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1006/nimg.1999.0484" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1006%2Fnimg.1999.0484" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1006%2Fnimg.1999.0484"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/10493897" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Multisubject%20fMRI%20studies%20and%20conjunction%20analyses&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B14" data-legacy-id="B14"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B14" href="javascript:;" aria-label="jumplink-B14"></a></span></div><div class="ref false"><div id="ref-auto-B14" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Gorno-Tempini</div> <div class="given-names">ML</div></div>,  <div class="name"><div class="surname">Rankin</div> <div class="given-names">KP</div></div>,  <div class="name"><div class="surname">Woolley</div> <div class="given-names">JD</div></div>,  <div class="name"><div class="surname">Rosen</div> <div class="given-names">HJ</div></div>,  <div class="name"><div class="surname">Phengrasamy</div> <div class="given-names">L</div></div>,  <div class="name"><div class="surname">Miller</div> <div class="given-names">BL</div></div>. </span><div class="article-title">Cognitive and behavioral profile in a case of right anterior temporal lobe neurodegeneration</div>, <div class="source ">Cortex</div>, <div class="year">2004</div>, vol. <div class="volume">40</div> <div class="issue">4–5</div>(pg. <div class="fpage">631</div>-<div class="lpage">44</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Cognitive%20and%20behavioral%20profile%20in%20a%20case%20of%20right%20anterior%20temporal%20lobe%20neurodegeneration&amp;author=ML%20Gorno-Tempini&amp;author=KP%20Rankin&amp;author=JD%20Woolley&amp;author=HJ%20Rosen&amp;author=L%20Phengrasamy&amp;author=BL%20Miller&amp;publication_year=2004&amp;journal=Cortex&amp;volume=40&amp;pages=631-44" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1016/S0010-9452(08)70159-X" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1016%2FS0010-9452(08)70159-X" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1016%2FS0010-9452(08)70159-X"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/15505973" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Cognitive%20and%20behavioral%20profile%20in%20a%20case%20of%20right%20anterior%20temporal%20lobe%20neurodegeneration&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B15" data-legacy-id="B15"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B15" href="javascript:;" aria-label="jumplink-B15"></a></span></div><div class="ref false"><div id="ref-auto-B15" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Gottlieb</div> <div class="given-names">S</div></div>. </span>, <div class="source ">Hitchcock on Hitchcock: Selected Writings and Interviews</div>, <div class="year">1995</div><div class="publisher-loc">Berkeley, CA</div><div class="publisher-name">University of California Press</div><!--citationLinks: case 2--><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Hitchcock%20on%20Hitchcock%3A%20Selected%20Writings%20and%20Interviews&amp;author=S%20Gottlieb&amp;publication_year=1995&amp;book=Hitchcock%20on%20Hitchcock%3A%20Selected%20Writings%20and%20Interviews" target="_blank">Google Scholar</a></span></p><p class="citation-links-compatibility"><span class="google-preview-ref-link js-google-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.google.com/search?q=Hitchcock%20on%20Hitchcock%3A%20Selected%20Writings%20and%20Interviews&amp;btnG=Search+Books&amp;tbm=bks&amp;tbo=1" target="_blank">Google Preview</a></span></p><div class="xslopenurl empty-target"><span class="js-inst-open-url-holders-nodoi"><a class="openInAnotherWindow js-open-url-link" target="_blank" data-href-template="{targetURL}?sid=oup:orr&amp;genre=book&amp;title=Hitchcock%20on%20Hitchcock%3A%20Selected%20Writings%20and%20Interviews&amp;aulast=Gottlieb&amp;date=1995" href="javascript:;"><span class="screenreader-text">OpenURL Placeholder Text</span></a></span></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Hitchcock%20on%20Hitchcock%3A%20Selected%20Writings%20and%20Interviews&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p><div class="copac-reference-ref-link js-copac-preview-ref-link" style="display:none" data-pubtype="book"><span class="inst-copac"><a class="openInAnotherWindow" target="_blank" href="http://copac.ac.uk/search?ti=Hitchcock%20on%20Hitchcock%3A%20Selected%20Writings%20and%20Interviews">COPAC</a></span></div> </div></div></div></div></div><div content-id="B16" data-legacy-id="B16"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B16" href="javascript:;" aria-label="jumplink-B16"></a></span></div><div class="ref false"><div id="ref-auto-B16" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Hagoort</div> <div class="given-names">P</div></div>. </span><div class="article-title">On Broca, brain, and binding: a new framework</div>, <div class="source ">Trends in Cognitive Sciences</div>, <div class="year">2005</div>, vol. <div class="volume">9</div> <div class="issue">9</div>(pg. <div class="fpage">416</div>-<div class="lpage">23</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=On%20Broca%2C%20brain%2C%20and%20binding%3A%20a%20new%20framework&amp;author=P%20Hagoort&amp;publication_year=2005&amp;journal=Trends%20in%20Cognitive%20Sciences&amp;volume=9&amp;pages=416-23" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1016/j.tics.2005.07.004" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1016%2Fj.tics.2005.07.004" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1016%2Fj.tics.2005.07.004"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/16054419" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:On%20Broca%2C%20brain%2C%20and%20binding%3A%20a%20new%20framework&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B17" data-legacy-id="B17"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B17" href="javascript:;" aria-label="jumplink-B17"></a></span></div><div class="ref false"><div id="ref-auto-B17" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Hagoort</div> <div class="given-names">P</div></div>,  <div class="name"><div class="surname">Baggio</div> <div class="given-names">G</div></div>,  <div class="name"><div class="surname">Willems</div> <div class="given-names">RM</div></div>. </span><span class="person-group"><div class="name"><div class="surname">Gazzaniga</div> <div class="given-names">MS</div></div>. </span><div class="article-title">Semantic unification</div>, <div class="source ">The Cognitive Neurosciences IV</div>, <div class="year">2009</div><div class="publisher-loc">Cambridge, MA</div><div class="publisher-name">MIT press</div><!--citationLinks: case 2--><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=The%20Cognitive%20Neurosciences%20IV&amp;author=P%20Hagoort&amp;author=G%20Baggio&amp;author=RM%20Willems&amp;author=MS%20Gazzaniga&amp;publication_year=2009&amp;book=The%20Cognitive%20Neurosciences%20IV" target="_blank">Google Scholar</a></span></p><p class="citation-links-compatibility"><span class="google-preview-ref-link js-google-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.google.com/search?q=The%20Cognitive%20Neurosciences%20IV&amp;btnG=Search+Books&amp;tbm=bks&amp;tbo=1" target="_blank">Google Preview</a></span></p><div class="xslopenurl empty-target"><span class="js-inst-open-url-holders-nodoi"><a class="openInAnotherWindow js-open-url-link" target="_blank" data-href-template="{targetURL}?sid=oup:orr&amp;genre=book&amp;title=The%20Cognitive%20Neurosciences%20IV&amp;aulast=Hagoort&amp;date=2009" href="javascript:;"><span class="screenreader-text">OpenURL Placeholder Text</span></a></span></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:The%20Cognitive%20Neurosciences%20IV&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p><div class="copac-reference-ref-link js-copac-preview-ref-link" style="display:none" data-pubtype="book"><span class="inst-copac"><a class="openInAnotherWindow" target="_blank" href="http://copac.ac.uk/search?ti=The%20Cognitive%20Neurosciences%20IV">COPAC</a></span></div> </div></div></div></div></div><div content-id="B18" data-legacy-id="B18"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B18" href="javascript:;" aria-label="jumplink-B18"></a></span></div><div class="ref false"><div id="ref-auto-B18" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Hagoort</div> <div class="given-names">P</div></div>,  <div class="name"><div class="surname">Hald</div> <div class="given-names">L</div></div>,  <div class="name"><div class="surname">Bastiaansen</div> <div class="given-names">M</div></div>,  <div class="name"><div class="surname">Petersson</div> <div class="given-names">KM</div></div>. </span><div class="article-title">Integration of word meaning and world knowledge in language comprehension</div>, <div class="source ">Science</div>, <div class="year">2004</div>, vol. <div class="volume">304</div> <div class="issue">5669</div>(pg. <div class="fpage">438</div>-<div class="lpage">41</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Integration%20of%20word%20meaning%20and%20world%20knowledge%20in%20language%20comprehension&amp;author=P%20Hagoort&amp;author=L%20Hald&amp;author=M%20Bastiaansen&amp;author=KM%20Petersson&amp;publication_year=2004&amp;journal=Science&amp;volume=304&amp;pages=438-41" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1126/science.1095455" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1126%2Fscience.1095455" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1126%2Fscience.1095455"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/15031438" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Integration%20of%20word%20meaning%20and%20world%20knowledge%20in%20language%20comprehension&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B19" data-legacy-id="B19"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B19" href="javascript:;" aria-label="jumplink-B19"></a></span></div><div class="ref false"><div id="ref-auto-B19" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Herbert</div> <div class="given-names">C</div></div>,  <div class="name"><div class="surname">Ethofer</div> <div class="given-names">T</div></div>,  <div class="name"><div class="surname">Anders</div> <div class="given-names">S</div></div>, et al. </span><div class="article-title">Amygdala activation during reading of emotional adjectives–an advantage for pleasant content</div>, <div class="source ">Social Cognitive and Affective Neuroscience</div>, <div class="year">2009</div>, vol. <div class="volume">4</div> <div class="issue">1</div>(pg. <div class="fpage">35</div>-<div class="lpage">49</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Amygdala%20activation%20during%20reading%20of%20emotional%20adjectives%E2%80%93an%20advantage%20for%20pleasant%20content&amp;author=C%20Herbert&amp;author=T%20Ethofer&amp;author=S%20Anders&amp;publication_year=2009&amp;journal=Social%20Cognitive%20and%20Affective%20Neuroscience&amp;volume=4&amp;pages=35-49" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1093/scan/nsn027" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1093%2Fscan%2Fnsn027" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1093%2Fscan%2Fnsn027"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/19015080" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Amygdala%20activation%20during%20reading%20of%20emotional%20adjectives%E2%80%93an%20advantage%20for%20pleasant%20content&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B20" data-legacy-id="B20"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B20" href="javascript:;" aria-label="jumplink-B20"></a></span></div><div class="ref false"><div id="ref-auto-B20" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Holt</div> <div class="given-names">D J</div></div>,  <div class="name"><div class="surname">Lynn</div> <div class="given-names">S K</div></div>,  <div class="name"><div class="surname">Kuperberg</div> <div class="given-names">G R</div></div>. </span><div class="article-title">Neurophysiological correlates of comprehending emotional meaning in context</div>, <div class="source ">Journal of Cogntive Neuroscience</div>, <div class="year">2009</div>, vol. <div class="volume">21</div> <div class="issue">11</div>(pg. <div class="fpage">2245</div>-<div class="lpage">62</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Neurophysiological%20correlates%20of%20comprehending%20emotional%20meaning%20in%20context&amp;author=D%20J%20Holt&amp;author=S%20K%20Lynn&amp;author=G%20R%20Kuperberg&amp;publication_year=2009&amp;journal=Journal%20of%20Cogntive%20Neuroscience&amp;volume=21&amp;pages=2245-62" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1162/jocn.2008.21151" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1162%2Fjocn.2008.21151" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1162%2Fjocn.2008.21151"> </span></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Neurophysiological%20correlates%20of%20comprehending%20emotional%20meaning%20in%20context&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B21" data-legacy-id="B21"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B21" href="javascript:;" aria-label="jumplink-B21"></a></span></div><div class="ref false"><div id="ref-auto-B21" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Isenberg</div> <div class="given-names">N</div></div>,  <div class="name"><div class="surname">Silbersweig</div> <div class="given-names">D</div></div>,  <div class="name"><div class="surname">Engelien</div> <div class="given-names">A</div></div>, et al. </span><div class="article-title">Linguistic threat activates the human amygdala</div>, <div class="source ">Proceedings of the National Academy of Sciences of the United States of America</div>, <div class="year">1999</div>, vol. <div class="volume">96</div> <div class="issue">18</div>(pg. <div class="fpage">10456</div>-<div class="lpage">10459</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Linguistic%20threat%20activates%20the%20human%20amygdala&amp;author=N%20Isenberg&amp;author=D%20Silbersweig&amp;author=A%20Engelien&amp;publication_year=1999&amp;journal=Proceedings%20of%20the%20National%20Academy%20of%20Sciences%20of%20the%20United%20States%20of%20America&amp;volume=96&amp;pages=10456-10459" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1073/pnas.96.18.10456" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1073%2Fpnas.96.18.10456" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1073%2Fpnas.96.18.10456"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/10468630" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Linguistic%20threat%20activates%20the%20human%20amygdala&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B22" data-legacy-id="B22"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B22" href="javascript:;" aria-label="jumplink-B22"></a></span></div><div class="ref false"><div id="ref-auto-B22" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Kim</div> <div class="given-names">H</div></div>,  <div class="name"><div class="surname">Somerville</div> <div class="given-names">LH</div></div>,  <div class="name"><div class="surname">Johnstone</div> <div class="given-names">T</div></div>, et al. </span><div class="article-title">Contextual modulation of amygdala responsivity to surprised faces</div>, <div class="source ">Journal of Cognitive Neuroscience</div>, <div class="year">2004</div>, vol. <div class="volume">16</div> <div class="issue">10</div>(pg. <div class="fpage">1730</div>-<div class="lpage">45</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Contextual%20modulation%20of%20amygdala%20responsivity%20to%20surprised%20faces&amp;author=H%20Kim&amp;author=LH%20Somerville&amp;author=T%20Johnstone&amp;publication_year=2004&amp;journal=Journal%20of%20Cognitive%20Neuroscience&amp;volume=16&amp;pages=1730-45" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1162/0898929042947865" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1162%2F0898929042947865" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1162%2F0898929042947865"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/15701225" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Contextual%20modulation%20of%20amygdala%20responsivity%20to%20surprised%20faces&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B23" data-legacy-id="B23"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B23" href="javascript:;" aria-label="jumplink-B23"></a></span></div><div class="ref false"><div id="ref-auto-B23" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Kober</div> <div class="given-names">H</div></div>,  <div class="name"><div class="surname">Barrett</div> <div class="given-names">LF</div></div>,  <div class="name"><div class="surname">Joseph</div> <div class="given-names">J</div></div>,  <div class="name"><div class="surname">Bliss-Moreau</div> <div class="given-names">E</div></div>,  <div class="name"><div class="surname">Lindquist</div> <div class="given-names">K</div></div>,  <div class="name"><div class="surname">Wager</div> <div class="given-names">TD</div></div>. </span><div class="article-title">Functional grouping and cortical-subcortical interactions in emotion: a meta-analysis of neuroimaging studies</div>, <div class="source ">Neuroimage</div>, <div class="year">2008</div>, vol. <div class="volume">42</div> <div class="issue">2</div>(pg. <div class="fpage">998</div>-<div class="lpage">1031</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Functional%20grouping%20and%20cortical-subcortical%20interactions%20in%20emotion%3A%20a%20meta-analysis%20of%20neuroimaging%20studies&amp;author=H%20Kober&amp;author=LF%20Barrett&amp;author=J%20Joseph&amp;author=E%20Bliss-Moreau&amp;author=K%20Lindquist&amp;author=TD%20Wager&amp;publication_year=2008&amp;journal=Neuroimage&amp;volume=42&amp;pages=998-1031" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1016/j.neuroimage.2008.03.059" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1016%2Fj.neuroimage.2008.03.059" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1016%2Fj.neuroimage.2008.03.059"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/18579414" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Functional%20grouping%20and%20cortical-subcortical%20interactions%20in%20emotion%3A%20a%20meta-analysis%20of%20neuroimaging%20studies&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B24" data-legacy-id="B24"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B24" href="javascript:;" aria-label="jumplink-B24"></a></span></div><div class="ref false"><div id="ref-auto-B24" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Kuchinke</div> <div class="given-names">L</div></div>,  <div class="name"><div class="surname">Jacobs</div> <div class="given-names">AM</div></div>,  <div class="name"><div class="surname">Grubich</div> <div class="given-names">C</div></div>,  <div class="name"><div class="surname">Vo</div> <div class="given-names">ML</div></div>,  <div class="name"><div class="surname">Conrad</div> <div class="given-names">M</div></div>,  <div class="name"><div class="surname">Herrmann</div> <div class="given-names">M</div></div>. </span><div class="article-title">Incidental effects of emotional valence in single word processing: an fMRI study</div>, <div class="source ">Neuroimage</div>, <div class="year">2005</div>, vol. <div class="volume">28</div> <div class="issue">4</div>(pg. <div class="fpage">1022</div>-<div class="lpage">32</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Incidental%20effects%20of%20emotional%20valence%20in%20single%20word%20processing%3A%20an%20fMRI%20study&amp;author=L%20Kuchinke&amp;author=AM%20Jacobs&amp;author=C%20Grubich&amp;author=ML%20Vo&amp;author=M%20Conrad&amp;author=M%20Herrmann&amp;publication_year=2005&amp;journal=Neuroimage&amp;volume=28&amp;pages=1022-32" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1016/j.neuroimage.2005.06.050" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1016%2Fj.neuroimage.2005.06.050" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1016%2Fj.neuroimage.2005.06.050"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/16084739" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Incidental%20effects%20of%20emotional%20valence%20in%20single%20word%20processing%3A%20an%20fMRI%20study&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B25" data-legacy-id="B25"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B25" href="javascript:;" aria-label="jumplink-B25"></a></span></div><div class="ref false"><div id="ref-auto-B25" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">LaBar</div> <div class="given-names">KS</div></div>,  <div class="name"><div class="surname">Gitelman</div> <div class="given-names">DR</div></div>,  <div class="name"><div class="surname">Mesulam</div> <div class="given-names">MM</div></div>,  <div class="name"><div class="surname">Parrish</div> <div class="given-names">TB</div></div>. </span><div class="article-title">Impact of signal-to-noise on functional MRI of the human amygdala</div>, <div class="source ">Neuroreport</div>, <div class="year">2001</div>, vol. <div class="volume">12</div> <div class="issue">16</div>(pg. <div class="fpage">3461</div>-<div class="lpage">64</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Impact%20of%20signal-to-noise%20on%20functional%20MRI%20of%20the%20human%20amygdala&amp;author=KS%20LaBar&amp;author=DR%20Gitelman&amp;author=MM%20Mesulam&amp;author=TB%20Parrish&amp;publication_year=2001&amp;journal=Neuroreport&amp;volume=12&amp;pages=3461-64" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1097/00001756-200111160-00017" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1097%2F00001756-200111160-00017" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1097%2F00001756-200111160-00017"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/11733691" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Impact%20of%20signal-to-noise%20on%20functional%20MRI%20of%20the%20human%20amygdala&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B26" data-legacy-id="B26"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B26" href="javascript:;" aria-label="jumplink-B26"></a></span></div><div class="ref false"><div id="ref-auto-B26" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Lieberman</div> <div class="given-names">MD</div></div>,  <div class="name"><div class="surname">Eisenberger</div> <div class="given-names">NI</div></div>,  <div class="name"><div class="surname">Crockett</div> <div class="given-names">MJ</div></div>,  <div class="name"><div class="surname">Tom</div> <div class="given-names">SM</div></div>,  <div class="name"><div class="surname">Pfeifer</div> <div class="given-names">JH</div></div>,  <div class="name"><div class="surname">Way</div> <div class="given-names">BM</div></div>. </span><div class="article-title">Putting feelings into words - Affect labeling disrupts amygdala activity in response to affective stimuli</div>, <div class="source ">Psychological Science</div>, <div class="year">2007</div>, vol. <div class="volume">18</div> <div class="issue">5</div>(pg. <div class="fpage">421</div>-<div class="lpage">8</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Putting%20feelings%20into%20words%20-%20Affect%20labeling%20disrupts%20amygdala%20activity%20in%20response%20to%20affective%20stimuli&amp;author=MD%20Lieberman&amp;author=NI%20Eisenberger&amp;author=MJ%20Crockett&amp;author=SM%20Tom&amp;author=JH%20Pfeifer&amp;author=BM%20Way&amp;publication_year=2007&amp;journal=Psychological%20Science&amp;volume=18&amp;pages=421-8" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1111/j.1467-9280.2007.01916.x" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1111%2Fj.1467-9280.2007.01916.x" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1111%2Fj.1467-9280.2007.01916.x"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/17576282" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Putting%20feelings%20into%20words%20-%20Affect%20labeling%20disrupts%20amygdala%20activity%20in%20response%20to%20affective%20stimuli&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B27" data-legacy-id="B27"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B27" href="javascript:;" aria-label="jumplink-B27"></a></span></div><div class="ref false"><div id="ref-auto-B27" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Mesulam</div> <div class="given-names">MM</div></div>. </span><span class="person-group"><div class="name"><div class="surname">Mesulam</div> <div class="given-names">MM</div></div>. </span><div class="article-title">Paralimbic (mesocortical) areas</div>, <div class="source ">Principles of Behavioral and Cognitive Neurology</div>, <div class="year">2000</div><div class="publisher-loc">New York</div><div class="publisher-name">Oxford University Press</div>(pg. <div class="fpage">49</div>-<div class="lpage">54</div>)<!--citationLinks: case 2--><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Principles%20of%20Behavioral%20and%20Cognitive%20Neurology&amp;author=MM%20Mesulam&amp;author=MM%20Mesulam&amp;publication_year=2000&amp;book=Principles%20of%20Behavioral%20and%20Cognitive%20Neurology" target="_blank">Google Scholar</a></span></p><p class="citation-links-compatibility"><span class="google-preview-ref-link js-google-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.google.com/search?q=Principles%20of%20Behavioral%20and%20Cognitive%20Neurology&amp;btnG=Search+Books&amp;tbm=bks&amp;tbo=1" target="_blank">Google Preview</a></span></p><div class="xslopenurl empty-target"><span class="js-inst-open-url-holders-nodoi"><a class="openInAnotherWindow js-open-url-link" target="_blank" data-href-template="{targetURL}?sid=oup:orr&amp;genre=book&amp;title=Principles%20of%20Behavioral%20and%20Cognitive%20Neurology&amp;aulast=Mesulam&amp;date=2000&amp;spage=49&amp;epage=54" href="javascript:;"><span class="screenreader-text">OpenURL Placeholder Text</span></a></span></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Principles%20of%20Behavioral%20and%20Cognitive%20Neurology&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p><div class="copac-reference-ref-link js-copac-preview-ref-link" style="display:none" data-pubtype="book"><span class="inst-copac"><a class="openInAnotherWindow" target="_blank" href="http://copac.ac.uk/search?ti=Principles%20of%20Behavioral%20and%20Cognitive%20Neurology">COPAC</a></span></div> </div></div></div></div></div><div content-id="B28" data-legacy-id="B28"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B28" href="javascript:;" aria-label="jumplink-B28"></a></span></div><div class="ref false"><div id="ref-auto-B28" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Miezin</div> <div class="given-names">FM</div></div>,  <div class="name"><div class="surname">Maccotta</div> <div class="given-names">L</div></div>,  <div class="name"><div class="surname">Ollinger</div> <div class="given-names">JM</div></div>,  <div class="name"><div class="surname">Petersen</div> <div class="given-names">SE</div></div>,  <div class="name"><div class="surname">Buckner</div> <div class="given-names">RL</div></div>. </span><div class="article-title">Characterizing the hemodynamic response: effects of presentation rate, sampling procedure, and the possibility of ordering brain activity based on relative timing</div>, <div class="source ">NeuroImage</div>, <div class="year">2000</div>, vol. <div class="volume">11</div> <div class="issue">6 Pt 1</div>(pg. <div class="fpage">735</div>-<div class="lpage">59</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Characterizing%20the%20hemodynamic%20response%3A%20effects%20of%20presentation%20rate%2C%20sampling%20procedure%2C%20and%20the%20possibility%20of%20ordering%20brain%20activity%20based%20on%20relative%20timing&amp;author=FM%20Miezin&amp;author=L%20Maccotta&amp;author=JM%20Ollinger&amp;author=SE%20Petersen&amp;author=RL%20Buckner&amp;publication_year=2000&amp;journal=NeuroImage&amp;volume=11&amp;pages=735-59" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1006/nimg.2000.0568" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1006%2Fnimg.2000.0568" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1006%2Fnimg.2000.0568"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/10860799" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Characterizing%20the%20hemodynamic%20response%3A%20effects%20of%20presentation%20rate%2C%20sampling%20procedure%2C%20and%20the%20possibility%20of%20ordering%20brain%20activity%20based%20on%20relative%20timing&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B29" data-legacy-id="B29"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B29" href="javascript:;" aria-label="jumplink-B29"></a></span></div><div class="ref false"><div id="ref-auto-B29" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Mobbs</div> <div class="given-names">D</div></div>,  <div class="name"><div class="surname">Weiskopf</div> <div class="given-names">N</div></div>,  <div class="name"><div class="surname">Lau</div> <div class="given-names">HC</div></div>,  <div class="name"><div class="surname">Featherstone</div> <div class="given-names">E</div></div>,  <div class="name"><div class="surname">Dolan</div> <div class="given-names">RJ</div></div>,  <div class="name"><div class="surname">Frith</div> <div class="given-names">CD</div></div>. </span><div class="article-title">The Kuleshov Effect: the influence of contextual framing on emotional attributions</div>, <div class="source ">Social Cognitive and Affective Neuroscience</div>, <div class="year">2006</div>, vol. <div class="volume">1</div> <div class="issue">2</div>(pg. <div class="fpage">95</div>-<div class="lpage">106</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=The%20Kuleshov%20Effect%3A%20the%20influence%20of%20contextual%20framing%20on%20emotional%20attributions&amp;author=D%20Mobbs&amp;author=N%20Weiskopf&amp;author=HC%20Lau&amp;author=E%20Featherstone&amp;author=RJ%20Dolan&amp;author=CD%20Frith&amp;publication_year=2006&amp;journal=Social%20Cognitive%20and%20Affective%20Neuroscience&amp;volume=1&amp;pages=95-106" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1093/scan/nsl014" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1093%2Fscan%2Fnsl014" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1093%2Fscan%2Fnsl014"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/17339967" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:The%20Kuleshov%20Effect%3A%20the%20influence%20of%20contextual%20framing%20on%20emotional%20attributions&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B30" data-legacy-id="B30"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B30" href="javascript:;" aria-label="jumplink-B30"></a></span></div><div class="ref false"><div id="ref-auto-B30" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Oldfield</div> <div class="given-names">RC</div></div>. </span><div class="article-title">The assessment and analysis of handedness: the Edinburgh inventory</div>, <div class="source ">Neuropsychologia</div>, <div class="year">1971</div>, vol. <div class="volume">9</div> <div class="issue">1</div>(pg. <div class="fpage">97</div>-<div class="lpage">113</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=The%20assessment%20and%20analysis%20of%20handedness%3A%20the%20Edinburgh%20inventory&amp;author=RC%20Oldfield&amp;publication_year=1971&amp;journal=Neuropsychologia&amp;volume=9&amp;pages=97-113" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1016/0028-3932(71)90067-4" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1016%2F0028-3932(71)90067-4" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1016%2F0028-3932(71)90067-4"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/5146491" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:The%20assessment%20and%20analysis%20of%20handedness%3A%20the%20Edinburgh%20inventory&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B31" data-legacy-id="B31"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B31" href="javascript:;" aria-label="jumplink-B31"></a></span></div><div class="ref false"><div id="ref-auto-B31" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Olson</div> <div class="given-names">IR</div></div>,  <div class="name"><div class="surname">Plotzker</div> <div class="given-names">A</div></div>,  <div class="name"><div class="surname">Ezzyat</div> <div class="given-names">Y</div></div>. </span><div class="article-title">The Enigmatic temporal pole: a review of findings on social and emotional processing</div>, <div class="source ">Brain</div>, <div class="year">2007</div>, vol. <div class="volume">130</div> <div class="issue">Pt 7</div>(pg. <div class="fpage">1718</div>-<div class="lpage">31</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=The%20Enigmatic%20temporal%20pole%3A%20a%20review%20of%20findings%20on%20social%20and%20emotional%20processing&amp;author=IR%20Olson&amp;author=A%20Plotzker&amp;author=Y%20Ezzyat&amp;publication_year=2007&amp;journal=Brain&amp;volume=130&amp;pages=1718-31" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1093/brain/awm052" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1093%2Fbrain%2Fawm052" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1093%2Fbrain%2Fawm052"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/17392317" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:The%20Enigmatic%20temporal%20pole%3A%20a%20review%20of%20findings%20on%20social%20and%20emotional%20processing&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B32" data-legacy-id="B32"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B32" href="javascript:;" aria-label="jumplink-B32"></a></span></div><div class="ref false"><div id="ref-auto-B32" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Özyürek</div> <div class="given-names">A</div></div>,  <div class="name"><div class="surname">Willems</div> <div class="given-names">RM</div></div>,  <div class="name"><div class="surname">Kita</div> <div class="given-names">S</div></div>,  <div class="name"><div class="surname">Hagoort</div> <div class="given-names">P</div></div>. </span><div class="article-title">On-line integration of semantic information from speech and gesture: insights from event-related brain potentials</div>, <div class="source ">Journal of Cognitive Neuroscience</div>, <div class="year">2007</div>, vol. <div class="volume">19</div> <div class="issue">4</div>(pg. <div class="fpage">605</div>-<div class="lpage">16</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=On-line%20integration%20of%20semantic%20information%20from%20speech%20and%20gesture%3A%20insights%20from%20event-related%20brain%20potentials&amp;author=A%20%C3%96zy%C3%BCrek&amp;author=RM%20Willems&amp;author=S%20Kita&amp;author=P%20Hagoort&amp;publication_year=2007&amp;journal=Journal%20of%20Cognitive%20Neuroscience&amp;volume=19&amp;pages=605-16" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1162/jocn.2007.19.4.605" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1162%2Fjocn.2007.19.4.605" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1162%2Fjocn.2007.19.4.605"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/17381252" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:On-line%20integration%20of%20semantic%20information%20from%20speech%20and%20gesture%3A%20insights%20from%20event-related%20brain%20potentials&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B33" data-legacy-id="B33"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B33" href="javascript:;" aria-label="jumplink-B33"></a></span></div><div class="ref false"><div id="ref-auto-B33" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Pessoa</div> <div class="given-names">L</div></div>,  <div class="name"><div class="surname">Ungerleider</div> <div class="given-names">LG</div></div>. </span><div class="article-title">Neuroimaging studies of attention and the processing of emotion-laden stimuli</div>, <div class="source ">Progress in Brain Research</div>, <div class="year">2004</div>, vol. <div class="volume">144</div> (pg. <div class="fpage">171</div>-<div class="lpage">82</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Neuroimaging%20studies%20of%20attention%20and%20the%20processing%20of%20emotion-laden%20stimuli&amp;author=L%20Pessoa&amp;author=LG%20Ungerleider&amp;publication_year=2004&amp;journal=Progress%20in%20Brain%20Research&amp;volume=144&amp;pages=171-82" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1016/S0079-6123(03)14412-3" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1016%2FS0079-6123(03)14412-3" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1016%2FS0079-6123(03)14412-3"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/14650848" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Neuroimaging%20studies%20of%20attention%20and%20the%20processing%20of%20emotion-laden%20stimuli&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B34" data-legacy-id="B34"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B34" href="javascript:;" aria-label="jumplink-B34"></a></span></div><div class="ref false"><div id="ref-auto-B34" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Phan</div> <div class="given-names">KL</div></div>,  <div class="name"><div class="surname">Wager</div> <div class="given-names">T</div></div>,  <div class="name"><div class="surname">Taylor</div> <div class="given-names">SF</div></div>,  <div class="name"><div class="surname">Liberzon</div> <div class="given-names">I</div></div>. </span><div class="article-title">Functional neuroanatomy of emotion: a meta-analysis of emotion activation studies in PET and fMRI</div>, <div class="source ">Neuroimage</div>, <div class="year">2002</div>, vol. <div class="volume">16</div> <div class="issue">2</div>(pg. <div class="fpage">331</div>-<div class="lpage">48</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Functional%20neuroanatomy%20of%20emotion%3A%20a%20meta-analysis%20of%20emotion%20activation%20studies%20in%20PET%20and%20fMRI&amp;author=KL%20Phan&amp;author=T%20Wager&amp;author=SF%20Taylor&amp;author=I%20Liberzon&amp;publication_year=2002&amp;journal=Neuroimage&amp;volume=16&amp;pages=331-48" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1006/nimg.2002.1087" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1006%2Fnimg.2002.1087" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1006%2Fnimg.2002.1087"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/12030820" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Functional%20neuroanatomy%20of%20emotion%3A%20a%20meta-analysis%20of%20emotion%20activation%20studies%20in%20PET%20and%20fMRI&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B35" data-legacy-id="B35"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B35" href="javascript:;" aria-label="jumplink-B35"></a></span></div><div class="ref false"><div id="ref-auto-B35" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Pisters</div> <div class="given-names">P</div></div>. </span>, <div class="source ">Lessen van Hitchcock</div>, <div class="year">2004</div><div class="publisher-loc">Amsterdam</div><div class="publisher-name">Amsterdam University Press</div><!--citationLinks: case 2--><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Lessen%20van%20Hitchcock&amp;author=P%20Pisters&amp;publication_year=2004&amp;book=Lessen%20van%20Hitchcock" target="_blank">Google Scholar</a></span></p><p class="citation-links-compatibility"><span class="google-preview-ref-link js-google-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.google.com/search?q=Lessen%20van%20Hitchcock&amp;btnG=Search+Books&amp;tbm=bks&amp;tbo=1" target="_blank">Google Preview</a></span></p><div class="xslopenurl empty-target"><span class="js-inst-open-url-holders-nodoi"><a class="openInAnotherWindow js-open-url-link" target="_blank" data-href-template="{targetURL}?sid=oup:orr&amp;genre=book&amp;title=Lessen%20van%20Hitchcock&amp;aulast=Pisters&amp;date=2004" href="javascript:;"><span class="screenreader-text">OpenURL Placeholder Text</span></a></span></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Lessen%20van%20Hitchcock&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p><div class="copac-reference-ref-link js-copac-preview-ref-link" style="display:none" data-pubtype="book"><span class="inst-copac"><a class="openInAnotherWindow" target="_blank" href="http://copac.ac.uk/search?ti=Lessen%20van%20Hitchcock">COPAC</a></span></div> </div></div></div></div></div><div content-id="B36" data-legacy-id="B36"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B36" href="javascript:;" aria-label="jumplink-B36"></a></span></div><div class="ref false"><div id="ref-auto-B36" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Poline</div> <div class="given-names">JB</div></div>,  <div class="name"><div class="surname">Worsley</div> <div class="given-names">KJ</div></div>,  <div class="name"><div class="surname">Evans</div> <div class="given-names">AC</div></div>,  <div class="name"><div class="surname">Friston</div> <div class="given-names">KJ</div></div>. </span><div class="article-title">Combining spatial extent and peak intensity to test for activations in functional imaging</div>, <div class="source ">Neuroimage</div>, <div class="year">1997</div>, vol. <div class="volume">5</div> <div class="issue">2</div>(pg. <div class="fpage">83</div>-<div class="lpage">96</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Combining%20spatial%20extent%20and%20peak%20intensity%20to%20test%20for%20activations%20in%20functional%20imaging&amp;author=JB%20Poline&amp;author=KJ%20Worsley&amp;author=AC%20Evans&amp;author=KJ%20Friston&amp;publication_year=1997&amp;journal=Neuroimage&amp;volume=5&amp;pages=83-96" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1006/nimg.1996.0248" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1006%2Fnimg.1996.0248" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1006%2Fnimg.1996.0248"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/9345540" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Combining%20spatial%20extent%20and%20peak%20intensity%20to%20test%20for%20activations%20in%20functional%20imaging&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B37" data-legacy-id="B37"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B37" href="javascript:;" aria-label="jumplink-B37"></a></span></div><div class="ref false"><div id="ref-auto-B37" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Pulvermuller</div> <div class="given-names">F</div></div>. </span><div class="article-title">Brain mechanisms linking language and action</div>, <div class="source ">Nature Reviews Neuroscience</div>, <div class="year">2005</div>, vol. <div class="volume">6</div> <div class="issue">7</div>(pg. <div class="fpage">576</div>-<div class="lpage">82</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Brain%20mechanisms%20linking%20language%20and%20action&amp;author=F%20Pulvermuller&amp;publication_year=2005&amp;journal=Nature%20Reviews%20Neuroscience&amp;volume=6&amp;pages=576-82" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1038/nrn1706" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1038%2Fnrn1706" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1038%2Fnrn1706"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/15959465" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Brain%20mechanisms%20linking%20language%20and%20action&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B38" data-legacy-id="B38"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B38" href="javascript:;" aria-label="jumplink-B38"></a></span></div><div class="ref false"><div id="ref-auto-B38" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Razafimandimby</div> <div class="given-names">A</div></div>,  <div class="name"><div class="surname">Vigneau</div> <div class="given-names">M</div></div>,  <div class="name"><div class="surname">Beaucousin</div> <div class="given-names">V</div></div>, et al. </span>, <div class="source ">Neural Networks of Emotional Discourse Comprehension</div>, <div class="year">2009</div><div class="month">June</div> <div class="comment">Paper presented at the Annual Meeting of the Organization for Human Brain Mapping, San Francisco</div><!--citationLinks: case 2--><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Neural%20Networks%20of%20Emotional%20Discourse%20Comprehension&amp;author=A%20Razafimandimby&amp;author=M%20Vigneau&amp;author=V%20Beaucousin&amp;publication_year=2009&amp;book=Neural%20Networks%20of%20Emotional%20Discourse%20Comprehension" target="_blank">Google Scholar</a></span></p><p class="citation-links-compatibility"><span class="google-preview-ref-link js-google-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.google.com/search?q=Neural%20Networks%20of%20Emotional%20Discourse%20Comprehension&amp;btnG=Search+Books&amp;tbm=bks&amp;tbo=1" target="_blank">Google Preview</a></span></p><div class="xslopenurl empty-target"><span class="js-inst-open-url-holders-nodoi"><a class="openInAnotherWindow js-open-url-link" target="_blank" data-href-template="{targetURL}?sid=oup:orr&amp;genre=book&amp;title=Neural%20Networks%20of%20Emotional%20Discourse%20Comprehension&amp;aulast=Razafimandimby&amp;date=2009" href="javascript:;"><span class="screenreader-text">OpenURL Placeholder Text</span></a></span></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Neural%20Networks%20of%20Emotional%20Discourse%20Comprehension&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p><div class="copac-reference-ref-link js-copac-preview-ref-link" style="display:none" data-pubtype="book"><span class="inst-copac"><a class="openInAnotherWindow" target="_blank" href="http://copac.ac.uk/search?ti=Neural%20Networks%20of%20Emotional%20Discourse%20Comprehension">COPAC</a></span></div> </div></div></div></div></div><div content-id="B39" data-legacy-id="B39"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B39" href="javascript:;" aria-label="jumplink-B39"></a></span></div><div class="ref false"><div id="ref-auto-B39" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Singer</div> <div class="given-names">T</div></div>,  <div class="name"><div class="surname">Critchley</div> <div class="given-names">HD</div></div>,  <div class="name"><div class="surname">Preuschoff</div> <div class="given-names">K</div></div>. </span><div class="article-title">A common role of insula in feelings, empathy and uncertainty</div>, <div class="source ">Trends in Cognitive Science</div>, <div class="year">2009</div>, vol. <div class="volume">13</div> <div class="issue">8</div>(pg. <div class="fpage">334</div>-<div class="lpage">40</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=A%20common%20role%20of%20insula%20in%20feelings%2C%20empathy%20and%20uncertainty&amp;author=T%20Singer&amp;author=HD%20Critchley&amp;author=K%20Preuschoff&amp;publication_year=2009&amp;journal=Trends%20in%20Cognitive%20Science&amp;volume=13&amp;pages=334-40" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1016/j.tics.2009.05.001" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1016%2Fj.tics.2009.05.001" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1016%2Fj.tics.2009.05.001"> </span></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:A%20common%20role%20of%20insula%20in%20feelings%2C%20empathy%20and%20uncertainty&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B40" data-legacy-id="B40"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B40" href="javascript:;" aria-label="jumplink-B40"></a></span></div><div class="ref false"><div id="ref-auto-B40" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Snijders</div> <div class="given-names">TM</div></div>,  <div class="name"><div class="surname">Vosse</div> <div class="given-names">T</div></div>,  <div class="name"><div class="surname">Kempen</div> <div class="given-names">G</div></div>,  <div class="name"><div class="surname">Van Berkum</div> <div class="given-names">JJ</div></div>,  <div class="name"><div class="surname">Petersson</div> <div class="given-names">KM</div></div>,  <div class="name"><div class="surname">Hagoort</div> <div class="given-names">P</div></div>. </span><div class="article-title">Retrieval and unification of syntactic structure in sentence comprehension: an fMRI study using word-category ambiguity</div>, <div class="source ">Cerebral Cortex</div>, <div class="year">2009</div>, vol. <div class="volume">19</div> <div class="issue">7</div>(pg. <div class="fpage">1493</div>-<div class="lpage">503</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Retrieval%20and%20unification%20of%20syntactic%20structure%20in%20sentence%20comprehension%3A%20an%20fMRI%20study%20using%20word-category%20ambiguity&amp;author=TM%20Snijders&amp;author=T%20Vosse&amp;author=G%20Kempen&amp;author=JJ%20Van%20Berkum&amp;author=KM%20Petersson&amp;author=P%20Hagoort&amp;publication_year=2009&amp;journal=Cerebral%20Cortex&amp;volume=19&amp;pages=1493-503" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1093/cercor/bhn187" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1093%2Fcercor%2Fbhn187" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1093%2Fcercor%2Fbhn187"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/19001084" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Retrieval%20and%20unification%20of%20syntactic%20structure%20in%20sentence%20comprehension%3A%20an%20fMRI%20study%20using%20word-category%20ambiguity&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B41" data-legacy-id="B41"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B41" href="javascript:;" aria-label="jumplink-B41"></a></span></div><div class="ref false"><div id="ref-auto-B41" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Strange</div> <div class="given-names">BA</div></div>,  <div class="name"><div class="surname">Henson</div> <div class="given-names">RNA</div></div>,  <div class="name"><div class="surname">Friston</div> <div class="given-names">KJ</div></div>,  <div class="name"><div class="surname">Dolan</div> <div class="given-names">RJ</div></div>. </span><div class="article-title">Brain mechanisms for detecting perceptual, semantic, and emotional deviance</div>, <div class="source ">Neuroimage</div>, <div class="year">2000</div>, vol. <div class="volume">12</div> <div class="issue">4</div>(pg. <div class="fpage">425</div>-<div class="lpage">33</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Brain%20mechanisms%20for%20detecting%20perceptual%2C%20semantic%2C%20and%20emotional%20deviance&amp;author=BA%20Strange&amp;author=RNA%20Henson&amp;author=KJ%20Friston&amp;author=RJ%20Dolan&amp;publication_year=2000&amp;journal=Neuroimage&amp;volume=12&amp;pages=425-33" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1006/nimg.2000.0637" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1006%2Fnimg.2000.0637" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1006%2Fnimg.2000.0637"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/10988036" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Brain%20mechanisms%20for%20detecting%20perceptual%2C%20semantic%2C%20and%20emotional%20deviance&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B42" data-legacy-id="B42"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B42" href="javascript:;" aria-label="jumplink-B42"></a></span></div><div class="ref false"><div id="ref-auto-B42" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Tabert</div> <div class="given-names">MH</div></div>,  <div class="name"><div class="surname">Borod</div> <div class="given-names">JC</div></div>,  <div class="name"><div class="surname">Tang</div> <div class="given-names">CY</div></div>, et al. </span><div class="article-title">Differential amygdala activation during emotional decision and recognition memory tasks using unpleasant words: an fMRI study</div>, <div class="source ">Neuropsychologia</div>, <div class="year">2001</div>, vol. <div class="volume">39</div> <div class="issue">6</div>(pg. <div class="fpage">556</div>-<div class="lpage">73</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Differential%20amygdala%20activation%20during%20emotional%20decision%20and%20recognition%20memory%20tasks%20using%20unpleasant%20words%3A%20an%20fMRI%20study&amp;author=MH%20Tabert&amp;author=JC%20Borod&amp;author=CY%20Tang&amp;publication_year=2001&amp;journal=Neuropsychologia&amp;volume=39&amp;pages=556-73" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1016/S0028-3932(00)00157-3" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1016%2FS0028-3932(00)00157-3" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1016%2FS0028-3932(00)00157-3"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/11257281" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Differential%20amygdala%20activation%20during%20emotional%20decision%20and%20recognition%20memory%20tasks%20using%20unpleasant%20words%3A%20an%20fMRI%20study&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B43" data-legacy-id="B43"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B43" href="javascript:;" aria-label="jumplink-B43"></a></span></div><div class="ref false"><div id="ref-auto-B43" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Tabibnia</div> <div class="given-names">G</div></div>,  <div class="name"><div class="surname">Lieberman</div> <div class="given-names">MD</div></div>,  <div class="name"><div class="surname">Craske</div> <div class="given-names">MG</div></div>. </span><div class="article-title">The lasting effect of words on feelings: words may facilitate exposure effects to threatening images</div>, <div class="source ">Emotion</div>, <div class="year">2008</div>, vol. <div class="volume">8</div> <div class="issue">3</div>(pg. <div class="fpage">307</div>-<div class="lpage">17</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=The%20lasting%20effect%20of%20words%20on%20feelings%3A%20words%20may%20facilitate%20exposure%20effects%20to%20threatening%20images&amp;author=G%20Tabibnia&amp;author=MD%20Lieberman&amp;author=MG%20Craske&amp;publication_year=2008&amp;journal=Emotion&amp;volume=8&amp;pages=307-17" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1037/1528-3542.8.3.307" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1037%2F1528-3542.8.3.307" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1037%2F1528-3542.8.3.307"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/18540747" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:The%20lasting%20effect%20of%20words%20on%20feelings%3A%20words%20may%20facilitate%20exposure%20effects%20to%20threatening%20images&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B44" data-legacy-id="B44"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B44" href="javascript:;" aria-label="jumplink-B44"></a></span></div><div class="ref false"><div id="ref-auto-B44" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Tesink</div> <div class="given-names">CM</div></div>,  <div class="name"><div class="surname">Petersson</div> <div class="given-names">KM</div></div>,  <div class="name"><div class="surname">Van Berkum</div> <div class="given-names">JJ</div></div>,  <div class="name"><div class="surname">van den Brink</div> <div class="given-names">D</div></div>,  <div class="name"><div class="surname">Buitelaar</div> <div class="given-names">JK</div></div>,  <div class="name"><div class="surname">Hagoort</div> <div class="given-names">P</div></div>. </span><div class="article-title">Unification of speaker and meaning in language comprehension: an fMRI Study</div>, <div class="source ">Journal of Cognitive Neuroscience</div>, <div class="year">2009</div>, vol. <div class="volume">21</div> <div class="issue">11</div>(pg. <div class="fpage">2085</div>-<div class="lpage">99</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Unification%20of%20speaker%20and%20meaning%20in%20language%20comprehension%3A%20an%20fMRI%20Study&amp;author=CM%20Tesink&amp;author=KM%20Petersson&amp;author=JJ%20Van%20Berkum&amp;author=D%20van%20den%20Brink&amp;author=JK%20Buitelaar&amp;author=P%20Hagoort&amp;publication_year=2009&amp;journal=Journal%20of%20Cognitive%20Neuroscience&amp;volume=21&amp;pages=2085-99" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1162/jocn.2008.21161" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1162%2Fjocn.2008.21161" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1162%2Fjocn.2008.21161"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/19016606" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Unification%20of%20speaker%20and%20meaning%20in%20language%20comprehension%3A%20an%20fMRI%20Study&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B45" data-legacy-id="B45"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B45" href="javascript:;" aria-label="jumplink-B45"></a></span></div><div class="ref false"><div id="ref-auto-B45" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Tzourio-Mazoyer</div> <div class="given-names">N</div></div>,  <div class="name"><div class="surname">Landeau</div> <div class="given-names">B</div></div>,  <div class="name"><div class="surname">Papathanassiou</div> <div class="given-names">D</div></div>, et al. </span><div class="article-title">Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain</div>, <div class="source ">Neuroimage</div>, <div class="year">2002</div>, vol. <div class="volume">15</div> <div class="issue">1</div>(pg. <div class="fpage">273</div>-<div class="lpage">289</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Automated%20anatomical%20labeling%20of%20activations%20in%20SPM%20using%20a%20macroscopic%20anatomical%20parcellation%20of%20the%20MNI%20MRI%20single-subject%20brain&amp;author=N%20Tzourio-Mazoyer&amp;author=B%20Landeau&amp;author=D%20Papathanassiou&amp;publication_year=2002&amp;journal=Neuroimage&amp;volume=15&amp;pages=273-289" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1006/nimg.2001.0978" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1006%2Fnimg.2001.0978" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1006%2Fnimg.2001.0978"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/11771995" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Automated%20anatomical%20labeling%20of%20activations%20in%20SPM%20using%20a%20macroscopic%20anatomical%20parcellation%20of%20the%20MNI%20MRI%20single-subject%20brain&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B46" data-legacy-id="B46"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B46" href="javascript:;" aria-label="jumplink-B46"></a></span></div><div class="ref false"><div id="ref-auto-B46" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Wicker</div> <div class="given-names">B</div></div>,  <div class="name"><div class="surname">Keysers</div> <div class="given-names">C</div></div>,  <div class="name"><div class="surname">Plailly</div> <div class="given-names">J</div></div>,  <div class="name"><div class="surname">Royet</div> <div class="given-names">JP</div></div>,  <div class="name"><div class="surname">Gallese</div> <div class="given-names">V</div></div>,  <div class="name"><div class="surname">Rizzolatti</div> <div class="given-names">G</div></div>. </span><div class="article-title">Both of us disgusted in My insula: the common neural basis of seeing and feeling disgust</div>, <div class="source ">Neuron</div>, <div class="year">2003</div>, vol. <div class="volume">40</div> <div class="issue">3</div>(pg. <div class="fpage">655</div>-<div class="lpage">64</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Both%20of%20us%20disgusted%20in%20My%20insula%3A%20the%20common%20neural%20basis%20of%20seeing%20and%20feeling%20disgust&amp;author=B%20Wicker&amp;author=C%20Keysers&amp;author=J%20Plailly&amp;author=JP%20Royet&amp;author=V%20Gallese&amp;author=G%20Rizzolatti&amp;publication_year=2003&amp;journal=Neuron&amp;volume=40&amp;pages=655-64" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1016/S0896-6273(03)00679-2" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1016%2FS0896-6273(03)00679-2" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1016%2FS0896-6273(03)00679-2"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/14642287" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Both%20of%20us%20disgusted%20in%20My%20insula%3A%20the%20common%20neural%20basis%20of%20seeing%20and%20feeling%20disgust&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B47" data-legacy-id="B47"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B47" href="javascript:;" aria-label="jumplink-B47"></a></span></div><div class="ref false"><div id="ref-auto-B47" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Willems</div> <div class="given-names">RM</div></div>,  <div class="name"><div class="surname">Hagoort</div> <div class="given-names">P</div></div>. </span><div class="article-title">Neural evidence for the interplay between language, gesture, and action: a review</div>, <div class="source ">Brain Language</div>, <div class="year">2007</div>, vol. <div class="volume">101</div> <div class="issue">3</div>(pg. <div class="fpage">278</div>-<div class="lpage">89</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Neural%20evidence%20for%20the%20interplay%20between%20language%2C%20gesture%2C%20and%20action%3A%20a%20review&amp;author=RM%20Willems&amp;author=P%20Hagoort&amp;publication_year=2007&amp;journal=Brain%20Language&amp;volume=101&amp;pages=278-89" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1016/j.bandl.2007.03.004" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1016%2Fj.bandl.2007.03.004" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1016%2Fj.bandl.2007.03.004"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/17416411" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Neural%20evidence%20for%20the%20interplay%20between%20language%2C%20gesture%2C%20and%20action%3A%20a%20review&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B48" data-legacy-id="B48"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B48" href="javascript:;" aria-label="jumplink-B48"></a></span></div><div class="ref false"><div id="ref-auto-B48" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Willems</div> <div class="given-names">RM</div></div>,  <div class="name"><div class="surname">Hagoort</div> <div class="given-names">P</div></div>,  <div class="name"><div class="surname">Casasanto</div> <div class="given-names">D</div></div>. </span><div class="article-title">Body-specific representations of action verbs: neural evidence from right- and left-handers</div>, <div class="source ">Psychological Science</div>, <div class="year">2010</div>, vol. <div class="volume">21</div> <div class="issue">1</div>(pg. <div class="fpage">67</div>-<div class="lpage">74</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Body-specific%20representations%20of%20action%20verbs%3A%20neural%20evidence%20from%20right-%20and%20left-handers&amp;author=RM%20Willems&amp;author=P%20Hagoort&amp;author=D%20Casasanto&amp;publication_year=2010&amp;journal=Psychological%20Science&amp;volume=21&amp;pages=67-74" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1177/0956797609354072" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1177%2F0956797609354072" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1177%2F0956797609354072"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/20424025" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Body-specific%20representations%20of%20action%20verbs%3A%20neural%20evidence%20from%20right-%20and%20left-handers&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B49" data-legacy-id="B49"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B49" href="javascript:;" aria-label="jumplink-B49"></a></span></div><div class="ref false"><div id="ref-auto-B49" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Willems</div> <div class="given-names">RM</div></div>,  <div class="name"><div class="surname">Oostenveld</div> <div class="given-names">R</div></div>,  <div class="name"><div class="surname">Hagoort</div> <div class="given-names">P</div></div>. </span><div class="article-title">Early decreases in alpha and gamma band power distinguish linguistic from visual information during sentence comprehension</div>, <div class="source ">Brain Research</div>, <div class="year">2008</div>, vol. <div class="volume">1219</div> (pg. <div class="fpage">78</div>-<div class="lpage">90</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Early%20decreases%20in%20alpha%20and%20gamma%20band%20power%20distinguish%20linguistic%20from%20visual%20information%20during%20sentence%20comprehension&amp;author=RM%20Willems&amp;author=R%20Oostenveld&amp;author=P%20Hagoort&amp;publication_year=2008&amp;journal=Brain%20Research&amp;volume=1219&amp;pages=78-90" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1016/j.brainres.2008.04.065" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1016%2Fj.brainres.2008.04.065" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1016%2Fj.brainres.2008.04.065"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/18538306" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Early%20decreases%20in%20alpha%20and%20gamma%20band%20power%20distinguish%20linguistic%20from%20visual%20information%20during%20sentence%20comprehension&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B50" data-legacy-id="B50"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B50" href="javascript:;" aria-label="jumplink-B50"></a></span></div><div class="ref false"><div id="ref-auto-B50" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Willems</div> <div class="given-names">RM</div></div>,  <div class="name"><div class="surname">Özyürek</div> <div class="given-names">A</div></div>,  <div class="name"><div class="surname">Hagoort</div> <div class="given-names">P</div></div>. </span><div class="article-title">When language meets action: the neural integration of gesture and speech</div>, <div class="source ">Cerebral Cortex</div>, <div class="year">2007</div>, vol. <div class="volume">17</div> <div class="issue">10</div>(pg. <div class="fpage">2322</div>-<div class="lpage">33</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=When%20language%20meets%20action%3A%20the%20neural%20integration%20of%20gesture%20and%20speech&amp;author=RM%20Willems&amp;author=A%20%C3%96zy%C3%BCrek&amp;author=P%20Hagoort&amp;publication_year=2007&amp;journal=Cerebral%20Cortex&amp;volume=17&amp;pages=2322-33" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1093/cercor/bhl141" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1093%2Fcercor%2Fbhl141" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1093%2Fcercor%2Fbhl141"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/17159232" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:When%20language%20meets%20action%3A%20the%20neural%20integration%20of%20gesture%20and%20speech&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B51" data-legacy-id="B51"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B51" href="javascript:;" aria-label="jumplink-B51"></a></span></div><div class="ref false"><div id="ref-auto-B51" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Willems</div> <div class="given-names">RM</div></div>,  <div class="name"><div class="surname">Özyürek</div> <div class="given-names">A</div></div>,  <div class="name"><div class="surname">Hagoort</div> <div class="given-names">P</div></div>. </span><div class="article-title">Seeing and hearing meaning: ERP and fMRI evidence of word versus picture integration into a sentence context</div>, <div class="source ">Journal of Cognitive Neuroscience</div>, <div class="year">2008</div>, vol. <div class="volume">20</div> <div class="issue">7</div>(pg. <div class="fpage">1235</div>-<div class="lpage">49</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Seeing%20and%20hearing%20meaning%3A%20ERP%20and%20fMRI%20evidence%20of%20word%20versus%20picture%20integration%20into%20a%20sentence%20context&amp;author=RM%20Willems&amp;author=A%20%C3%96zy%C3%BCrek&amp;author=P%20Hagoort&amp;publication_year=2008&amp;journal=Journal%20of%20Cognitive%20Neuroscience&amp;volume=20&amp;pages=1235-49" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1162/jocn.2008.20085" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1162%2Fjocn.2008.20085" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1162%2Fjocn.2008.20085"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/18284352" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Seeing%20and%20hearing%20meaning%3A%20ERP%20and%20fMRI%20evidence%20of%20word%20versus%20picture%20integration%20into%20a%20sentence%20context&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B52" data-legacy-id="B52"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B52" href="javascript:;" aria-label="jumplink-B52"></a></span></div><div class="ref false"><div id="ref-auto-B52" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Willems</div> <div class="given-names">RM</div></div>,  <div class="name"><div class="surname">Özyürek</div> <div class="given-names">A</div></div>,  <div class="name"><div class="surname">Hagoort</div> <div class="given-names">P</div></div>. </span><div class="article-title">Differential roles for left inferior frontal and superior temporal cortex in multimodal integration of action and language</div>, <div class="source ">Neuroimage</div>, <div class="year">2009</div>, vol. <div class="volume">47</div> <div class="issue">4</div>(pg. <div class="fpage">1992</div>-<div class="lpage">2004</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Differential%20roles%20for%20left%20inferior%20frontal%20and%20superior%20temporal%20cortex%20in%20multimodal%20integration%20of%20action%20and%20language&amp;author=RM%20Willems&amp;author=A%20%C3%96zy%C3%BCrek&amp;author=P%20Hagoort&amp;publication_year=2009&amp;journal=Neuroimage&amp;volume=47&amp;pages=1992-2004" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1016/j.neuroimage.2009.05.066" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1016%2Fj.neuroimage.2009.05.066" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1016%2Fj.neuroimage.2009.05.066"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/19497376" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Differential%20roles%20for%20left%20inferior%20frontal%20and%20superior%20temporal%20cortex%20in%20multimodal%20integration%20of%20action%20and%20language&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div><div content-id="B53" data-legacy-id="B53"><div class="refLink-parent"><span class="refLink"><a name="jumplink-B53" href="javascript:;" aria-label="jumplink-B53"></a></span></div><div class="ref false"><div id="ref-auto-B53" class="ref-content "><div class="citation element-citation"><span class="person-group"><div class="name"><div class="surname">Willems</div> <div class="given-names">RM</div></div>,  <div class="name"><div class="surname">Toni</div> <div class="given-names">I</div></div>,  <div class="name"><div class="surname">Hagoort</div> <div class="given-names">P</div></div>,  <div class="name"><div class="surname">Casasanto</div> <div class="given-names">D</div></div>. </span><div class="article-title">Neural dissociations between action verb understanding and motor imagery</div>, <div class="source ">Journal of Cognitive Neuroscience</div>, <div class="year">2010</div>, vol. <div class="volume">22</div> <div class="issue">10</div>(pg. <div class="fpage">2387</div>-<div class="lpage">400</div>)<!--citationLinks: case 1--><div class="citation-links"></div><div class="citation-links"><p class="citation-links-compatibility"><span class="google-scholar-ref-link"><a class="openInAnotherWindow" href="https://scholar.google.com/scholar_lookup?title=Neural%20dissociations%20between%20action%20verb%20understanding%20and%20motor%20imagery&amp;author=RM%20Willems&amp;author=I%20Toni&amp;author=P%20Hagoort&amp;author=D%20Casasanto&amp;publication_year=2010&amp;journal=Journal%20of%20Cognitive%20Neuroscience&amp;volume=22&amp;pages=2387-400" target="_blank">Google Scholar</a></span></p><div class="crossref-doi js-ref-link"><a class="openInAnotherWindow" href="http://dx.doi.org/10.1162/jocn.2009.21386" target="_blank">Crossref</a></div><div class="adsDoiReference hide"><a class="openInAnotherWindow" href="http://adsabs.harvard.edu/cgi-bin/basic_connect?qsearch=10.1162%2Fjocn.2009.21386" target="_blank">Search ADS</a></div><div class="xslopenurl empty-target"><span class="inst-open-url-holders" data-targetId="10.1162%2Fjocn.2009.21386"> </span></div><div class="pub-id"><a href="http://www.ncbi.nlm.nih.gov/pubmed/19925195" class="link link-pub-id openInAnotherWindow" target="_blank">PubMed</a></div><p class="citation-links-compatibility"><span class="worldcat-reference-ref-link js-worldcat-preview-ref-link" style="display:none"><a class="openInAnotherWindow" href="https://www.worldcat.org/search?q=ti:Neural%20dissociations%20between%20action%20verb%20understanding%20and%20motor%20imagery&amp;qt=advanced&amp;dblist=638" target="_blank">WorldCat</a></span></p> </div></div></div></div></div></div>        <!-- /foreach -->



        <div class="article-metadata-standalone-panel clearfix"></div>

        
<div class="copyright copyright-statement">© The Author(s) (2010). Published by Oxford University Press.</div><div class="license"><div class="license-p">This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/by-nc/4.0/), which permits non-commercial re-use, distribution, and reproduction in any medium, provided the original work is properly cited. For commercial re-use, please contact journals.permissions@oup.com</div></div><!-- /foreach -->

        <span id="UserHasAccess" data-userHasAccess="True"></span>

    </div><!-- /.widget-items -->
</div><!-- /.module-widget -->

 
    </div>
    <div class="widget widget-SolrResourceMetadata widget-instance-OUP_Article_ResourceMetadata_Widget">
        
    <div class=" add-border article-metadata-panel solr-resource-metadata">
                <div class="article-metadata-tocSections">
                    <div class="article-metadata-tocSections-title">Issue Section:</div>
                        <a href="/scan/search-results?f_TocHeadingTitle=Original Articles">Original Articles</a>
                </div>

    </div>


 
    </div>
    <div class="widget widget-EditorInformation widget-instance-OUP_Article_EditorInformation_Widget">
        
 
    </div>
    <div class="widget widget-ArticleOpenScienceBadges widget-instance-OUP_Article_OpenScienceBadge_Widget">
        
 
    </div>

                <div id="ContentTabFilteredView"></div>
                <div class="downloadImagesppt js-download-images-ppt st-download-images-ppt">
                    <a id="lnkDownloadAllImages"
                       class="js-download-all-images-link btn"
                       href="/DownloadFile/DownloadImage.aspx?image=&amp;PPTtype=SlideSet&amp;ar=1647696&amp;xsltPath=~/UI/app/XSLT&amp;siteId=5242">Download all slides</a>
                </div>
                    <div class="widget widget-ArticleDataRepositories widget-instance-Article_DryadLink">
         
    </div>

                <div class="comments">
    <div class="widget widget-UserCommentBody widget-instance-UserCommentBody_Article">
        

 
    </div>
    <div class="widget widget-UserComment widget-instance-OUP_UserComment_Article">
         
    </div>

                </div>
            </div>
        </div>

    </div>
</div>
<div id="Sidebar" class="page-column page-column--right">
    <div class="widget widget-AdBlock widget-instance-ArticlePageTopSidebar">
        

<div class="adBlockMainBodyTop-wrap js-adBlockMainBodyTop hide">
    
    <div id="adBlockMainBodyTop"
         style=" ">
        <script>
            googletag.cmd.push(function () { googletag.display('adBlockMainBodyTop'); });
        </script>
    </div>
        <div class="advertisement-text">Advertisement</div>
</div> 
    </div>
<div class="widget widget-dynamic " data-count="1"> 

    <div class="widget-dynamic-inner-wrap">

<div class="widget widget-dynamic " data-count="10"> 

    <div class="widget-dynamic-inner-wrap">

    <div class="widget widget-ArticleLevelMetrics widget-instance-Article_RightRailB0Article_RightRail_ArticleLevelMetrics">
        



    <div class="artmet-wrapper horizontal-artmet">

        <div class="artmet-condensed-wrap clearfix">

            <div class="artmet-condensed-stats clearfix">
                    <div class="artmet-item artmet-views">
                        <span class="artmet-number">2,177</span>
                        <span class="artmet-text">Views</span>
                    </div>

                <div class="artmet-item artmet-citations">
                    <span class="artmet-number">
                            <a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;SrcApp=PARTNER_APP&amp;SrcAuth=LinksAMR&amp;KeyUT=WOS:000293636000002&amp;DestLinkType=CitingArticles&amp;DestApp=ALL_WOS&amp;UsrCustomerID=61f30d8ae69c46f86624c5f98a3bc13a" target="_blank">15</a>
                    </span>
                    <span class="artmet-text">Citations</span>
                </div>
                <div class="artmet-item artmet-badges-wrap">
                        <div class="artmet-item artmet-altmetric">
    <div class="widget widget-AltmetricLink widget-instance-ArticleLevelMetrics_AltmetricLinkSummary">
            <!-- Altmetrics -->
    <div id="altmetricEmbedId"
         runat="server"
         class='altmetric-embed'
         data-badge-type="donut"
         data-hide-no-mentions="false"
         data-doi="10.1093/scan/nsq050"

        

        ></div>
         <script type='text/javascript' src='https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js'></script>
 
    </div>

                        </div>


                    </div>
                </div>

                <div class="artmet-modal-trigger-wrap clearfix">
                    <a class="artmet-modal-trigger" data-article-id="1647696"><i class="icon-metrics"></i><span>View Metrics</span></a>
                </div>
        </div>
            <div class="artmet-modal" id="MetricsModal">
                <div class="artmet-modal-contents">
                    <a class="artmet-close-modal">&#215;</a>
                </div>
            </div>
    </div>

 
    </div>
    <div class="widget widget-Alerts widget-instance-Article_RightRailB0Article_RightRail_Alerts">
        
    <div class="alertsWidget">
        <h3>Email alerts</h3>
                <div class="userAlert alertType-1">
                    <a class="js-user-alert" role="button"
                       data-userLoggedIn="False"
                       data-alertType="1" href="javascript:;">Article activity alert</a>
                </div>
                <div class="userAlert alertType-3">
                    <a class="js-user-alert" role="button"
                       data-userLoggedIn="False"
                       data-alertType="3" href="javascript:;">Advance article alerts</a>
                </div>
                <div class="userAlert alertType-5">
                    <a class="js-user-alert" role="button"
                       data-userLoggedIn="False"
                       data-alertType="5" href="javascript:;">New issue alert</a>
                </div>
                    <div class="userAlert alertType-MarketingLink">
                <a class="js-user-alert" role="button"
                   data-userLoggedIn="False"
                   data-additionalUrl="/my-account/communication-preferences" href="javascript:;">Receive exclusive offers and updates from Oxford Academic</a>
            </div>
        <div class="userAlertSignUpModal reveal-modal small" data-reveal>
            <div class="userAlertSignUp"></div>
            <a role="button" aria-label="Close" class="close-reveal-modal" href="javascript:;">
                <i class="icon-general-close"></i>
            </a>
        </div>
    </div>
 
    </div>
    <div class="widget widget-ArticleLinks widget-instance-Article_RightRailB0Article_RightRail_ArticleLinks">
         
    </div>
    <div class="widget widget-RelatedContent widget-instance-Article_RightRailB0Article_RightRail_RelatedContent">
         
    </div>
    <div class="widget widget-RelatedArticleIn widget-instance-Article_RightRailB0Article_RightRail_RelatedArticleIn">
            <h3 class="relatedArticleIn-title">Related articles in</h3>
    <div class="relatedArticleIn-content">
        <ul>
                <li>
                    <a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&amp;SrcApp=PARTNER_APP&amp;SrcAuth=LinksAMR&amp;KeyUT=WOS:000293636000002&amp;DestLinkType=RelatedRecords&amp;DestApp=ALL_WOS&amp;UsrCustomerID=61f30d8ae69c46f86624c5f98a3bc13a">Web of Science</a>
                </li>
                <li>
                    <a href="https://scholar.google.com/scholar?q=related:https%3a%2f%2facademic.oup.com%2fscan%2farticle%2f6%2f4%2f404%2f1647696">Google Scholar</a>
                </li>
        </ul>
    </div>
 
    </div>
    <div class="widget widget-ArticleCitedBy widget-instance-Article_RightRailB0Article_RightRail_ArticleCitedBy">
        <div class="rail-widget_wrap vt-articles-cited-by">
    <h3 class="article-cited-title">Citing articles via</h3>
    <div class="widget-links_wrap">
            <div class="article-cited-link-wrap web-of-science">
                <a href="http://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&SrcApp=PARTNER_APP&SrcAuth=LinksAMR&KeyUT=WOS:000293636000002&DestLinkType=CitingArticles&DestApp=ALL_WOS&UsrCustomerID=61f30d8ae69c46f86624c5f98a3bc13a" target="_blank">Web of Science (15)</a>
            </div>
                    <div class="article-cited-link-wrap google-scholar-url">
                <a href="http://scholar.google.com/scholar?q=link:https%3A%2F%2Facademic.oup.com%2Fscan%2Farticle%2F6%2F4%2F404%2F1647696" target="_blank">Google Scholar</a>
            </div>
                    <div class="article-cited-link-wrap crossref-citedby">
                <a href='https://academic.oup.com/scan/crossref-citedby/1647696'>Crossref</a>
            </div>
    </div>
</div> 
    </div>
    <div class="widget widget-ArticleListNewAndPopular widget-instance-Article_RightRailB0Article_RightRail_ArticleNewPopularCombined">
            <ul class="articleListNewAndPopularCombinedView">
            <li>
                <h3>
                    <a href="javascript:;" class="articleListNewAndPopular-mode active" data-mode="MostRecent">Latest</a>
                </h3>
            </li>
            <li>
                <h3>
                    <a href="javascript:;" class="articleListNewAndPopular-mode " data-mode="MostRead">Most Read</a>
                </h3>
            </li>
            <li>
                <h3>
                    <a href="javascript:;" class="articleListNewAndPopular-mode " data-mode="MostCited">Most Cited</a>
                </h3>
            </li>
    </ul>
        <section class="articleListNewPopContent articleListNewAndPopular-ContentView-MostRecent hasContent">




<div id="newPopularList-Article_RightRailB0Article_RightRail_ArticleNewPopularCombined" class="fb">

    



<div class="widget-layout widget-layout--vert">
            <div class="widget-columns widget-col-1">
                    <div class="col">

<div class="widget-dynamic-entry">
    <input id="hfDoi" name="hfDoi" type="hidden" value="10.1093/scan/nsaa142" />

    

<a href="/scan/advance-article/doi/10.1093/scan/nsaa142/5928351?searchresult=1">
        <div class="widget-dynamic-journal-title">
Morning brain: Real-world neural evidence that high school class times matter    </div>
</a>
<div class="widget-dynamic-journal-image-synopsis">
        <div class="widget-dynamic-journal-synopsis">
            
        </div>
</div>
</div>
<div class="widget-dynamic-entry">
    <input id="hfDoi" name="hfDoi" type="hidden" value="10.1093/scan/nsaa131" />

    

<a href="/scan/advance-article/doi/10.1093/scan/nsaa131/5925823?searchresult=1">
        <div class="widget-dynamic-journal-title">
EEG response to game-craving according to personal preference for games    </div>
</a>
<div class="widget-dynamic-journal-image-synopsis">
        <div class="widget-dynamic-journal-synopsis">
            
        </div>
</div>
</div>
<div class="widget-dynamic-entry">
    <input id="hfDoi" name="hfDoi" type="hidden" value="10.1093/scan/nsaa129" />

    

<a href="/scan/advance-article/doi/10.1093/scan/nsaa129/5925822?searchresult=1">
        <div class="widget-dynamic-journal-title">
Health news sharing is reflected in distributed reward-related brain activity    </div>
</a>
<div class="widget-dynamic-journal-image-synopsis">
        <div class="widget-dynamic-journal-synopsis">
            
        </div>
</div>
</div>
<div class="widget-dynamic-entry">
    <input id="hfDoi" name="hfDoi" type="hidden" value="10.1093/scan/nsaa140" />

    

<a href="/scan/advance-article/doi/10.1093/scan/nsaa140/5925821?searchresult=1">
        <div class="widget-dynamic-journal-title">
The Protective Effect of Daytime Sleep on Planning and Risk-Related Decision Making in Emerging Adults    </div>
</a>
<div class="widget-dynamic-journal-image-synopsis">
        <div class="widget-dynamic-journal-synopsis">
            
        </div>
</div>
</div>
<div class="widget-dynamic-entry">
    <input id="hfDoi" name="hfDoi" type="hidden" value="10.1093/scan/nsaa130" />

    

<a href="/scan/advance-article/doi/10.1093/scan/nsaa130/5912972?searchresult=1">
        <div class="widget-dynamic-journal-title">
Windowed Multiscale Synchrony: Modeling Time-Varying and Scale-Localized Interpersonal Coordination Dynamics    </div>
</a>
<div class="widget-dynamic-journal-image-synopsis">
        <div class="widget-dynamic-journal-synopsis">
            
        </div>
</div>
</div>
                    </div>
            </div>

</div></div>
        </section>
        <section class="articleListNewPopContent articleListNewAndPopular-ContentView-MostRead hide">
        </section>
        <section class="articleListNewPopContent articleListNewAndPopular-ContentView-MostCited hide">
        </section>
 
    </div>

    </div>

</div>
    </div>

</div>    <div class="widget widget-AdBlock widget-instance-ArticlePageTopMainBodyBottom">
        

<div class="adBlockMainBodyBottom-wrap js-adBlockMainBodyBottom hide">
    
    <div id="adBlockMainBodyBottom"
         style=" ">
        <script>
            googletag.cmd.push(function () { googletag.display('adBlockMainBodyBottom'); });
        </script>
    </div>
        <div class="advertisement-text">Advertisement</div>
</div> 
    </div>

</div>

</div>
<input id="hfArticleTitle" name="hfArticleTitle" type="hidden" value="Add a picture for suspense: neural correlates of the interaction between language and visual information in the perception of fear | Social Cognitive and Affective Neuroscience | Oxford Academic" />
<input id="hfLeftNavStickyOffset" name="hfLeftNavStickyOffset" type="hidden" value="29" />
<input id="hfAreOpFeaturesEnabled" name="hfAreOpFeaturesEnabled" type="hidden" value="False" />


            </div><!-- /.center-inner-row no-overflow -->
        </section>
    </div>
    <div class="mobile-mask">
    </div>
    <section class="footer_wrap vt-site-footer">
        
    <script type="text/javascript" src="https://www.google.com/recaptcha/api.js?onload=onloadCallback&render=explicit"></script>
    
    
    <script type="text/javascript" src="https://cdn.jsdelivr.net/chartist.js/latest/chartist.min.js"></script>

    <script type="text/javascript" src="//oup.silverchair-cdn.com/UI/app/jsdist/v-637378577425675830/article-page.min.js"></script>

    <script type="text/javascript">
        googletag.cmd.push(function () {
            
            googletag.pubads().setTargeting("jnlsdoi", "10.1093/scan/nsq050");
            googletag.enableServices();
        });
    </script>



        


    <div class="widget widget-SitePageFooter widget-instance-SitePageFooter">
        <div class="ad-banner ad-banner-footer">
    <div class="widget widget-AdBlock widget-instance-FooterAd">
        

<div class="adBlockFooter-wrap js-adBlockFooter hide">
    
    <div id="adBlockFooter"
         style=" ">
        <script>
            googletag.cmd.push(function () { googletag.display('adBlockFooter'); });
        </script>
    </div>
        <div class="advertisement-text">Advertisement</div>
</div> 
    </div>

</div>

    <div class="journal-footer journal-bg">
        <div class="center-inner-row">

                <div class="journal-footer-menu">

                    <ul>
                                <li class="link-1">
                                    <a href="/scan/pages/About">About SCAN</a>
                                </li>
                                <li class="link-2">
                                    <a href="/scan/pages/Editorial_Board">Editorial Board</a>
                                </li>
                                <li class="link-3">
                                    <a href="/scan/pages/General_Instructions">Author Guidelines</a>
                                </li>
                                <li class="link-4">
                                    <a href="https://www.facebook.com/OUPMedicine/">Facebook</a>
                                </li>
                                <li class="link-5">
                                    <a href="https://twitter.com/OUPMedicine">Twitter</a>
                                </li>
</ul><ul>                                <li class="link-1">
                                    <a href="http://www.oxfordjournals.org/en/library-recommendation-form.html">Recommend to your Library</a>
                                </li>
                                <li class="link-2">
                                    <a href="http://www.oupmediainfo.com/">Advertising and Corporate Services</a>
                                </li>
                                <li class="link-3">
                                    <a href="http://science-and-mathematics-careernetwork.oxfordjournals.org">Journals Career Network</a>
                                </li>

                    </ul>


                </div><!-- /.journal-footer-menu -->

            <div class="journal-footer-affiliations">
                <!-- <h3>Affiliations</h3> -->
                    <a href="" target="">
                        <img id="footer-logo-SocialCognitiveandAffectiveNeuroscience" class="journal-footer-affiliations-logo" src="//oup.silverchair-cdn.com/data/SiteBuilderAssets/Live/Images/scan/scan_f11453332748.svg" alt="Social Cognitive and Affective Neuroscience" />
                    </a>
            </div><!-- /.journal-footer-affiliations -->

            <div class="journal-footer-colophon">
                <ul>
                        <li>Online ISSN 1749-5024</li>
                                            <li>Print ISSN 1749-5016</li>
                    <li>Copyright &#169; 2020 Oxford University Press</li>
                </ul>
            </div><!-- /.journal-footer-colophon -->


        </div><!-- /.center-inner-row -->
    </div><!-- /.journal-footer -->
 
    </div>

<div class="oup-footer">
    <div class="center-inner-row">
    <div class="widget widget-SelfServeContent widget-instance-OupUmbrellaFooterSelfServe">
        
<div class="oup-footer-row journal-links">
<div class="global-footer selfservelinks">
<ul>
    <li>
    <a href="/journals/pages/about_us">About Us</a>
    </li>
    <li>
    <a href="/journals/pages/contact_us">Contact Us</a>
    </li>
    <li>
    <a href="http://global.oup.com/jobs">Careers</a>
    </li>
    <li>
    <a href="/journals/pages/help">Help</a>
    </li>
    <li>
    <a href="/journals/pages/access_purchase">Access &amp; Purchase</a></li>
    <li>
    <a href="/journals/pages/access_purchase/rights_and_permissions">Rights &amp; Permissions</a>
    </li>
    <li>
    <a href="/journals/pages/open_access">Open Access</a>
    </li>
</ul>
</div>
<div class="global-footer selfservelinks">
<h4 id="global-footer-customer services" class="title footerheader">Connect</h4>
<ul>
    <li>
    <a href="/my-account/communication-preferences">Join Our Mailing List</a>
    </li>
    <li>
    <a href="http://blog.oup.com/">OUPblog</a>
    </li>
    <li>
    <a href="http://twitter.com/oupacademic">Twitter</a>
    </li>
    <li>
    <a href="https://www.facebook.com/OUPAcademic">Facebook</a>
    </li>
    <li>
    <a href="http://www.youtube.com/playlist?list=PL3MAPgqN8JWioLLTkU4mlFM4-SNt-f1Xs">YouTube</a>
    </li>
    <li>
    <a href="http://oupacademic.tumblr.com/">Tumblr</a>
    </li>
</ul>
</div>
<div class="global-footer selfservelinks">
<h4>Resources</h4>
<ul>
    <li><a href="/journals/pages/authors">Authors</a></li>
    <li><a href="/journals/pages/librarians">Librarians</a></li>
    <li><a href="/journals/pages/societies">Societies</a></li>
    <li><a href="https://academic.oup.com/journals/pages/sponsorship_and_advertising">Sponsors &amp; Advertisers</a></li>
    <li><a href="/journals/pages/press">Press &amp; Media</a></li>
    <li><a href="/journals/pages/agents">Agents</a></li>
</ul>
</div>
<div class="global-footer selfservelinks">
<h4>Explore</h4>
<ul>
    <li><a href="http://global.oup.com/academic">Shop OUP Academic</a></li>
    <li><a href="http://www.oxforddictionaries.com/">Oxford Dictionaries</a></li>
    <li><a href="https://www.epigeum.com/">Epigeum</a></li>
    <li><a href="http://global.oup.com/">OUP Worldwide</a></li>
    <li><a href="http://www.ox.ac.uk/">University of Oxford</a></li>
</ul>
</div>
<div class="OUP-mission">
<p>Oxford University Press is a department of the University of Oxford. It furthers the University's objective of excellence in research, scholarship, and education by publishing worldwide</p>
<img class="journal-footer-logo" src="//oup.silverchair-cdn.com/UI/app/svg/umbrella/oup-logo.svg" alt="Oxford University Press" width="150" height="42" />
</div>
</div>
<div class="oup-footer-row">
<div class="oup-footer-row-links">
<ul>
    <li>Copyright &copy; 2020 Oxford University Press</li>
    <li><a href="https://global.oup.com/cookiepolicy/">Cookie Policy</a></li>
    <li><a href="https://global.oup.com/privacy">Privacy Policy</a></li>
    <li><a href="/journals/pages/about_us/legal/notices">Legal Notice</a></li>
    <li><a href="/journals/pages/sitemap">Site Map</a></li>
    <li><a href="/journals/pages/about_us/legal/accessibility">Accessibility</a></li>
    <li><a href="https://get.adobe.com/reader/">Get Adobe Reader</a></li>
</ul>
</div>
</div>
<style type="text/css">
    /* Issue right column fix for tablet/mobile */
    @media (max-width: 1200px) {
    .pg_issue .widget-instance-OUP_Issue {
    width: 100%;
    }
    }
    .sf-facet-list .sf-facet label, .sf-facet-list .taxonomy-label-wrap label {font-size: .9375rem;}
    .issue-pagination-wrap .pagination-container {float: right;}
</style>
    
    
     
    </div>

    </div>
</div>
<div class="ss-ui-only">

</div>

    </section>
</div>



    



    <div class="widget widget-SiteWideModals widget-instance-SiteWideModals">
        <div id="revealModal" class="reveal-modal" data-reveal>
    <div id="revealContent"></div>
    <a class="close-reveal-modal" href="javascript:;"><i class="icon-general-close"></i><span class="screenreader-text">Close</span></a>
</div>

<div id="NeedSubscription" class="reveal-modal small" data-reveal>
    <div class="subscription-needed">
        <h5>This Feature Is Available To Subscribers Only</h5>
        <p><a href="/sign-in">Sign In</a> or <a href="/my-account/register?siteId=5242&amp;returnUrl=%2fscan%2farticle%2f6%2f4%2f404%2f1647696">Create an Account</a></p>
    </div>
    <a class="close-reveal-modal" href="javascript:;"><i class="icon-general-close"></i><span class="screenreader-text">Close</span></a>
</div>

<div id="noAccessReveal" class="reveal-modal tiny" data-reveal>
    <p>This PDF is available to Subscribers Only</p>
    <a class="hide-for-article-page" id="articleLinkToPurchase" data-reveal><span>View Article Abstract & Purchase Options</span></a>
    <div class="issue-purchase-modal">
        <p>For full access to this pdf, sign in to an existing account, or purchase an annual subscription.</p>
    </div>
    <a class="close-reveal-modal" href="javascript:;"><i class="icon-general-close"></i><span class="screenreader-text">Close</span></a>
</div>
 
    </div>


    


<script src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<script src="//cdn.jsdelivr.net/npm/promise-polyfill@8/dist/polyfill.min.js"></script>

    <script type="text/javascript" src="//oup.silverchair-cdn.com/UI/app/jsdist/v-637378577469269799/footer.min.js"></script>
    <script async="async" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=xa-5265518246c10183&domready=1"></script>


    

    

    
    




    


    <!-- Copyright 2001-2010, IBM Corporation All rights reserved. -->
    <script src="//ouptag.scholarlyiq.com/ntpagetag.js"></script>
    <noscript>
        <img src="//ouptag.scholarlyiq.com/ntpagetag.gif?js=0" height="1" width="1" border="0" hspace="0" vspace="0" alt="Scholarly IQ" />
    </noscript>


    <div class="ad-banner js-ad-riser ad-banner-riser">

    <div class="widget widget-AdBlock widget-instance-RiserAd">
         
    </div>

    </div>


</body>
</html>

